
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":["daniel_antal"],"categories":null,"content":"Daniel Antal is an experienced data scientist, consultant, economist, and the co-founder of Reprex, a Netherlands-based startup that brings the benefits of big data to small organizations with shared resources and research automation. He applies data science practice, open-source software development with sound economics and valuation techniques.\nHe is also a research affiliate at the Centre for Competition Policy and at the Institute for Information Law of the University of Amsterdam.\n","date":1664107200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1664874780,"objectID":"0d25123d0ac03749a9d015a7325a60af","permalink":"https://reprex.nl/authors/daniel_antal/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/daniel_antal/","section":"authors","summary":"Daniel Antal is an experienced data scientist, consultant, economist, and the co-founder of Reprex, a Netherlands-based startup that brings the benefits of big data to small organizations with shared resources and research automation.","tags":null,"title":"Daniel Antal","type":"authors"},{"authors":["botond_vitos"],"categories":null,"content":"Botond is a data scientist and cultural studies scholar with an interest in digital humanities, music research and festival cultures. His past projects were focused on grassroots music scenes and alternative communities, and he is currently contributing to the development of our Demo Music Observatory and Listen Local initiatives. He is the production editor and art director of the peer reviewed journal Dancecult. He is taking care of our Data APIs and “big data” collection.\n","date":1622545200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1625655600,"objectID":"c1536294e7c1b417b634c0a8cbd81ce6","permalink":"https://reprex.nl/authors/botond_vitos/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/botond_vitos/","section":"authors","summary":"Botond is a data scientist and cultural studies scholar with an interest in digital humanities, music research and festival cultures. His past projects were focused on grassroots music scenes and alternative communities, and he is currently contributing to the development of our Demo Music Observatory and Listen Local initiatives.","tags":null,"title":"Botond Vitos","type":"authors"},{"authors":["line"],"categories":null,"content":"Andrés is a data scientist and an ethnomusicologist. He is an experienced international researcher with interests that lie at the intersection between data science and the humanities. He helps our team with quantifying (ethno-)musicological variables to train better AI models and to make our Demo Music Observatory more valuable for its users. He also helps us reach out to potential partners in North America.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9e868dbbe6f9fb7afda2116432b74ef6","permalink":"https://reprex.nl/authors/andres/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/andres/","section":"authors","summary":"Andrés is a data scientist and an ethnomusicologist. He is an experienced international researcher with interests that lie at the intersection between data science and the humanities. He helps our team with quantifying (ethno-)musicological variables to train better AI models and to make our Demo Music Observatory more valuable for its users.","tags":null,"title":"Andrés García Molina","type":"authors"},{"authors":["borbala_domotorfy"],"categories":null,"content":"Borbála Dömötörfy is a European competition law and policy professional with 12 years of experience spent working for academia, competition authorities and international law firms. Her past research projects (including her PhD thesis) focused on the intersection of competition law with IP and sectoral regulations. Besides her legal and policy work, she has a genuine interest in technology and data, and especially in legal technology. She is also a trained UX designer and has a passion for human-computer interaction and behavioral science.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f64d59381f3f6bae0e36ce260537e0f1","permalink":"https://reprex.nl/authors/borbala_domotorfy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/borbala_domotorfy/","section":"authors","summary":"Borbála Dömötörfy is a European competition law and policy professional with 12 years of experience spent working for academia, competition authorities and international law firms. Her past research projects (including her PhD thesis) focused on the intersection of competition law with IP and sectoral regulations.","tags":null,"title":"Borbála Dömötörfy","type":"authors"},{"authors":null,"categories":null,"content":"Our Competition Data Observatory is a fully automated, open source, open data observatory that produces new indicators from open data sources and experimental big data sources, with authoritative copies and a modern API.\nOur observatory is monitoring the certain segments of the European economy, and develops tools for computational antitrust in Europe. We take a critical SME-, intellectual property policy and competition policy point of view automation, robotization, and the AI revolution on the service-oriented European social market economy.\nWe would like to create early-warning, risk, economic effect, and impact indicators that can be used in scientific, business and policy contexts for professionals who are working on re-setting the European economy after a devastating pandemic and in the age of AI. We would like to map data between economic activities (NACE), antitrust markets, and sub-national, regional, metropolitian area data.\nGet involved in services: our ongoing projects, team of contributors, open-source libraries and use our data for publications. See some use cases. We are committed to the Guidelines for Open Policy Analysis\nFollow news about us or the more comprehensive Data \u0026amp; Lyrics blog.\nContact us .\nDownload our competition presentation\nOur Product/Market Fit was validated in the world’s 2nd ranked university-backed incubator program, the Yes!Delft AI Validation Lab.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"a159d9e206578d76dccedfa8fe719339","permalink":"https://reprex.nl/authors/competition/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/competition/","section":"authors","summary":"Our Competition Data Observatory is a fully automated, open source, open data observatory that produces new indicators from open data sources and experimental big data sources, with authoritative copies and a modern API.","tags":null,"title":"Competition Data Observatory","type":"authors"},{"authors":null,"categories":null,"content":"The creative and cultural sectors and industries are mainly made of networks of freelancers and microenterprises, with very few medium-sized companies. Their economic performance, problems, and innovation capacities are hidden. Our open collaboration to create this data observatory is committed to change this. Relying on modern data science, the re-use of open governmental data, open science data, and novel harmonized data collection we aim to fill in the gaps left in the official statistics of the European Union.\nDownload our short introduction.\nWe believe that introducing Open Policy Analysis standards with open data, open-source software and research automation can help better understanding how creative people and their enterprises and institutions add value to the European economy, how they create jobs, innovate, and increase the well-being of a diverse European society. Our collaboration is open for individuals, citizens scientists. Institutions can join as partners to the Consortium that maintains our observatory.\nGet involved in services: our ongoing projects, team of contributors, open-source libraries and use our data for publications. See some use cases.\nFollow news about us.\nContact us .\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"a7745461e1013c7c1b47c14d382fb8c6","permalink":"https://reprex.nl/authors/ccsi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/ccsi/","section":"authors","summary":"The creative and cultural sectors and industries are mainly made of networks of freelancers and microenterprises, with very few medium-sized companies. Their economic performance, problems, and innovation capacities are hidden. Our open collaboration to create this data observatory is committed to change this.","tags":null,"title":"Cultural \u0026 Creative Sectors and Industries Observatory","type":"authors"},{"authors":null,"categories":null,"content":"The Digital Music Observatory is a fully automated, open source, open data observatory that links public datasets in order to provide a comprehensive view of the European music industry. The DMO produces key business and policy indicators that enable the growth of music business strategies and national music policies in a way that works both for music lover audiences and the creative enterprises of the sector, and contributes to a more competitive, fair and sustainable European music ecosystem.\nDownload our introduction. We are committed to the Guidelines for Open Policy Analysis.\nOur data pillars are following the structure laid out in the Feasibility study for the establishment of a European Music Observatory: Music Economy; Diversity \u0026amp; Circulation; Music \u0026amp; Society and Innovation - innovative data applications\nOur Product/Market Fit was validated in the world’s 2nd ranked university-backed incubator program, the Yes!Delft AI Validation Lab. We are currently developing this project with the help of the JUMP European Music Market Accelerator program.\nFollow news about us or the more comprehensive Data \u0026amp; Lyrics blog.\nContact us.\nMusic is one of the most data-driven service industries where the majority of sales are already made by AI-driven autonomous systems. The DMO is a fully-functional service that can function as a testing ground of the European Data Strategy, showcasing the ways in which the music industry is affected by the problems that the Digital Services Act and the Trustworthy AI initiatives attempt to regulate. If these policies will work for the European microenterprise-dominated, complex and fragile European music ecosystem, then they are likely to make Europe fit for the digital age.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e0cd67c14a496b769f8c9f7ca04cb1d5","permalink":"https://reprex.nl/authors/music/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/music/","section":"authors","summary":"The Digital Music Observatory is a fully automated, open source, open data observatory that links public datasets in order to provide a comprehensive view of the European music industry. The DMO produces key business and policy indicators that enable the growth of music business strategies and national music policies in a way that works both for music lover audiences and the creative enterprises of the sector, and contributes to a more competitive, fair and sustainable European music ecosystem.","tags":null,"title":"Digital Music Observatory Team","type":"authors"},{"authors":null,"categories":null,"content":"Climate change and environmental degradation are an existential threat to Europe and the world. To overcome these challenges, the European Union created the European Green Deal strategic plan. It aims to make the EU’s economy sustainable by turning climate and environmental challenges into opportunities, and making the transition just and inclusive for all.\nOur automated observatory want to support evidence-based policy making, and KPIs for business and policy-makers alike with truly usable open science and open governmental data. We want to make sure that environmental, socio-economic, political data is brought to easy-to-import, easy to compare, tidy formats. We use data that has been scientifically validated, and we aim to validate all our open-source processing code in scientific peer-review.\nOur collaboration is open for individuals, citizens scientists, research institutes, NGOS, companies.\nDownload our description and open call for collaboration. We are committed to the Guidelines for Open Policy Analysis\nGet involved in services: our ongoing projects, team of contributors, open-source libraries and use our data for publications. See some use cases.\nFollow news about us.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"733630ec7222dac974dd528ba7cec1a1","permalink":"https://reprex.nl/authors/greendeal/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/greendeal/","section":"authors","summary":"Climate change and environmental degradation are an existential threat to Europe and the world. To overcome these challenges, the European Union created the European Green Deal strategic plan. It aims to make the EU’s economy sustainable by turning climate and environmental challenges into opportunities, and making the transition just and inclusive for all.","tags":null,"title":"Green Deal Data Observatory Team","type":"authors"},{"authors":["istvan_simon"],"categories":null,"content":"Istvan is an experienced technology entrepreneur venturing new digital solutions and business models. Before that he was a consulting actuary for a decade with large and smaller clients in Northern, Western and Eastern Europe. His business understanding paired with his highly quantitative background and programming skills make him able to help our business and research partners turn their data workflows more automated, reproducible, effective and efficient. Istvan follows the Code of Ethics of the Hungarian Actuarial Society.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"563f5fd38ad6b1429a816d27436746c2","permalink":"https://reprex.nl/authors/istvan_simon/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/istvan_simon/","section":"authors","summary":"Istvan is an experienced technology entrepreneur venturing new digital solutions and business models. Before that he was a consulting actuary for a decade with large and smaller clients in Northern, Western and Eastern Europe.","tags":null,"title":"Istvan Simon","type":"authors"},{"authors":["curator"],"categories":null,"content":" Help us curate data - tell us what sort of information is missing from your research agenda. Challenge us and collaborate with us in the crafting of valuable datasets that combine domain knowledge with reproducible, open data research practices.\nWhen you ae ready, just fill the template of this file out and send it to us in an email or via a Github pull request.\nJane Doe is an experienced competition economist and often produces evidence in various consumer protection related cases. She is interested in how fair competition measures can prevent greenwashing and she is contributing to our data curation about this topic.\nRead more: Open Collaboration With Data Curators and Onboarding New Curators.\nMore interested in music, cultural heritage, or environemtal and social sustainability? Please, follow us on social media, it really helps us finding new users and showing that we are able to grow our ecosystem. Green Deal Data Observatory on Linkedin and Green Deal Data Observatory on Twitter Economy Data Observatory on Linkedin and Economy Data Observatory on Twitter Digital Music Data Observatory on Linkedin and Digital Music Data Observatory on Twitter Are you a developer interested in open source reproducible research? Please refer to this call for cooperation.\nAttribution: the woman avatar is designed by Andy Horvath - Flaticon.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"dd7e87cb618c3c88b40f53ca6635c9ec","permalink":"https://reprex.nl/authors/curator/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/curator/","section":"authors","summary":"Help us curate data - tell us what sort of information is missing from your research agenda. Challenge us and collaborate with us in the crafting of valuable datasets that combine domain knowledge with reproducible, open data research practices.","tags":null,"title":"New Curators","type":"authors"},{"authors":["developer"],"categories":null,"content":"Reprex is a Dutch-American early stage startup based in the Netherlands specializing in making data reliable and accountable while delivering trustworthy analytics and AI solutions. Our diverse team works from several locations and countries; our ideal candidates are located in South Holland (the Hague/Rotterdam/Delft/Leiden), Western New York state/greater Toronto, Budapest, Bratislava, or Milano, where we have ongoing projects and team members, and thus more onboarding and team-building possibilities. That said, we are open to candidates from any location. We bridge industry and academia through various advanced statistical and ethical AI verification projects: while our R\u0026amp;D partners are leading universities, we aim to deploy our solutions in business environments.\nWe welcome candidates from all backgrounds and mother tongues who are proficient in R and have a good working knowledge of the English language.\nReprex team members follow the Contributor Covenant, “pledg[ing] to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.”\nOur internal communication platform is Github for software development and Keybase, an open-source alternative to Slack. You do not have to be a master of Github Action and Github products but you must be able to make pull requests, commits, and solve issues on this platform. To apply to any of the positions below, please send an email with a link to your résumé and a brief description of your interest. You can ask questions on Keybase, too.\nR developer(s) We are looking for intermediate or advanced R users with a passion for open data and open science for the maintenance of our CRAN-released R packages and the development of further packages. We are pursuing a hybrid model, providing the R community with open-source packages, and engaging in paid work that utilizes this software in commercial or academic environments.\nOur ideal candidate(s) are\na) at least intermediate-level R programmers or possess domain-specific knowledge relevant to our packages, or\nb) advanced in R programming and agnostic to actual packages\nc) excited to maintain and develop one or more of our packages\nAll of our packages follow the modernization of the R language and are built on rlang and vctrs. All the packages use the tidyverse as a dependency, which creates a consistent user interface (i.e. dplyr, tidyr, tidyselect.)\nPackages Please visit our dataobservatory.eu github page, and check out our advice for new contributors.\niotables: an R package for reproducible input-output analysis, economic, and environmental impact assessment. The domain specific knowledge is input-output economics, multiplier analysis, and environmental impact analysis. A working knowledge of SNA or an interest in macro-finance is a plus. We develop this application within the rOpenGov community and the rOpenSci community. The application has various uses in banking, insurance, music industry, and policy design.\nretroharmonize: an R package for retrospective survey harmonization and survey recycling. The domain specific knowledge is an interest in international, multi-language surveys, longitudinal surveys, and the reuse of survey data. We develop this application within the rOpenGov community and the rOpenSci community. The application has various uses in survey harmonization, data integration, and survey design.\nregions: an R package for adjusting sub-national boundaries for the making of regional statistics. While the U.S. has relatively stable sub-national boundaries (the US postal codes), most nations change their internal boundaries very frequently. Currently, regions tracks these changes in Europe, but our package could and should be extended to all ISO-conforming sub-national boundaries globally. An ideal domain-specific interest is geography, cartography, and/or small-area statistics. The package is currently not developed actively, but we expect it to be developed in a small-area statistics context, or for surveying withing a regional component.\ndataset creates datasets from standared R objects (data.fame, data.table, tibble, or well-structured lists like json) that are highly interoperable and can be placed into relational databases, semantic web applications, archives, repositories. They follow the FAIR principles: they are findable, accessible, interoperable and reusable. They contain the entire processing history of the dataset for reproducability.\nThe goal of statcodelists is to promote the reuse and exchange of statistical information and related metadata with making the internationally standardized SDMX code lists available for the R user.\nspotifyr\ndataobservatory The goal of dataobservatory is to facilitate the automated …","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"25c8c4ca7d3bdc3f31d6afce9bdb583a","permalink":"https://reprex.nl/authors/developer/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/developer/","section":"authors","summary":"Reprex is a Dutch-American early stage startup based in the Netherlands specializing in making data reliable and accountable while delivering trustworthy analytics and AI solutions. Our diverse team works from several locations and countries; our ideal candidates are located in South Holland (the Hague/Rotterdam/Delft/Leiden), Western New York state/greater Toronto, Budapest, Bratislava, or Milano, where we have ongoing projects and team members, and thus more onboarding and team-building possibilities.","tags":null,"title":"New Developers","type":"authors"},{"authors":null,"categories":null,"content":"We are a Netherlands-based start-up company that makes big data reliable and accountable, delivering trustworthy analytics and AI solutions. We validate multiple data sources and are able to merge private and proprietary data with open data. We bring novel insight into policy and business problems, as well as scientific research. Our work addresses the potentially negative effects of black-box proprietary algorithms. Our diverse team is particularly experienced in music, the creative industries, and digital humanities, where data is scattered in small organizations.\nWe are finalists in The Hague Innovators Award 2022 competition. Check out how you can help. Download our competition programme.\nThe Data SisyphusPoor metadata management causes much repeated tasks, errors, non-billable hours and uncredited work. Open DataOpen data cannot be just ‘downloaded’. It is not ready-to-use, and often not even public. Trustworthy AIWhat can go wrong with the algorithm? Finding unwanted outcomes and correcting them in complex systems. Research AutomationRepeaded data processing and validation steps are best made, documented, logged by computers. Data CurationData sits everywhere and it is not easy to find even at home. Our curators know where to dig. Professional Data ProcessingUncut diamonds need to be polished. Data is only potential information, raw and unprocessed. Metadata: Documentation \u0026amp; CodebooksAdding FAIR metadata exponentially increases the value of data. We use DataCite and SDMX statistical coding. Data-as-ServiceReusable, easy-to-import, interoperable, always fresh data in tidy formats with a modern API. Our flagship demo projects are the Listen Local ethical music recommendation system based on our Demo Music Observatory data integration and knowledge sharing platform. We have validated our product/market fit in the prestigious Yes!Delft AI+Blockchain Lab. We are members of the Dutch AI Coalition and participate in the work of the European AI Alliance.\nSee our services: data curation, open data access, survey harmonization, reproducible research and validated trustworthy AI applications.\nDownload our introduction.\nFollow news about us or the more comprehensive Data \u0026amp; Lyrics blog.\nContact us.\nCompany details: Registration number: 80205275 (KvK Chamber of Commerce); founding document: 000046572589 (vestigingnummer); VAT number NL 861587893B01.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://reprex.nl/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"We are a Netherlands-based start-up company that makes big data reliable and accountable, delivering trustworthy analytics and AI solutions. We validate multiple data sources and are able to merge private and proprietary data with open data.","tags":null,"title":"Reprex","type":"authors"},{"authors":[],"categories":["Public talk"],"content":" Reprex is a finalist for The Hague Innovators Award 2022, and the prize of the audience, in the startup category with our respectable competitors, Sibö, WECO, STHRIVE and ECOBLOQ. The transition towards a sustainable and inclusive economy depends on collaboration. That is why we are bringing together startups, scale-ups, investors, policymakers, and other impact makers from around the world in The Hague for the 7th edition of ImpactFest.\nWith the The Hague Innovators Challenge, the municipality of The Hague challenges startups, scale-ups, and students to present their innovative ideas for global issues, as described in the UN Sustainable Development Goals (SDGs).\nThe nominees receive a substantive program aimed at further development and the growth of the plan or organization. At the end of the substantive program, all nominees submit a definitive action plan and this is pitched to a professional jury. The jury chooses one winner per category.\n","date":1668502800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668502800,"objectID":"595c7f31c80fc87fcc0c11cd8bc1f5a8","permalink":"https://reprex.nl/talk/reprex-nominated-for-the-hague-innovators-award/","publishdate":"2022-09-13T10:20:00+02:00","relpermalink":"/talk/reprex-nominated-for-the-hague-innovators-award/","section":"event","summary":"Reprex is a finalist for The Hague Innovators Award 2022, and the prize of the audience, in the startup category with our respectable competitors, Sibö, WECO, STHRIVE and ECOBLOQ.","tags":["Listen Local","OpenMusE"],"title":"Reprex Nominated for The Hague Innovators Award","type":"event"},{"authors":[],"categories":null,"content":" Daniel Antal, Reprex’s founder will talk in the Eindhoven Innovation Café. You can rewatch some former talks on their website. ","date":1667496600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667496600,"objectID":"4c7a8d9aee3b2455bdc1c477c498ab54","permalink":"https://reprex.nl/talk/big-data-for-all-building-collaborative-data-observatories/","publishdate":"2022-08-10T12:20:00+02:00","relpermalink":"/talk/big-data-for-all-building-collaborative-data-observatories/","section":"event","summary":"Introducing the collaborative data observatories with the example of the music industry and sector.","tags":["Listen Local","OpenMusE"],"title":"Big Data for All - Building Collaborative Data Observatories","type":"event"},{"authors":[],"categories":["Meetups"],"content":" Reprex is a research automation company with an international team and clientele. We validated our product/market fit in the Yes!Delft AI+Blockchain Lab in 2020 and started to build research automation tools for complex data problems with a fast-growing user base and a very high-level international recognition in the EU and the UK. Our dual product offers us to participate in large data platform PPP projects and find growth opportunities in building data-driven commercial applications simultaneously. We want to scale up our operations in the Hague, where we are registered.\nReprex is a finalist for The Hague Innovators Challenge and the prize of the audience. Download this information in 1 page. | Check out our pitch deck Our platform solution is a modernized, future-proof, web 3.0 version of the data observatories of the EU, UN, and OECD. About 60 large data observatories worldwide serve numerous consultancies, universities, NGOs, and other knowledge-based organizations with consistent information collection and processing. We want to power at least 10% of these global knowledge infrastructures in 5 years because we think our technology is superior to almost all of them. By providing essential services to them, we get access to the data ecosystems of prime governmental, academic, and large corporate users. Our central position in one mature and four emerging observatories allows us to provide shared services to for-profit and non-profit organizations that do not have a data science/engineering team.\nWe also have a compelling proposition to an organization that had built large database systems that became quickly obsolete: we offer them an alternative to rigid relational databases. We provide these organizations with competitive data acquisition, processing, knowledge management, and documentation services, which enables even very small commercial or civil society partners to deploy (ethical) AI.\nAfter winning a very competitive Horizon Europe Research and Innovation tender, we are upgrading our Digital Music Observatory to be an officially recognized, shared data resource of the European music sector. Our observatories are PPP data ecosystems that create many jobs, not only in our startup but in their city ecosystems, too. As a permanent EU organization similar to the European Audiovisual Observatory, it can create up to 35 crucial knowledge jobs in Strasbourg. We want to join forces with the Hague, the Europeana (the EU cultural heritage body in the Hague), the PAARD, and other actors to make the permanent place of the European Music Observatory in the Hague. This work connects mainly to SGD Goal 5 (detecting algorithmic biases against womxn) and SDG Goal 8 (decent work for creative freelancers and protecting their income from global data monopolies).\nWe would also like to attract at least one more European or global observatory to the city. Our beachhead/flagship ecosystem is in music. We started expanding towards the related film, gaming, fashion, architecture, and other copyright-based industries. We also discovered function-specific uses that allowed us to go into commercially far more lucrative directions: we started building a computational antitrust and an environmental and social reporting supporting green observatory.\nWe think that our software-as-service components for connected financial-sustainability reporting, fueled by our emerging Computational Antitrust and Green Deal Data Observatories, provide an entry into the 4-billion-euro market of connecting financial and sustainability reporting and can make a very significant impact related to the SDG Goals 12 (responsible consumption) and Goals 13 (climate change). The banking, financial and antitrust regulators are forcing first the 49,000 large EU companies by 2024, then the SMEs and e-commerce platforms to provide auditable accounts of their environmental and social impacts in their entire value chains.\n","date":1664355600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664355600,"objectID":"b283aedef9ec6f8a47ff58827a9a5d08","permalink":"https://reprex.nl/talk/impactcity-startup-support-xl/","publishdate":"2022-09-13T10:20:00+02:00","relpermalink":"/talk/impactcity-startup-support-xl/","section":"event","summary":"Reprex is a finalist for The Hague Innovators Award 2022, and the prize of the audience, in the startup category with our respectable competitors, Sibö, WECO, STHRIVE and ECOBLOQ.","tags":["The Hague Innovators Challenge 2022"],"title":"ImpactCity Startup Support XL","type":"event"},{"authors":["Daniel Antal"],"categories":[],"content":"Survey Harmonization Workflow Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home | Finish: End Overview: Esc | Speaker notes: S | Fullscreen: F Principles Generic concept of surveying, i.e. examining and record the area and features of (an area of land) to construct a map, plan, or description. Structured data collection of the missing information, harmonization of knowledge. Reproducibility and not automation. On a small scale, anything can be done with Ctrl C + Ctrl V. But it should be recorded, documented for future Ctrl C + Ctrl V. Timeline Concepts We harmonize knowledge concepts. Because knowledge concepts are very abstract, the harmonization of concepts requires an iteration of desired output and questionnaire or form items, and it will be carried on throughout the project. The harmonization of concepts will allow us to link our survey data to pre-existing survey data, financial information, or any other source of information. Data Model Data modeling enables us to place the information we gain from existing sources, for example, by recycling pre-existing questionnaire items and answers to a knowledge graph together with our data. A knowledge graph is a more flexible, future-proof, generalized database that connects pre-existing information with new information. Question Bank The questionnaire harmonization includes the harmonization of the question or entry form label (In the past 12 months, how many times have you been to a concert) and the response scale (1, 2, Do not remember, Decline to say). The harmonization must be made with other knowledge concepts (i.e. the concept of the concert) and survey questionnaires or annual report information fields. Translations We must be able to work with translators and standardized translated labels. We must have the question bank ready by the end of October. Ensure that we do not use URIs but IRIs for identifying questionnaire items. Labesl are translated or localized. A generic ‘French’ label is often unsuitable for French speakers in Belgium. Fieldwork We must carry out fieldwork, i.e. surveying music-related problems. We will conduct the fieldwork with a cheap online tool (LimeSurvey or SurveyMonkey). The fieldwork will likely remain fully online or may contain a small, hybrid online interview element. The integration of fieldwork implementation is the least important task for us. Use whatever is convenient. Code and Save We must record the information into coded datasets that are saved into files. The success of the output harmonization will depend on the use of harmonized coding (we will use, whenever possible, SDMX code definitions, such as ‘F\u0026#34; = ‘female’) and the use of machine-readable, open, portable file formats. Potential users are small entities, and we will avoid the use of databases and favor the use of knowledge graphs instead. Output harmonization We will harmonize the data, which means that we will join the coded answers considering the question labels, the value labels, and various forms of missing information across all languages (i.e., English or German versions of a question and answer options.) Presentation We will report the harmonized information using graphic visualizations, tables placed into presentation slides, books or web pages. We should have the templates based on test data ready in January. Questions? Email\nLinkedIn: Daniel Antal - Digital Music Observatory\n","date":1664107200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664107200,"objectID":"a8e5c428104bc6b141a53a52fdc69ae9","permalink":"https://reprex.nl/slides/surveyharmonization/","publishdate":"2022-09-25T12:00:00Z","relpermalink":"/slides/surveyharmonization/","section":"slides","summary":"Survey Harmonization Workflow Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home | Finish: End Overview: Esc | Speaker notes: S | Fullscreen: F Principles Generic concept of surveying, i.","tags":["retroharmonize"],"title":"Surveyharmonization","type":"slides"},{"authors":null,"categories":"Rbloggers","content":" Download iotables The iotables R package is an open-source, scientifically validated package that collects and integrates data from reliable statistical sources and performs economic and environmental impact analysis. It is the backbone of our connected financial-sustainability reporting tool, Eviota, because it can analyze the value chains of 64 industries in every European country for free. It is your starting point to calculate employment, tax, or greenhouse gas multipliers for various policy actions in your country.\nThe 0.9.1 version of iotables was released today on CRAN. This new minor release contains a bug fix reported by a user and some documentation improvements. Check out our product page and our examples. The iotables package works with the open-source R statistical environment. We programmed every example of the Eurostat Manual of Supply, Use and Input-Output Tables, which can be used both as a control tool for our package and as a comprehensive, extended handbook on use. We have also started to meet the demands of a more global audience by adding more and more examples from the Handbook on Supply and Use Tables and Input-Output Tables with Extensions and Applications published by the United Nations. Our goal is to make both our iotables a free analytic and data processing tool and our premium Eviota ESG reporting premium solution applicable anywhere in the world. # From CRAN: install.packages(\u0026#34;iotables\u0026#34;) # From Github (development version) devtools::install_github(\u0026#34;rOpenGov/iotables\u0026#34;) # with vignettes: devtools::install_github(\u0026#34;rOpenGov/iotables\u0026#34;, build_vignettes = TRUE) The iotables tool has hundreds of technical and professional users in the world. We know that it is not for the faint heart. In 2022 we started the development of a tool that will create impact assessments for small companies or civil society organizations without the need to learn and use R.\n","date":1664000035,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664000035,"objectID":"709db518ffb907b64b3e4022fa9131ff","permalink":"https://reprex.nl/post/2022-09-24_iotables_release/","publishdate":"2022-09-24T08:13:55+02:00","relpermalink":"/post/2022-09-24_iotables_release/","section":"post","summary":"The iotables R package collects and integrates data from reliable statistical sources and performs economic and environmental impact analysis. It can be your starting point to calculate employment, tax, or greenhouse gas multipliers for various policy actions in your country for free, and it is the backbone of our connected financial-sustainability ESG reporting tool, Eviota, because it can analyze the value chains of 64 industries in every European country.","tags":["iotables","Eviota","Environmental Impact Analysis","Economic Impact Analysis"],"title":"iotables: Integrate Data from Reliable Statistical Sources for Economic and Environmental Impact Analysis","type":"post"},{"authors":[],"categories":["Meetup"],"content":"Our Listen Local project aims to develop tools that can be used by independent labels and self-releasing artists to make sure that their music finds relevant audiences in their scene, in their geographical environment and abroad.\nThe purpose of the meetup is to provide an informal setting to get to know each other, or exchange ideas and get into action. RSV on Eventbrite, on Keybase or via the contact form. We are working with leading EU and UK universities and industry associations to find out why sometimes Utrecht-based music is not recommended to people in Utrecht on streaming platforms? Or how we could build applications that bring the local music ecosystem into the attention of visitors, tourists? Or how we could build games or educational applications that help local youth, pupils, students, educators, with artists in their town, and expand their music discovery to the province, their country, neighboring countries, instead of only recommending a few artists from New York, London, Rio de Janeiro or Seoul.\nMap shows what rock bands mean when they announce a \u0026#34;World tour\u0026#34;. Really clever idea for a map I think! Source: https://t.co/ACjTZgdGJ7 pic.twitter.com/3LnVnlM2PS\n— Simon Kuestenmacher (@simongerman600) January 21, 2020 With the help of MusicAIRE and Horizon Europe, Europe’s premiere research and innovation grant, we are building open source tools to help to solve these problems, or allow other developers to build new applications and games.\nReprex is a member of the Dutch AI Coalition’s Culture and Media Working Group. The Dutch AI Coalition wants to make sure that algorithms work for all. This informal event will take place after the annual gathering of the working group from 9.00-18.00, with working groups members optional visit the Culture AI Lab.\nInterested in the Dutch AI Coalition event? If you are interested in those professional events, get in touch with us on Keybase or via the contact form. {{/spoiler}}\n","date":1663871400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663871400,"objectID":"c8c942a819e7e112bfafb8cd268ca156","permalink":"https://reprex.nl/talk/listen-local-utrecht/","publishdate":"2022-08-31T09:43:00+02:00","relpermalink":"/talk/listen-local-utrecht/","section":"event","summary":"Introducing the collaborative data observatories with the example of the music industry and sector.","tags":["Listen Local","Netherlands"],"title":"Listen Local Utrecht","type":"event"},{"authors":[],"categories":"","content":"Reprex presented its Digital Music Observatory and Cultural Creative Sectors Industries Data Observatory as platforms for developing and evaluating trustworthy AI in the cultural domains. We hope to find new partners within the NLAIC community to join our open, collaborative projects.\nWe have reviewed more than 80 data observatories in the world, and we are building five modern ones. It was particularly important for us to get away from the Hague, and meet organizations like DEN and the KB to find out how our ambitious plans could connect to their excellent work. Reprex is a finalist in the Hague Innovators Challenge 2022, and we would like to bring at least one global observatory, the planned European Music Observatory, into our beautiful and smart city. While knowledge graphs are virtual and live in the web 3.0, the Dutch AI Coalition and the country’s future competitiveness need to ensure that essential knowledge graphs will be managed by the ecosystem of Netherlands-based researchers, institutions, and startups. The ethical consciousness shown by the members of our Culture AI Lab shows that it is probably the best for future human generations globally, too.\nThe SABIO is one of the most interesting in the world and couuld be connected easily with our Cultural Creative Sectors Industries Data Observatory prototype. The Culture AI Lab presented a handful of very interesting, ethical and interesting projects. Pressing Matter responds to growing concerns in the Netherlands and Europe about how to deal with the legacies of colonialism in museums and builds innovative tools for museums (and broader society) to address the question of ownership of objects collected in the colonial period. Dr Emily Hansell Clark, former editor of our Data\u0026amp;Lyrics blog, presented the Polyvocal Interpretation of Contested Colonial Heritage project.\nBoth projects are conceptually and technologically relevant to our Listen Local project. Our project aims to prevent the colonization or start the de-colonization of the local music ecosystem and make local artists of Utrecht, Vilnius, or Sarajevo visible and audible in their own cities’ public spaces or on the smartphones of their town.\nThe most compelling use case of Listen Local project is finding out why music recommender systems do not recommend some music at all. Or why is it so hard to connect Utrecht-based artists with fans living or visiting Utrecht on the Spotify or YouTube platform? The Responsible Recommenders in the Public Library Sector is looking for similar answers for librarians to avoid all recommendations to visitors pointing to U.S. authors and publishers.\nSavvina Daniil’s excellent presentation raised very similar questions to our Feasibility Study On Promoting Slovak Music In Slovakia \u0026amp; Abroad. Our deep dive into legislative and regulatory issues of AI highlighted that the past decade unleashed global web-based tools that have the potential to undermine our democratic and cultural cohesion. Reassuringly, we have seen that our thinking about the dangers of AI on European culture and the technological solutions to combat them are very widely shared by NLAIC Culture and Media members. We hope that our partners’ policy work in the Digital Music Observatory and our forming new observatories will support policy design and decision-making that will protect the Netherlands and the EU from some of these threats.\nLearn more about the Dutch AI Coalition’s Cultur and Media Working Group (in Dutch:)\n","date":1663867800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664000035,"objectID":"012858c1c5b5b595e3edabd6a0a86407","permalink":"https://reprex.nl/post/2022-09-22_nlaic_culture_media/","publishdate":"2022-09-22T19:30:00+02:00","relpermalink":"/post/2022-09-22_nlaic_culture_media/","section":"post","summary":"Reprex is presenting its Digital Music Observatory and Cultural Creative Sectors Industries Data Observatory as platforms for developing and evaluating trustworthy AI in the cultural domains. We hope to find new partners within the NLAIC community to join our open, collaborative projects.","tags":["Listen Local","OpenMusE"],"title":"Dutch AI Coalition Working Group Culture and Media","type":"post"},{"authors":[],"categories":"","content":"Reprex is presenting its Digital Music Observatory and Cultural Creative Sectors Industries Data Observatory as platforms for developing and evaluating trustworthy AI in the cultural domains. We hope to find new partners within the NLAIC community to join our open, collaborative projects.\nLearn more about the Dutch AI Coalition’s Cultur and Media Working Group (in Dutch:)\n","date":1663839000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663839000,"objectID":"79dd795377b7d362778df71bc8375c6d","permalink":"https://reprex.nl/talk/dutch-ai-coalition-working-group-culture-and-media/","publishdate":"2022-09-21T16:20:00+02:00","relpermalink":"/talk/dutch-ai-coalition-working-group-culture-and-media/","section":"event","summary":"Reprex is presenting its Digital Music Observatory and Cultural Creative Sectors Industries Data Observatory as platforms for developing and evaluating trustworthy AI in the cultural domains. We hope to find new partners within the NLAIC community to join our open, collaborative projects.","tags":["Listen Local","OpenMusE"],"title":"Dutch AI Coalition Working Group Culture and Media","type":"event"},{"authors":["Daniel Antal"],"categories":[],"content":" Reprex is looking for new collaborations within the NLAIC Questions? Email | Keybase\nLinkedIn: Daniel Antal - Reprex\n","date":1663776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663776000,"objectID":"316a2f7f1ba5898d2bb4e26b0efc539a","permalink":"https://reprex.nl/slides/reprex-nlaic-2022/","publishdate":"2022-09-21T18:00:00+02:00","relpermalink":"/slides/reprex-nlaic-2022/","section":"slides","summary":"Reprex is looking for new collaborations within the NLAIC","tags":["Digital Music Observatory","CCSI Data Observatory","NLAIC"],"title":"Reprex Open Collaboration NLAIC 2022","type":"slides"},{"authors":["Daniel Antal"],"categories":["Rbloggers"],"content":"Big Data Creates Inequalities Only the largest corporations, best-endowed universities, and rich governments can afford data collection and processing capacities that are large enough to harness the advantages of AI.\nSlide navigation Fullscreen: F\nNext: ️\u0026gt; or Space | Previous :️\u0026lt; Start: Home | Finish: End Overview: Esc| Speaker notes: S Zoom: Alt + Click 🖱️ Big data that works for all Reprex: No matter how big is the problem or how small is your team, we fill your reports, dashboards, newsletters, books with data and its visualization.\nRun code from tutorials Find help, ask for help: reprex Documentation for better tutorials Debugging and testing code Contribute to documentation R is a functional language R + YAML + markdown = web ready Package and release: a team effort Data problems: Reprex Most SMEs, and civil society organizations do not have a data scientist/engineer in their team, maybe not even an IT person or a HR professional to make such a hire.","date":1663768800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664874780,"objectID":"5c7adcdfc6fe81d8487ad7a11cc370bf","permalink":"https://reprex.nl/slides/learnr-with-reprex/","publishdate":"2022-09-21T16:00:00+02:00","relpermalink":"/slides/learnr-with-reprex/","section":"slides","summary":"Your transition into using and developing R tools","tags":["R","Reprex"],"title":"Learn R with Reprex","type":"slides"},{"authors":["Daniel Antal"],"categories":[],"content":"Big Data Creates Inequalities Only the largest corporations, best-endowed universities, and rich governments can afford data collection and processing capacities that are large enough to harness the advantages of AI.\nSlide navigation Fullscreen: F\nNext: ️\u0026gt; or Space | Previous :️\u0026lt; Start: Home | Finish: End Overview: Esc| Speaker notes: S Zoom: Alt + Click 🖱️ Big data that works for all Reprex: No matter how big is the problem or how small is your team, we fill your reports, dashboards, newsletters, books with data and its visualization.\nConnected financial and sustainability reporting based on open data Eviota: We map your material impacts in your value chain and connect it with environmental or social data that is re-used from the public sector.\nData problems: Reprex Most SMEs, and civil society organizations do not have a data scientist/engineer in their team, maybe not even an IT person or a HR professional to make such a hire.","date":1663768800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664874780,"objectID":"7a3e79e5e5924eb9ecbd20c01f5aabcb","permalink":"https://reprex.nl/slides/reprex-esg-pitch/","publishdate":"2022-09-21T16:00:00+02:00","relpermalink":"/slides/reprex-esg-pitch/","section":"slides","summary":"ESG","tags":["Green Deal Music Observatory","Eviota"],"title":"Reprex","type":"slides"},{"authors":["Daniel Antal"],"categories":[],"content":"Big Data Creates Inequalities Only the largest corporations, best-endowed universities, and rich governments can afford data collection and processing capacities that are large enough to harness the advantages of AI.\nSlide navigation Fullscreen: F\nNext: ️\u0026gt; or Space | Previous :️\u0026lt; Start: Home | Finish: End Overview: Esc| Speaker notes: S Zoom: Alt + Click 🖱️ Data problems The cost of questionnaire-based market research (survey) is increasing exponentially and offers mediocre results without an enormous question bank and harmonization with other surveys.(See 🖱 blogpost) Manual data acquisition is an error-prone and boring task for humans that requires many working hours (often not credited in consultancies, law firms, or research institutes.)\nWrangling spreadsheet tables or word processor documents by people without data knowledge is the 🖱 data Sisyphus.\nData observatories 3.0 Reprex is offering shared data ecosystems. Our observatories are great solutions for organizations without a data specialization:\n🌳 Organizations that cannot afford to build a large enough data team to sustain consistent, extensive data collection and processing (many large institutions and companies)\n🪴 Who cannot hire even a single data engineer or a data scientist (medium-sized companies, NGOs)\n🌱 Who do not even have a permanent IT function (about 2 million European small enterprises and civil society organizations)\nThe European Union, the World Bank, OECD, and UN have facilitated the creation of more than 80 so-called ‘data observatories’ to help companies, researchers, NGOs, and governments systematically collect data and knowledge.\nWe are currently building one prototype for the European Music Observatory financed by the European Union and music industry players (cc 3-4 million euros.) We would like to take over existing or start new observatories in 2 years at least 5)\nOur observatories are competitive, because they use high-quality open source scientific software; they exploit the new Data Governance Act and Open Data Directive, deploy web 3.0 data synchronization, and offer great value-added research products.\nPlatform products Value added data applications The European Union, the World Bank, OECD, and UN have facilitated the creation of more than 80 so-called ‘data observatories’ to help companies, researchers, NGOs, and governments systematically collect data and knowledge.\nThe different observatories offer different types of knowledge products, such as statistical yearbooks, various apps, and database access.\nMost of them use web 1.0 technologies, inefficient knowledge accumulation. Already 20 of them have been discontinued. We are developing software solutions that exploit our platforms: we harmonize surveys, statistical data, automate research reporting, elements of market monitoring or ESG reporting.\nWe are currently building one prototype for the European Music Observatory financed by the European Union and music industry players (cc 3-4 million euros.) We would like to take over existing or start new observatories in 2 years at least 5) Each observatory gives us intimidate customer access to 3-4 large universities, 1-2 large consultancies, and various specialist institutions. Marketing strategy Buma/Stemra like copyright management agencies, music export offices, festivals and venues, University of Amsterdam, Sant’Anna, Economic University of Bratislava, ministries of culture, grant agencies.\nUniversity of Amsterdam, Europeana, Sant’Anna, Hungarian Film Fund\nConnected financial and sustainability reporting: bank consultancies, big four audit companies, large environmental NGOs.\nAntitrust agencies, law firms, economics consultancies working with mergers and other competition related issues.\nTarget market size The observatory platforms usually have a build-up cost of about 3-5 million euros and an annual running costs of 0.1-3 million euros.\nWe hope to gain at least 10% global market share on the observatory platform management market to pay our basic data science team and R\u0026amp;D. Our existing observatories give us access to the market and public surveying markets (cc € 30-40 bn in the developed nations), particularly to its software component (€ 10 billion euros). retroharmonize integrates pre-existing questionnaire-based surveys and new surveys. We see interest from the biggest global players. Our existing observatories gave us access to environmental impact assessment and currently we build an ESG reporting tool with a central bank, a value bank, and a big four company. Connected ESG reporting has a €4 bn market in the EU alone, and our Eviota product is very competitive. Due to regulatory pressure, we can harvest a decent share if we are able to attract venture capital. Team The two co-founders, 🖱 Daniel Antal, CFA and 🖱 Andrés García Molina, PhD, and the core team manage the ecosystems’ development, develop knowledge management, and direct the software development. 🖱 Team on full screen\nEach observatory has a broader …","date":1663768800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663768800,"objectID":"2aa41f38e291942e52b3746816b34ebe","permalink":"https://reprex.nl/slides/reprex-impactcity/","publishdate":"2022-09-21T16:00:00+02:00","relpermalink":"/slides/reprex-impactcity/","section":"slides","summary":"Discussion starter to contest the Hague Innovation Award.","tags":["Digital Music Observatory","The Hague Innovators Challenge 2022"],"title":"Reprex","type":"slides"},{"authors":["Daniel Antal"],"categories":null,"content":" Reprex is a finalist for The Hague Innovators Award 2022, and the prize of the audience, in the startup category with our respectable competitors, Sibö, WECO, STHRIVE and ECOBLOQ. The transition towards a sustainable and inclusive economy depends on collaboration. That is why we are bringing together startups, scale-ups, investors, policymakers, and other impact makers from around the world in The Hague for the 7th edition of ImpactFest.\nWith the The Hague Innovators Challenge, the municipality of The Hague challenges startups, scale-ups, and students to present their innovative ideas for global issues, as described in the UN Sustainable Development Goals (SDGs).\n","date":1663049520,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663049520,"objectID":"740b1dfb988d188118ed8357fe73053f","permalink":"https://reprex.nl/post/2022-09-13-the-hague-innovators-award/","publishdate":"2022-09-13T08:12:00+02:00","relpermalink":"/post/2022-09-13-the-hague-innovators-award/","section":"post","summary":"Reprex is a finalist for The Hague Innovators Award 2022, and the prize of the audience, in the startup category with our respectable competitors, Sibö, WECO, STHRIVE and ECOBLOQ.","tags":["Reprex","The Hague","Netherlands","The Hague Innovators Challenge 2022"],"title":"Reprex Nominated for The Hague Innovators Award","type":"post"},{"authors":[],"categories":["Meetup"],"content":"Our Listen Local project aims to develop tools that can be used by independent labels and self-releasing artists to make sure that their music finds relevant audiences in their scene, in their geographical environment and abroad.\nThe purpose of the meetup is to provide an informal setting to get to know each other, or exchange ideas and get into action. RSV on Keybase or via the contact form. We are working with leading EU and UK universities and industry associations to find out why sometimes Utrecht-based music is not recommended to people in Utrecht on streaming platforms? Or how we could build applications that bring the local music ecosystem into the attention of visitors, tourists? Or how we could build games or educational applications that help local youth, pupils, students, educators, with artists in their town, and expand their music discovery to the province, their country, neighboring countries, instead of only recommending a few artists from New York, London, Rio de Janeiro or Seoul.\nMap shows what rock bands mean when they announce a \u0026#34;World tour\u0026#34;. Really clever idea for a map I think! Source: https://t.co/ACjTZgdGJ7 pic.twitter.com/3LnVnlM2PS\n— Simon Kuestenmacher (@simongerman600) January 21, 2020 With the help of MusicAIRE and Horizon Europe, Europe’s premiere research and innovation grant, we are building open source tools to help to solve these problems, or allow other developers to build new applications and games.\nReprex is a member of the Dutch AI Coalition’s Culture and Media Working Group.\nInterested in the Dutch AI Coalition event? If you are interested in those professional events, get in touch with us on Keybase or via the contact form. {{/spoiler}}\n","date":1662681600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662681600,"objectID":"607030613377e67ff09e34320b64f821","permalink":"https://reprex.nl/talk/listen-local-vilnius/","publishdate":"2022-08-31T09:43:00+02:00","relpermalink":"/talk/listen-local-vilnius/","section":"event","summary":"Introducing the collaborative data observatories with the example of the music industry and sector.","tags":["Listen Local","Lithuania"],"title":"Listen Local Vilnius","type":"event"},{"authors":[],"categories":null,"content":"Daniel Antal will introduce Listen Local Lithuania, a new offspring of the Digital Music Observatory’s trustworthy AI program, Listen Local, and show what artists, managers, labels, and cultural policymakers can do to ideas about balancing the post-Covid revenues with increased sales on global platforms.\nBased on our experience in Slovakia (see: Feasibility Study On Promoting Slovak Music In Slovakia \u0026amp; Abroad), and new data from Lithuania and Ukraine we show what data management problems make the Lithuanian music invisible for the AI algorithms of YouTube, Spotify and other platforms; how artists from Vilnius or Kaunas can find their new release on Forgetify, and app that plays songs that were never played. We show why music revenues decreased in the past years for independent and small country catalogues, and we give practical advice on increasing the value and visibility of the Lithuanian music repertoire. We show an open, data federation model to connect the Lithuanian national library the system of collective management, distributors, and small data of artists and labels.\nPrepare your questions Do you want to know why your music is not recommended by streaming platforms? Are you interested in finding new Lithuanian music that fits into your radio or festival programming but your are stuck? You can send questions prior to the conference to the speaker, Daniel Antal, and we’ll address your problem with examples in the talk.\nOpt-in You can opt-in into our database before or during the conference, and we will give you tailored analysis about your data quality, and your opportunities to place your music to new audiences in Lithuania and abroad.\nVenue The talk will be in the what’s next in music conference or follow them on Facebook. Participation is free but requires registration. (We will post shortly more details on this.)\nThe time set for the talk is EEST Vilnius time (GMT+02.00).\nNot available? You can meet the project’s manager and the speaker on 10 September in Kaunas, at the closing event of what’s next in music.\nBackground Listen Local Lithuania is supported by the European Union’s MusicAIRE, an EU-funded project that aims to provide tailored-made instruments for the sector and contribute to a green, digital, just, and resilient recovery of the music ecosystem. It is managed by MXF in collaboration with Music Export Ukraine and Reprex.\nMXF and the outcomes of the Listen Local Lithuania will participate in the OpenMusE project, an international research and innovation project with prestigious universities, music industry stakeholders, collective management organizations, and innovative SMEs to design tools that promote the diversity of music on global platforms, increase the revenues and decrease the data costs of music organizations, provide cultural policymakers with the Open Policy Analysis framework the first time in Europe. This open collaboration project funded for 2023-2025 is open for small and large music organizations, collective management organizations, libraries, and cultural policymakers.\n","date":1662647400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662647400,"objectID":"0360331d396b80ca42ee08a44ddb5d64","permalink":"https://reprex.nl/talk/listen-local/","publishdate":"2022-07-22T12:20:00+02:00","relpermalink":"/talk/listen-local/","section":"event","summary":"Introducing `Listen Local Lithuania`","tags":["Listen Local"],"title":"Listen Local","type":"event"},{"authors":[],"categories":[],"content":"Invitation for an open collaboration Digital Music Observatory | Listen Local Lithuania\nControls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Lithuanian creators, including music creators, should earn as much as the European average. Their income should level up to German and Finnish levels.\nLithuanian people should find good Lithuanian music in Lithuania on Spotify, YouTube and the radio. Foreign labels must not increase their market share and colonize the local creative ecosystem.\nJoining the European Union Why should creators earn less than other skilled occupations and knowledge workers? Why should artists get less paid than the average in Lithuania? Why should Lithuanians get paid less than the average European? Read More Income \u0026amp; empirical comparisons | Setting the Value of Lithuanian Music\nWhy They Recommend American Music Is the algorithm cheating? ➡️ trustworthy AI policy, enabling courts, competition and consuerm protection agencies to protect the Lithuanian CCIs Is the algorithm learning from bad data? ➡️ national heritage policy, consolidate Lithuanian CCI data as linked, open data, and synch it daily with the world. Can we ask for 20% Lithuanian music in radio, television, YouTube or Spotify? Download in English | | Download in Slovak Lithuania is no different There are initiatives in the progress: LATGA already improved the rights management for one part of the composer’s rights management, MIC has more than 400 profiles in their database online, LMVA already lobbied for quotas, the Kūrybiškos Europos biuras has bright funding ideas, and the country has a respected national library.\nThere are facts and ideas: Muzikos sritis - Ekspertinio vertinimo ataskaita | ArtTech – galimybės Lietuvos kultūros ir kūrybinių industrijų sektoriui. Rekomendacijos Still a lot to do Still much to do: revaluing music requires a cooperation of all rightsholders, making sure that the AI systems of streaming services work well requires linking (elements of) the existing databases, probably via the library, to web of data to sync knowledge into the global global databases about Lithuania. Plenty of education needed how to revalue, claim money or defend the country from dark algorithms.\nFurther reading Open Polcy Analysis Open Policy Brief Trustworthy Cultural AI: make big data work for Lithuania artists and small labels, publishers and CCIs Synchronize the (meta)data of Lithuania heritage and present cultural production as linked open data, so that autonomous systems of Spotify, YouTube, Wikipedia, Library of Congress, etc, can read it. Practical, open source solutions that can immediately applied Access to the OpenMuse know-how LaLa Database Opt-in, opt-out database to make sure that you are in control Health check of artist data from Wikipedia to YouTube Make changes that avoid missing payments, recommendations errors. Listen Local Database Write-in database that we do not forget about any new or legacy artists, crowdsourcing for fans, journalists, musicians, educators to add artists, bands, ensembles Minimum requirement one commercially released recording, one published music composition, a Wikipedia page. Other commercially not released artists, or their heirs must explicitly register to LaLa (if they are not public, GDPR applies) Topics: - European AI regulation and ethics, music AI, - non-discriminiation and fair remuneration for Lithuania\u0026#39;s creators. - Smart and future proof local content and media regulation, music export, cultural heritage. Features: - The policy brief itself expressed as a resource, not a static file that is once finished and downloaded. - It is an educational document in itself, it is self-refreshing with data, legal and policy texts - We educate policy-makers and music professionals to talk, write and think about AI in a smart way. Invitation for an open collaboration Click for Contacts: Digital Music Observatory | Listen Local Lithuania | LaLa for Artists | Lala for Fans | Open Policy Analysis\nQuestions? Get in Touch: Daniel - Valuations, Metadata, AI Policy | Ioanna - Fashion \u0026amp; Blockchain | Borbala - Fair competition and fighting dark algorithms | Mark - MXF\nMarket analysis Local content regulation \u0026amp; goals Unpaid revenue rate Local content regulations for radios Goal setting on streaming Avoiding negative outcomes Trustworthy AI Human agency and oversight | Technical Robustness and Safety | Human agency and oversight | Privacy and Data Governance | Transparency | Diversity, Non-Discrimination and Fairness | Societal and Environmental Well-Being Data biases The data about the Lithuanian national cultural output and heritage shoulld be availabe in Lithuania Should be daily synchronized with the world via the Europena, Dbpedia, MusicBrainz and other open linked data solutions that connect YouTube, Spotify, and other platforms to daily, up-to-date knowledge to train their algorithms. AI is …","date":1662508800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662508800,"objectID":"4d02d06a80b0609891f373a56520566c","permalink":"https://reprex.nl/slides/listen-local-lithuania-invitation/","publishdate":"2022-09-07T00:00:00Z","relpermalink":"/slides/listen-local-lithuania-invitation/","section":"slides","summary":"Invitation for an open collaboration","tags":["Listen Local"],"title":"Listen Local Lithuania","type":"slides"},{"authors":null,"categories":null,"content":"Stop uploading your work onto the web 2.0 in a pdf, epub, or word file. Build a self-refreshing resource that re-refreshes the statistics, legal texts, tables, visualizations, footnotes and bibliography instead. This way you’ll have a greater impact: you’ll connect to global knowledge graphs, and your work can be reused much better.\nOur “smart document” is always live: it contains code that searches for data updates or changes in the law. It is a document that includes reproducible research code and makes sure that your document contains the latest information. It is a resource that, when uploaded to the web 3.0, cannot only be downloaded, but finds itself its audience, places itself into global libraries, data exchanges, automated websites.\n📊 Downloads or updates reliable statistical data, utilizing the SDMX standard, for example, Eurostat datasets, which is placed into your text as a table, a data visualization, and its source as a footnote and bibliographic citation.\n⚖️ Updates legal citations from Eur-LEX, i.e. contains the latest form of policy or legal documents, and flags for the researchers any important changes in the lifecycle of the citation (legal text goes out of force, amended, important court decisions get connected).\n🎨 Exchange cultural Digital Objects with Europeana or other cultural heritage or knowledge organizations, such as out-of-print books, music works, or 3D design objects.\nWe admit that at this point we mainly serve policy wonks or scientists who are very tech savvy. But we are working hard to package it into a highly usable end-user product.\nWhat is reproducible research? Reproducible research is what it is: it can be reproduced. Easier said than done. We create open source software that accompanies the entire research workflow, from the fieldwork or big data collector, downloading documents via the analysis, visualizations, citations, web dissemination and publication. We do all those little steps that computers do better than humans: logging, documenting, testing, validating, archiving. This allows our users to do what humans do best: think.\nOur data observatories are open scholarly platforms that support reproducible research. Our policy documents bring this functionality to your personal computer, and make it available for an NGO, a lawyer, a consultant, or an individual researcher.\nFeature list Each external resource, i.e. a policy document, a legal text, a cultural heritage object, a catalog entry, a dataset is clearly identified and downloaded, processed for the document into a footnote, citation, table or standard visualization.\nNew artifacts, such as visualizations, tables, receive a unique document object identifier (DOI) that clearly states their source, the person who oversaw the creation, the date, and the version.\nThese artifacts are added into the text in pre-defined places, such as the “Chart on GDP growth” placeholder containing the latest chart on GDP growth, while the citation in the bibliography contains the new version of the artifact (i.e. the chart with a DOI.)\nThe artifacts, such as datasets, tables, visualizations, codebooks, reference lists, are uploaded with a new version to an open science repository such as FigShare or Zenodo. This ensures that the creator’s intellectual rights are respected, and different, unauthorized versions of the table, chart, or other artifact in unknown news outlets, social media, are not connected to the creator or publisher.\nZenodo, via OpenAIRE, connects your work with global libraries, and if they meet the quality criteria, they are often immediately placed into the catalogues of global libraries. Our smart policy documents are not only uploaded onto the web, but connect to global knowledge graphs, or the web 3.0.\nThe author and publisher of the ‘smart policy document’ receives notifications of significant changes, i.e. non-trivial new data at Eurostat, or non-trivial connecting policy documents, court decisions, which should trigger a revision of the smart policy document’s textual contents. Needless to say, behind the scenes, we handle those trivial changes, too.\nAfter human review of the new version, it is created as Word docx, EPUB, and PDF file, and with a new version and DOI, it is uploaded to open science repositories that synchronize this publication with global library systems.\n","date":1662249600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662249600,"objectID":"648c4b0e3991171327d838573f8680cc","permalink":"https://reprex.nl/apps/smart-policy-documents/","publishdate":"2022-09-04T00:00:00Z","relpermalink":"/apps/smart-policy-documents/","section":"apps","summary":"Stop uploading your work onto the web 2.0 in a pdf, epub, or word file. Build a self-refreshing resource that re-refreshes the statistics, legal texts, tables, visualizations, footnotes and bibliography instead.  This way you’ll have a greater impact: you’ll connect to web 3.0 of the global knowledge graphs, and your work can be reused much better.","tags":["Smart Policy Documents"],"title":"Smart Policy Documents","type":"apps"},{"authors":null,"categories":null,"content":"We are building and ecosystem of open data, open software and trustworthy algorithms around our data observatories. We collaborate with scientific software developers, and their communities, such as rOpenGov. Our software tools have many thousand users, but they require coding skills. We will soon start to deploy more user-friendly applications that can be used by sustainability reporting professionals, or lawyers preparing factual green disclosures.\nOur Eviota project, which builds a multi-language reporting interface for preventing greenwashing. It will have a user-frontend for our environmental (and economic) impact assessment software tool, iotables. The iotables R package implements most of the functionality laid out in the economic and environmental input-output analysis features in the Eurostat and the respective UN statistical technical guidance on the topic.\nOur smart document are always alive: they contain code that searches for data updates or changes in the law. It is a document that includes reproducible research code and makes sure that your document contains the latest information. It is a resource that, when uploaded to the web 3.0, cannot only be downloaded, but finds itself its audience, places itself into global libraries, data exchanges, automated websites.\n","date":1661860320,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662249600,"objectID":"2f7b02f7e78d7d2d235bae3c09f9934f","permalink":"https://reprex.nl/apps/apps/","publishdate":"2022-08-30T13:52:00+02:00","relpermalink":"/apps/apps/","section":"apps","summary":"We are building and ecosystem of open data, open software and trustworthy algorithms around our data observatories. We collaborate with scientific software developers, and their communities, such as rOpenGov. Our software tools have many thousand users, but they require coding skills.","tags":["Apps"],"title":"Application Development","type":"apps"},{"authors":null,"categories":null,"content":" Reporting the impacts of the entire value chain. Our minimum viable product will create sustainability reports (or report components) for greenhouse gases and sustainable water use with applying the Global GHG Accounting \u0026amp; Reporting Standard for the Financial Industry and EFRAG’s proposed concept on connecting European accounting standards and information with sustainability. We will help small music organizations in their sustainability reporting, where detail data and reporting standards are only available for greenhouse gas emissions. The Music Eviota project is supported by the MusicAIRE.\nOpen collaboration Our project is based on open collaboration. Our proposal, if funded, will provide us with resources to supply further music businesses, music civil society organizations and researchers with high-quality data (during the duration of the project for free.) We are already looking for interested parties to put our data and research projects into use and validate their usability and quality in real-life policy or business development scenarios.\nWhy are we developing this service? The European Green Deal, which includes the proposed Corporate Sustainability Reporting Directive, and the sustainable finance package, aims to set the European economy on a permanent decarbonization and sustainability increasing path with adjusting the rules how economic activities are financed by bank loans, insurance, investments, and direct subsidies. From 2023, it will be cheaper to get loans, insurance, and other types of funding for organizations that can prove that they follow the environmental, social and governance path set out in the Paris Agreement and other UN, OECD, and EU agreements.\nRequirements for connecting financial and sustainability reporting. Correct and reliable sustainability management will come with many financial advantages and increased responsibility. The European Financial Reporting Advisory Board is currently preparing the new combined financial and sustainability reporting standard that will be used in banks, insurance, investment, granting, and the large companies of Europe in their entire supply and purchaser chain. The European Commission estimates that compliance costs until the end of 2023 will amount to 4 billion euros, with reporting and auditing costs mounting 10,000 euros per organization. While music small and medium sized organizations (MSMEs) and limited liability civil society organizations (CSOs) will be exempted from mandatory sustainability management and audited reporting, they can still comply in a non-audited and voluntary way.\nOur solution benefits the music MSMEs and CSOs in several ways:\nIt provides them with a size adequate sustainability management and reporting tool that helps first the management of greenhouse gas emissions, and later sustainable water use, pollutions, biodiversity, and recycling in their entire value chain (for example, it flags environmental risks in the supply base of a festival including equipment rentals, transport, security firms, catering facilities, etc.) by connecting standard accounting documents of the MSME with SNA and EEA science based benchmarks. Our system will be extendible to management of social sustainability. Our previous research shows that particularly the live music industry that needs a large workforce, suffers from underuse of, and discrimination of female workers in various technical and even managerial roles. Our system will be able to flag risks of gender paygap and related issues in the entire value chain and of course, provide good benchmarks for internal activities. Our review of the environmental, social and governance risk management (ESG sustainability management) suggests that complying with ESG standards is not only a pre-requisite to get cheaper loans (less important) and cheaper insurance (very important in live music), but also a requirement by corporate sponsors of events, and even a large part of the audience. While some music organizations already provide sustainability reporting, they are not standardized and are less factful as they are not connected to accounting information at every point. Our solution aims to give much credibility to both the sustainability reports and non-financial disclosures of the financial reports (which are not mandatory for MSMEs but increase their trustworthiness on an elective basis if they are included.)\nGrowing interest for ESG in select countries. ","date":1661860320,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662298740,"objectID":"678c7f4295bd07441d4fe712f17548bb","permalink":"https://reprex.nl/apps/eviota/","publishdate":"2022-08-30T13:52:00+02:00","relpermalink":"/apps/eviota/","section":"apps","summary":"Connected financial and sustainability reporting","tags":["Eviota"],"title":"Eviota","type":"apps"},{"authors":null,"categories":null,"content":"Greenwashing refers to false, misleading, overstated or unsubstantiated environmental advertising (e.g. marketing a product as “eco-friendly,” “safe for the environment”). Fighting climate change requires a fundamental change in consumer behavior supported by consumer protection. An important aspect of this change is fighting environmental misinformation, in other words, greenwashing labels that use vague, exaggerated, deceiving environmental attributes.\nConsumers must have trustworthy and accessible information to make sustainable choices, and they must be protected against unfair commercial practices. In the European Union, the Unfair Commercial Practices Directive (UCPD) has been amended with expanding the list of product characteristics about which a trader cannot mislead consumers to cover the environmental or social impact, as well as the durability and reparability. It also opened the door for adding new misleading practices on the basis of a case-by-case assessment. It also contains now a ‘black list’ of prohibited practices. Similar questions are raised in other jurisdictions, including the U.S. and the UK, where unfair practices can be challenged on either a consumer protection or competition law basis.\nOur aim is to develop a solid set of indicators that allow consumer protection agencies, including NGOs, and green journalists to factually challenge corporate and political greenwashing.\n","date":1661740320,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661740320,"objectID":"7daf5ccb3f40a74c7328bd7b91e143ae","permalink":"https://reprex.nl/project/greenwashing/","publishdate":"2022-08-29T04:32:00+02:00","relpermalink":"/project/greenwashing/","section":"project","summary":"Greenwashing refers to false, misleading, overstated or unsubstantiated environmental advertising. We want to help consumers and their agents to  challenge greenwashing with scientific facts.","tags":["Greenwashing"],"title":"Greenwashing","type":"project"},{"authors":["Daniel Antal"],"categories":[],"content":" Data Observatory 3.0 Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Shared evidence ecosystems: data observatories Organizations that cannot afford to build a large enough data team to sustain consistent, extensive data collection and processing (many large institutions and companies) Who cannot hire even a single data engineer or a data scientist Who do not even have a permanent IT function (about 2 million European small enterprises and civil organizations) What are data observatories? There are more than 60 functional, and about 20 already discontinued data observatories, i.e. long-term, usually triangular (business, academic, policy) data collection institutions recognized by the EU, OECD or UNESCO, including the European Observatory on Infringements of Intellectual Property Rights of the EU or the European Audiovisual Observatory of the Council of Europe. Do it Smarter They usually do not exchange standard data with statistical agencies, they are not synchronized on knowledge graphs of the Europeana or national libraries, and their research output is usually not to be found on open science repositories. The Hague is the winner of the World Smart City Award 2021, and we would like to attract the planned European Music Observatory and other, EU/UNESCO recognized institutions into the town building on the innovations of Reprex and the ecosystem of the Hague. Strategic objectives Develop our data observatories as Open Scholarly Infrastructure Place our Digital Music Observtory, Cultural and Creative Data Observatory, and Green Deal Data Observaotry on knowledge graphs of Europeana, Wikidata, and other open knowledge sytems Harmonize research artefacts with open repositories such as Zenodo and Figshare. Achieve EU/UNESCO/OECD recognition for our self-governing, triangular, science-policy-busines triangular data ecosystems as data observatories Digital Music Observatory Listen Local in Horizon Europe OpenMuse WP Diversity, Creative Europe MusicAIRE: connected and curated data on 10,000s of music works Our aim is to describe the entire, currently legally available music repertoire of Slovakia and Lithuania at first, and a large part of Ukraine. Connected with name authorities, web services. Possible Collaboration Connect national collective management organization, national library, and various services (Spotify, YouTube) to make the national repertoire more visible Create use statistics for cultural diversity policies and monitoring local content regulations Provide best practice example and open source tools for replication Creative and Cultural Sectors Industries Data Observatory Possible Collaboration The CCSI Data Observatory already has some data assets on Zenodo, and we can upgrade its API (both as Rest API with datacube and with a simple RDF serialization) Create use statistics for cultural heritage objects and other cultural heritage policy data Revisit some modest deliverables of RECREO and seek new funding. Green Deal Data Observatory Possible Collaboration The Green Deal Data Observatory is currently developed to provide free or very accessible environmental, social and governance reporting tools to the cultural sector. It could also be used to provide ecological context to cultural heritage objects (CHO) for greater awareness. Technical Features Reprex | Documentation\nFAIR FAIR metadata: Dublin Core \u0026amp; DataCite referential metadata Integration to FigShare and Zenodo for automated releases and publications Web 3.0 supported with optional, open source APIs to retrieve the data supported with RDF serialization Dissemination Support support automated publishing and releasing of data, visualizations, newsletters, and long-form documentation in auto-refreshing websites, blogposts, or articles, or even books. develop an ecosystem of open source software that helps the professional collection, processing, documentation of data conforming the Data Governance Act, and supporting data sharing and data altruism. Research Automation Research automation support research automation Questions? Email\nLinkedIn: Daniel Antal - Digital Music Observatory\n","date":1660737600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663657200,"objectID":"f4011ca4d158c7155520118018673205","permalink":"https://reprex.nl/slides/hague-innovation-award-2022/","publishdate":"2022-08-17T12:00:00Z","relpermalink":"/slides/hague-innovation-award-2022/","section":"slides","summary":"Discussion starter to contest the Hague Innovation Award.","tags":["Hague Innovators Award 2022"],"title":"Hague Innovators Award 2022","type":"slides"},{"authors":["Daniel Antal"],"categories":[],"content":"Big Data Creates Inequalities Only the largest corporations, best-endowed universities, and rich governments can afford data collection and processing capacities that are large enough to harness the advantages of AI.\nSlide navigation Fullscreen: F\nNext: \u0026gt; or Space | Previous: \u0026lt; Start: Home | Finish: End Overview: Esc| Speaker notes: S Zoom: Alt + Click Data problems The cost of questionnaire-based market research (survey) is increasing exponentially and offers mediocre results without an enormous question bank and harmonization with other surveys.(See 🖱 blogpost) Manual data acquisition is an error-prone and boring task for humans that requires many working hours (often not credited in consultancies, law firms, or research institutes.)\nWrangling spreadsheet tables or word processor documents by people without data knowledge is the 🖱 data Sisyphus.\nData observatories 3.0 Reprex is offering shared data ecosystems. Our observatories are great solutions for organizations without a data specialization:\n🌳 Organizations that cannot afford to build a large enough data team to sustain consistent, extensive data collection and processing (many large institutions and companies)\n🪴 Who cannot hire even a single data engineer or a data scientist (medium-sized companies, NGOs)\n🌱 Who do not even have a permanent IT function (about 2 million European small enterprises and civil society organizations)\nThe European Union, the World Bank, OECD, and UN have facilitated the creation of more than 80 so-called ‘data observatories’ to help companies, researchers, NGOs, and governments systematically collect data and knowledge.\nWe are currently building one prototype for the European Music Observatory financed by the European Union and music industry players (cc 3-4 million euros.) We would like to take over existing or start new observatories in 2 years at least 5)\nOur observatories are competitive, because they use high-quality open source scientific software; they exploit the new Data Governance Act and Open Data Directive, deploy web 3.0 data synchronization, and offer great value-added research products.\nPlatform products Value added data applications The European Union, the World Bank, OECD, and UN have facilitated the creation of more than 80 so-called ‘data observatories’ to help companies, researchers, NGOs, and governments systematically collect data and knowledge.\nThe different observatories offer different types of knowledge products, such as statistical yearbooks, various apps, and database access.\nMost of them use web 1.0 technologies, inefficient knowledge accumulation. Already 20 of them have been discontinued. We are developing software solutions that exploit our platforms: we harmonize surveys, statistical data, automate research reporting, elements of market monitoring or ESG reporting.\nWe are currently building one prototype for the European Music Observatory financed by the European Union and music industry players (cc 3-4 million euros.) We would like to take over existing or start new observatories in 2 years at least 5) Each observatory gives us intimidate customer access to 3-4 large universities, 1-2 large consultancies, and various specialist institutions. Marketing strategy Buma/Stemra like copyright management agencies, music export offices, festivals and venues, University of Amsterdam, Sant’Anna, Economic University of Bratislava, ministries of culture, grant agencies.\nUniversity of Amsterdam, Europeana, Sant’Anna, Hungarian Film Fund\nConnected financial and sustainability reporting: bank consultancies, big four audit companies, large environmental NGOs.\nAntitrust agencies, law firms, economics consultancies working with mergers and other competition related issues.\nTarget market size The observatory platforms usually have a build-up cost of about 3-5 million euros and an annual running costs of 0.1-3 million euros.\nSome of our basic products are included in the platform service. Our existing observatories give us access to the market and public surveying markets (cc 30-40 billion euros in the developed nations), particularly to its software component (about 10 billion euros). retroharmonize integrates pre-existing questionnaire-based surveys and new surveys. It is aimed at large, international survey companies (Kantar, Gfk) and large international survey programs (Eurostat, GESIS). regions improves the granularity of existing market research with ‘small area statistics’. Our existing observatories gave us access to environmental impact assessment and currently we build an ESG reporting tool with a central bank, a value bank, and a big four company. We hope to gain at least 10% global market share on the observatory platform management market to pay our basic data science team and R\u0026amp;D. Team The two co-founders, 🖱 Daniel Antal, CFA and 🖱 Andrés García Molina, PhD, and the core team manage the ecosystems’ development, develop knowledge management, and direct the software development. 🖱 Team on full …","date":1660737600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660737600,"objectID":"dd33e772709163995a8a615e2ac0ffb8","permalink":"https://reprex.nl/slides/data-observatory/","publishdate":"2022-08-17T12:00:00Z","relpermalink":"/slides/data-observatory/","section":"slides","summary":"Discussion starter to contest the Hague Innovation Award.","tags":["Digital Music Observatory","Hague Innovation Award 2022"],"title":"Slides","type":"slides"},{"authors":["Daniel Antal"],"categories":null,"content":"Interoperable, FAIR datasets The primary aim of dataset is create well-referenced, well-described, interoperable datasets from data.frames, tibbles or data.tables that translate well into the W3C DataSet definition within the Data Cube Vocabulary in a reproducible manner. The data cube model in itself is is originated in the Statistical Data and Metadata eXchange, and it is almost fully harmonzied with the Resource Description Framework (RDF), the standard model for data interchange on the web[^1].\nA mapping of R objects into these models has numerous advantages:\nMakes data importing easier and less error-prone; Leaves plenty of room for documentation automation, resulting in far better reusability and reproducability; The publication of results from R following the FAIR principles is far easier, making the work of the R user more findable, more accessible, more interoperable and more reusable by other users; Makes the placement into relational databases, semantic web applications, archives, repositories possible without time-consuming and costly data wrangling (See From dataset To RDF). Our package functions work with any structured R objects (data.fame, data.table, tibble, or well-structured lists like json), however, the best functionality is achieved by the (See The dataset S3 Class), which is inherited from data.frame().\nContact For contact information, contributors, see the package homepage.\nCode of Conduct Please note that the dataset project is released with a Contributor Code of Conduct. By contributing to this project, you agree to abide by its terms.\nClick the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. ","date":1660176000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660208400,"objectID":"26ed66c19df0a261920b3b3afb0f0370","permalink":"https://reprex.nl/software/dataset/","publishdate":"2022-08-11T00:00:00Z","relpermalink":"/software/dataset/","section":"software","summary":"Publish your datasets with FAIR metadata in open science repositories and place them on knowledge graphs","tags":["Reproducible research","SDMX","W3C","semantic web"],"title":"dataset: Create Interoperable FAIR Datasets","type":"software"},{"authors":["Daniel Antal"],"categories":null,"content":" Visit the documentation website of statcodelists on statcodelists.dataobservatory.eu/. The goal of statcodelists is to promote the reuse and exchange of statistical information and related metadata with making the internationally standardized SDMX code lists available for the R user. SDMX – the Statistical Data and Metadata eXchange has been published as an ISO International Standard (ISO 17369). The metadata definitions, including the codelists are updated regularly according to the standard. The authoritative version of the code lists made available in this package is https://sdmx.org/?page_id=3215/.\nPurpose Cross-domain concepts in the SDMX framework describe concepts relevant to many, if not all, statistical domains. SDMX recommends using these concepts whenever feasible in SDMX structures and messages to promote the reuse and exchange of statistical information and related metadata between organisations.\nCode lists are predefined sets of terms from which some statistical coded concepts take their values. SDMX cross-domain code lists are used to support cross-domain concepts. What are these cross-domain coded concepts?\nGeographical codes, like NL: the Netherlands in the CL_AREA code list. Standard industry codes J631 for Data processing, hosting and related activities in Europe. (NACE Rev 2 in Europe, beware, it is J592in Australia and New Zealand, see CL_ACTIVITY_ANZSIC06.) Occupations, like OC2521 for Database designers and administrators in CL_OCCUPATIONS Time fomatting standards, like CCYY for annual data series in CL_TIME_FORMAT. Check out the available codlists on the package homepage.\nThe use of common code lists will help users to work even more efficiently, easing the maintenance of and reducing the need for mapping systems and interfaces delivering data and metadata to them. A very obvious advantage of using the code systems is that you can retrieve data from national sources indifferent of the natural language used in North Macedonia, Japan, the U.S. or the Netherlands. While the data labels may change to be locally human-readable, computers and geeks can read the codes and understand them immediately. Provided that they use the standard codes.\nOur data observatories are rolling out SDMX coding across all datasets to help data ingestion and interoperability, data findability and data reuse. statcodelists can help the use of standard SDMX codes in your R workflow–both for downloading data from statistical agencies and to produce publication-ready datasets that the rest of the world (and even APIs) will understand.\nInstallation You can install statcodelists from CRAN:\ninstall.packages(\u0026#34;statcodelists\u0026#34;) Further recommended code values for expressing general statistical concepts like not applicable, etc., can be found in section Generic codes of the Guidelines for the creation and management of SDMX Cross-Domain Code Lists.\nFor further codelists used by reliable statistical agency but not harmonized on SDMX level please consult the SDMX Global Registry Codelists page.\nThe creator of this package is not affiliated with SDMX, and this package was has not been endorsed by SDMX.\nCode of Conduct Please note that the statcodelists project is released with a Contributor Code of Conduct. By contributing to this project, you agree to abide by its terms.\n","date":1656486720,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656486720,"objectID":"93e74f22e59182e38c653816a3412e7d","permalink":"https://reprex.nl/post/2022-06-29-statcodelists/","publishdate":"2022-06-29T08:12:00+01:00","relpermalink":"/post/2022-06-29-statcodelists/","section":"post","summary":"A new building block of our observatories went through code peer review and was released yesterday. The statcodelists R package aim to promote the  reuse and exchange of statistical information and related metadata with making the internationally standardized SDMX code lists available for the R user.","tags":["R","metadata","statistics","SDMX"],"title":"stacodelists: use standard, language-independent variable codes to help international data interoperability and machine reuse in R","type":"post"},{"authors":["Daniel Antal"],"categories":null,"content":"Retrospective data harmonization The aim of retroharmonize is to provide tools for reproducible retrospective (ex-post) harmonization of datasets that contain variables measuring the same concepts but coded in different ways. Ex-post data harmonization enables better use of existing data and creates new research opportunities. For example, harmonizing data from different countries enables cross-national comparisons, while merging data from different time points makes it possible to track changes over time.\nRetrospective data harmonization is associated with challenges including conceptual issues with establishing equivalence and comparability, practical complications of having to standardize the naming and coding of variables, technical difficulties with merging data stored in different formats, and the need to document a large number of data transformations. The retroharmonize package assists with the latter three components, freeing up the capacity of researchers to focus on the first.\nSpecifically, the retroharmonize package proposes a reproducible workflow, including a new class for storing data together with the harmonized and original metadata, as well as functions for importing data from different formats, harmonizing data and metadata, documenting the harmonization process, and converting between data types. See here for an overview of the functionalities.\nThe new labelled_spss_survey() class is an extension of haven’s labelled_spss class. It not only preserves variable and value labels and the user-defined missing range, but also gives an identifier, for example, the filename or the wave number, to the vector. Additionally, it enables the preservation – as metadata attributes – of the original variable names, labels, and value codes and labels, from the source data, in addition to the harmonized variable names, labels, and value codes and labels. This way, the harmonized data also contain the pre-harmonization record. The stored original metadata can be used for validation and documentation purposes.\nThe vignette Working With The labelled_spss_survey Class provides more information about the labelled_spss_survey() class.\nIn Harmonize Value Labels we discuss the characteristics of the labelled_spss_survey() class and demonstrates the problems that using this class solves.\nWe also provide three extensive case studies illustrating how the retroharmonize package can be used for ex-post harmonization of data from cross-national surveys:\nAfrobarometer Arab Barometer Eurobarometer The creators of retroharmonize are not affiliated with either Afrobarometer, Arab Barometer, Eurobarometer, or the organizations that designs, produces or archives their surveys.\nWe started building an experimental APIs data is running retroharmonize regularly and improving known statistical data sources. See: Digital Music Observatory, Green Deal Data Observatory, Economy Data Observatory.\nCitations and related work Citing the data sources Our package has been tested on three harmonized survey’s microdata. Because retroharmonize is not affiliated with any of these data sources, to replicate our tutorials or work with the data, you have download the data files from these sources, and you have to cite those sources in your work.\nAfrobarometer data: Cite Afrobarometer Arab Barometer data: cite Arab Barometer. Eurobarometer data: The Eurobarometer data Eurobarometer raw data and related documentation (questionnaires, codebooks, etc.) are made available by GESIS, ICPSR and through the Social Science Data Archive networks. You should cite your source, in our examples, we rely on the GESIS data files.\nCiting the retroharmonize R package For main developer and contributors, see the package homepage.\nThis work can be freely used, modified and distributed under the GPL-3 license:\ncitation(\u0026#34;retroharmonize\u0026#34;) #\u0026gt; #\u0026gt; To cite package \u0026#39;retroharmonize\u0026#39; in publications use: #\u0026gt; #\u0026gt; Daniel Antal (2021). retroharmonize: Ex Post Survey Data #\u0026gt; Harmonization. R package version 0.1.17. #\u0026gt; https://retroharmonize.dataobservatory.eu/ #\u0026gt; #\u0026gt; A BibTeX entry for LaTeX users is #\u0026gt; #\u0026gt; @Manual{, #\u0026gt; title: {retroharmonize: Ex Post Survey Data Harmonization}, #\u0026gt; author: {Daniel Antal}, #\u0026gt; year: {2021}, #\u0026gt; doi: {10.5281/zenodo.5006056}, #\u0026gt; note: {R package version 0.1.17}, #\u0026gt; url: {https://retroharmonize.dataobservatory.eu/}, #\u0026gt; } Contact For contact information, contributors, see the package homepage.\nCode of Conduct Please note that the retroharmonize project is released with a Contributor Code of Conduct. By contributing to this project, you agree to abide by its terms.\nClick the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. ","date":1656374400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660201200,"objectID":"cfc0014323d64a4fbf879405539ea261","permalink":"https://reprex.nl/software/statcodelists/","publishdate":"2022-06-28T00:00:00Z","relpermalink":"/software/statcodelists/","section":"software","summary":"The goal of retroharmonize is to facilitate retrospective (ex-post) harmonization of data, particularly survey data, in a reproducible manner.","tags":["statcodelists"],"title":"statcodelists: Use Standardized Statistical Codelists","type":"software"},{"authors":["Daniel Antal"],"categories":null,"content":"The music sector must increase its environmental and social (ESG) sustainability management to meet the challenges of the climate emergency and to make the music sector a fairer, more just workplace for womxn and artists coming from minorities, small countries. The European Union will make target setting and audited reporting mandatory in environmental and social sustainability for large companies. The application of these new accounting, reporting and disclosure rules are optional for the music sector where almost all entities are micro-, or small enterprises and civil society organizations.\nEven if music organizations are not pushed by regulators to adopt these new standards, it is in their best interest to take the initiative on the principle of subsidiarty, and develop tools that can be applied as an extension to their simplified financial and tax reporting. Music organizations and businesses that can prove that they are making progress in reducing their carbon footprint, making their water use more sustainable, and they provide equal opportunities for womxn, they will be eligible for new, green bank and insurance products (which are particularly important in live music) and can attract new sponsors and donors.\nCompliance with these new rules is very costly, because tools are being developed for stock-exchange listed big companies and financial institutions. The Commission’s impact assessment (SWD/2021/150 final) estimates the cost of compliance with the Corporate Social Responsibility Directive exceeding 4 bn euros for the European companies or around 10,000 euros per company. Reprex, working together with large accounting, audit and value-based banking partners, scientific, research and industry partners in the Digital Music Observatory open knowledge collaboration, hopes to bring down this cost below 500 euros, which will immediately pay off when a music organization receives green money.\nWe are working on a simple interface that can connect the accounting system of micro and small enterprises with new methodologies, starting with greenhouse gas reporting with Reprex’s open source EEIO application iotables. We will keep many aspects of our software and data solution open, so that later methodological innovations and scientific achievements can be easily incorporated into the system. Reprex’s minimum viable product will be created in four iteration rounds in Malta, Czechia, Bulgaria and Belgium. However, our testing is open for any amount of donations to any music entities in the European Union who can provide input data in English or Dutch, or be able to pay for their translation and localization costs.\nLink: Final List of Awareded Projects by MusicAIRE\n","date":1654764000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654764000,"objectID":"8e9cf4f3e538581e9473e776d4a734d0","permalink":"https://reprex.nl/post/2022-06-09-music-eviota/","publishdate":"2022-06-09T09:40:00+01:00","relpermalink":"/post/2022-06-09-music-eviota/","section":"post","summary":"We are working on a simple interface that can connect the accounting system of micro and small enterprises with new methodologies, starting with greenhouse gas reporting with Reprex’s open source EEIO application [iotables](https://iotables.dataobservatory.eu/) after receiving a competitive grant from [MusicAIRE](https://musicaire.eu/).","tags":["Eviota","European Green Deal","MusicAIRE"],"title":"Developing a software-as-service solution for micro-, and small enterprises","type":"post"},{"authors":null,"categories":null,"content":" Reporting the impacts of the entire value chain. Our minimum viable product will create sustainability reports (or report components) for greenhouse gases and sustainable water use with applying the Global GHG Accounting \u0026amp; Reporting Standard for the Financial Industry and EFRAG’s proposed concept on connecting European accounting standards and information with sustainability. We will help small music organizations in their sustainability reporting, where detail data and reporting standards are only available for greenhouse gas emissions. The Music Eviota project is supported by the MusicAIRE.\nOpen collaboration Our project is based on open collaboration. Our proposal, if funded, will provide us with resources to supply further music businesses, music civil society organizations and researchers with high-quality data (during the duration of the project for free.) We are already looking for interested parties to put our data and research projects into use and validate their usability and quality in real-life policy or business development scenarios.\nWhy are we developing this service? The European Green Deal, which includes the proposed Corporate Sustainability Reporting Directive, and the sustainable finance package, aims to set the European economy on a permanent decarbonization and sustainability increasing path with adjusting the rules how economic activities are financed by bank loans, insurance, investments, and direct subsidies. From 2023, it will be cheaper to get loans, insurance, and other types of funding for organizations that can prove that they follow the environmental, social and governance path set out in the Paris Agreement and other UN, OECD, and EU agreements.\nRequirements for connecting financial and sustainability reporting. Correct and reliable sustainability management will come with many financial advantages and increased responsibility. The European Financial Reporting Advisory Board is currently preparing the new combined financial and sustainability reporting standard that will be used in banks, insurance, investment, granting, and the large companies of Europe in their entire supply and purchaser chain. The European Commission estimates that compliance costs until the end of 2023 will amount to 4 billion euros, with reporting and auditing costs mounting 10,000 euros per organization. While music small and medium sized organizations (MSMEs) and limited liability civil society organizations (CSOs) will be exempted from mandatory sustainability management and audited reporting, they can still comply in a non-audited and voluntary way.\nOur solution benefits the music MSMEs and CSOs in several ways:\nIt provides them with a size adequate sustainability management and reporting tool that helps first the management of greenhouse gas emissions, and later sustainable water use, pollutions, biodiversity, and recycling in their entire value chain (for example, it flags environmental risks in the supply base of a festival including equipment rentals, transport, security firms, catering facilities, etc.) by connecting standard accounting documents of the MSME with SNA and EEA science based benchmarks. Our system will be extendible to management of social sustainability. Our previous research shows that particularly the live music industry that needs a large workforce, suffers from underuse of, and discrimination of female workers in various technical and even managerial roles. Our system will be able to flag risks of gender paygap and related issues in the entire value chain and of course, provide good benchmarks for internal activities. Our review of the environmental, social and governance risk management (ESG sustainability management) suggests that complying with ESG standards is not only a pre-requisite to get cheaper loans (less important) and cheaper insurance (very important in live music), but also a requirement by corporate sponsors of events, and even a large part of the audience. While some music organizations already provide sustainability reporting, they are not standardized and are less factful as they are not connected to accounting information at every point. Our solution aims to give much credibility to both the sustainability reports and non-financial disclosures of the financial reports (which are not mandatory for MSMEs but increase their trustworthiness on an elective basis if they are included.)\nGrowing interest for ESG in select countries. Green Recovery in the Music Sector Co-funded by the European Union The objectives of the MusicAIRE GREEN recovery program is increasing the music sector’s environmental sustainability and ecological awareness with a view to greening the music industry, in particular live acts, festivals and touring, as well as supporting innovative start-ups aiming at decreasing the environmental footprint of online data storing and music distribution.\nCo-funded by the European Union ","date":1654764000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662280800,"objectID":"4515fe136aff6e90d9d1d2ab83d5ef20","permalink":"https://reprex.nl/project/musiceviota/","publishdate":"2022-06-09T09:40:00+01:00","relpermalink":"/project/musiceviota/","section":"project","summary":"We will help small music organizations in their sustainability reporting, where detail data and reporting standards are only available for greenhouse gas emissions.","tags":["Sustainability","European Green Deal","MusicAIRE"],"title":"Music Eviota","type":"project"},{"authors":["Daniel Antal"],"categories":null,"content":"Currently almost 60% of the global recording industry sales are made via streaming platforms. Given the enormity of choice on these platforms, and that music listening is a low-key, routine consumption choice, consumers are more and more relying on the recommendations of autonomous recommendation systems. Streaming platforms are two-sided markets, where recommendations are deployed to enhance the user experience on the consumer side, but they also decide the fate of the investments that composers, lyricists, producers, and performers made into the music. We are going to contribute to a research on how such systems may lead to potentially tilted competition field between the content providers, and more specifically, between major labels and independents.\nReprex maintains the Digital Music Observatory and the Listen Local system for granular microdata about music use in small territories (i.e., on small country or sub-national level.) We will provide data/expertise in music streaming and recommendation systems and links to many relevant stakeholders with our considerable experience running experiments on music platforms.\nA research team of the University of East Anglia (UEA) the University of Liverpool (UoL), The University of London (City), and King’s College (KCL), supported by the Competition Market Authority of the United Kingdom and Reprex won a prestigious research grant to understand how recommender systems on music streaming platforms can employ trustworthy AI.\nThe researchers will explore the relationship between the autonomous recommendation systems and entry barriers via simulation. Working closely with Reprex, they will simulate sets of users, and iteratively generate recommendation lists, which the simulated users will react to by deciding how long to engage for and which recommendations to listen to. Through their engagement their user profiles will be updated based on what they listen to which will feed into future recommendations.\nSee our Feasibility Study for Listen Local. The empirical experiments of the project want to explore how autonomous recommendation systems are driving consumer choice in a real-life setting, and to establish causality between the recommendation systems and the barrier to entry. As part of the second work package, the researchers will conduct randomised trials by inviting participants to stream music through our own user interface. Reprex has extensive experience conducting similar experiments in the music domain (for various online, field experiments, and high-quality surveys.)\nLink: Eight new TAS research projects announced\n","date":1646071200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646071200,"objectID":"f2ddcadb7a6dcaf889a6eedf6f2d7ffa","permalink":"https://reprex.nl/post/2022-02-28-tas/","publishdate":"2022-02-28T19:00:00+01:00","relpermalink":"/post/2022-02-28-tas/","section":"post","summary":"Almost 60% of the global recording industry sales are made via streaming platforms. Given the enormity of choice on these platforms consumers are more and more relying on the recommendations of autonomous recommendation systems. But these recommendation systems do not only enhance the user experience on the consumer side, but they also decide the fate of the investments that composers, lyricists, producers, and performers made into the music. We are going to contribute to a research on how such systems may lead to potentially tilted competition field between the content providers, and more specifically, between major labels and independents.","tags":["Listen Local","Music Data Observatory"],"title":"Trustworthy Autonomous Recommender Systems on Music Streaming Platforms","type":"post"},{"authors":null,"categories":null,"content":"Our ambition is to truly maximize transparency, (re)usability, scientific, policy, and business impact while embracing the best practices laid out in the the recommendations of the Reproducibility of scientific results scoping report, and the Progress on Open Science: Towards a Shared Research Knowledge System policy documents of the European Commission’s DG Research \u0026amp; Innovation, as well as the best practices outlined in the evidence-based Knowledge4Policy K4P platform of the European Commission.\nFor the first time in Europe, we will apply and contextualize the Open Policy Analysis Guidelines (OPA Guidelines) in our OpenMuse project.\nThe Open Policy Analysis Guidelines grew out of several initiatives in research transparency with the aim of maximizing benefits in the context of the Foundations for Evidence-based Policy Making Act of 2018 initiative in the United States. We want to ensure that by relying not only on the best European practices, but considering trans-Atlantic experiences, we will make the most out of the opportunities offered by the European Open Data Directive of 2019. This will not only mean rendering a dramatically increased data availability for our partners, as well as increased quality assurance and transparency in our work, but also immediate data access.\nOur new software will continue to run in the cloud, depositing all of our findings—Findable, Accessible, Interoperable and Reuseable digital assets, including our well-designed and user-tested indicators in 41 data gap fields—into our Digital Music Observatory, which already hosts a modern REST API similar to the Eurostat Rest API.\nLayer Goal Target Example Open Output Ensure unified output We comply with the level 3 requirements and we will create a showcase how to do this best following EU open science recommendations. See our example. Open Output Establish a clear link between input and output We will produce more than 100 outputs, some only as indicators, and others in form of policy analysis, we will comply with level 1,2,3 as necessary. Our affiliated music industry partners will create cases studies with interactive tools (level 3). See our Slovak case study which came with a Shiny App that analyzed music recommendations. Open Analysis Provide clear accounts of all methodological procedures in a way that is easily interpreted by an informed reader. We accomplish level 3 with placing the code in clearly documented. into a dynamic document, or open notebook See for example our blogpost on automatic forecasting for the music industry. Open Analysis Share raw (or analytic) data and materials in a way that the analysis is reproducible with minimal effort. We will accomplish level 3 through trusted repositories following EU recommendations. We will use the Zenodo repository developed by CERN and the EU’s OpenAIRE project. See our solution on Zenodo. Open Analysis Share an open report that includes clear accounts of all methodological procedures, data, and assumptions. We would like to go beyond the level 3 requirements of the OPA with using standardized documentation languages, such as SDMX statistical metadata and its standardized codebooks, and comply with both Dublin Core and DataCite extended, recommended standarized reporing. See our example An Empirical Analysis of Music Streaming Revenues and Their Distribution created for the UK Intellectual Property Office’s evidence-based policy effort in music streaming. Open Materials Standardize the file structure so that materials are organized in a way that is accessible to an informed reader. We comply with the level 3 requirements. Our versioned controled output is on Github. See an example on Github. Open Materials Label and document each input, including data, research, and guesswork. We will go beyond level 3 requirements, because we want to make sure that our labelling and documentation is interopreable, and we apply various metadata standards for this purpose. See our example explaining how we document our datasets in our API. Open Materials Ensure that code/spreadsheets are reproducible. All our spreadsheets are machine generated for the convenience of the user who uses spreadsheet applications, but everything can be run with a click, which accomplishes level 3, and maintains the convenience of level 1-2 for the user. We go further with creating authoritative copies of each dataset and visualization with DOIs. We also produce an API which gives programatic or single table access to both the data and standardized codebooks. See our API. All our datasets are described in detail on Zenodo and Figshare, too. Open Materials Use a version control strategy. We use Git version control, and we employ various repositories and project documentation tools on Github. These are linked with the Zenodo EU open repository and our data API. See our example intergration. ","date":1644156000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661781720,"objectID":"df7b1ac9366aaf6623379b30b637c665","permalink":"https://reprex.nl/project/opa/","publishdate":"2022-02-06T14:00:00Z","relpermalink":"/project/opa/","section":"project","summary":"Open Policy Analysis is an approach to policy analysis wherein data, code, materials, and clear accounts of methodological decisions are made freely available to facilitate collaboration, discussion, and reuse.","tags":["Open Policy Analysis","Open Science","Open Government"],"title":"Open Policy Analysis","type":"project"},{"authors":["Daniel Antal"],"categories":null,"content":" Get started with iotables. We made an important, peer-reviewed release of iotables in the last week as a preparation to increase the functionality of our open-source software. The official release of the iotables R package currently works with economic impact assessments, and can evaluate the likely employment, tax, wage, or gross value added direct, indirect and multiplied impacts of various policy changes in about 30 countries.\nOriginally the package was developed to calculate the economic impact of the Hungarian film tax shelter and the impact of the music sector on the Slovak economy. (See Slovak Music Industry Report).\nThe new CRAN release improved the documentation of the function and removed most outdated dependencies. The new, development version (which did not go through peer-review yet) is adding new functionality for environmental impact analysis with the following pollutants: Carbon dioxide without emissions from biomass (CO2), Carbon dioxide from biomass (Biomass CO2), Nitroux oxide (N2O), Methane (CH4), Perfluorocarbons (PFCs), Hydrofluorocarbons (HFCs), Sulphur hexafluoride (SF6) including nitrogen trifluoride (NF3), Nitrogen oxides (NOx), Non-methane volatile organic compounds, (NMVOC), Carbon monoxide (CO), Particulate matter \u0026lt; 10μm (PM10), Particulate matter \u0026lt; 2,5μm (PM2,5), Sulphur dioxide (SO2), Ammonia (NH3) and their combinations (see Reference Metadata in Euro SDMX Metadata Structure (ESMS)).\nOur aim is to develop new sustainable finance applications, and understand the sustainability impacts of bank’s lending activities and insurer’s underwriting activities on climate change mitigation and adoption, biodiversity, preservation of water reservers, preventing pollution, and promoting the circular economy.\nEU Taxonomy on Sustainable Activities The European Commission created an created an EU Taxonomy Compass, which provides a visual representation of the contents of the EU Taxonomy, starting with the Delegated Act on the climate objectives, as adopted on 4 June 2021. Whilst you can download the EU Taxonomy in xlsx or json format, they are not tidy datasets, and they are not particularly well-suited for calculations, filtering, or inclusion in applications.\nReprex created a tidy version of the EU Taxonomy for developing better sustainability indicators into the Green Deal Data Observatory.\nOpen Data EU Taxonomy on Sustainable Activities (Tidy) download. Using our iotables is not for the faint heart. It is a scientific software, and it requires a good command of national accounts, input-output economics and sustainability to work with. Our Green Deal Data Observaotry is designed to be an API of scientific software, and produce clean, ready to use data for researchers, policy-makers and business planners who do not have the skills to work with scientific software. We are planning to release well-designed datasets that go through dozens of checks to make sure they have the best data quality.\nDo you want to develop input-output models for any European country to measure the direct and indirect green house gas impacts of policy actions? Do you need well-formatted data on interindustry linkages or other relevant topics for sustainable economy or susitainable finance research? Get in touch with us – we are happy to help and test our new software tool with data you need, and create high-quality, open datasets that are ready to use. ","date":1639915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639915200,"objectID":"535301e8342269d5861d04d0ccd83468","permalink":"https://reprex.nl/post/2021-12-20-environmental_impact/","publishdate":"2021-12-19T13:00:00+01:00","relpermalink":"/post/2021-12-20-environmental_impact/","section":"post","summary":"We made an important, peer-reviewed release of iotables in the last week as a preparation to increase the functionality of our open-source software. This release of the iotables R package currently works with economic impact assessments, and can evaluate the likely employment, tax, wage, or gross value added direct, indirect and multiplied impacts of various policy changes in about 30 countries. The new, development version (which did not go through peer-review yet) is adding new functionality for environmental impact analysis with the following pollutants and will be connected to the EU Taxonomy on sustainable economic activities.","tags":["iotables","Green Deal Data Observatory","Sustainability","EU Taxonomy"],"title":"Reproducible Economic Impact Assessment","type":"post"},{"authors":["Daniel Antal"],"categories":null,"content":"Our Digital Music Observatory project spent a year in the JUMP Music Market Accelerator’s program. Over the course of 9 months, co-founder Daniel Antal could meet many stakeholders from almost all European countries, meet other new music technology startups and projects, and got mentoring and other professional help to further develop the project.\nThe Digital Music Observatory is one of the several initiatives to fill the data gaps of the fragmented European music ecosystems. While most of Europe’s music is available and promoted on data-heavy, AI-driven autonomous platforms like TikTok, Spotify, YouTube, Deezer, music labels, publishers, national export offices are lacking the necessary data solutions to remain competitive.\nDaniel is pitching for partnership with Music Tech Europe on Linechech and finding a music city that wants to be the seat of the future European Music Observatory. Photo: Wen Liu. One of the recurring themes of 2021 was the notion that the music streaming economy is broken. Several JUMP fellows are working on various projects that aim to fix this, and our Digital Music Observatory has both the data and track record to provide evidence and test ideas about possible solutions – change in pricing, better targeting in export and domestic markets, and checking for algorithmic biases. See what we have done in the field this year in the UK IPO-initiated Music Creators’ Earning project; understanding algorithmic recommendation problems with the support of the Slovak Arts Council, and making recommendations about better music metadata and copyright regulation with our research consortium.\nThe other very interesting theme of the year was the emergence of new, immersive music tech companies. We hope that our Digital Music Observatory can grow into a hub for their data needs, too. How is the world of 2.7 billion gamer and music lovers is forming a new market for Ristband? We would also like to curate data about the healing effects of sound, and work in the future with immersive, functional music providers like Flower of Sound who place music and sound design into a less stressful, more healthy acoustic environment.\nWe were often criticized for placing too little emphasis on data visualization. Our next priority is to provide clear, beautiful infographs and charts to all of our datasets.\nThere were many professionals who helped us in the JUMP program. We are particularly thankful for Alessanra di Caro (partnership building), Elodie Crouzet (program coordination), Steve Farris (mentoring), Veronique Friedrich (team building), Thierry Giesler (improving our pitch) and Anna Zò (Music Tech Europe).\nAre you a data user? Give us some feedback! Shall we do some further automatic data enhancements with our datasets? Document with different metadata? Link more information for business, policy, or academic use? Please ive us any feedback!\n","date":1638446400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638446400,"objectID":"0a43fca75023baf13537aa6acd3d91a3","permalink":"https://reprex.nl/post/2021-12-02-dmo-jump/","publishdate":"2021-12-02T13:00:00+01:00","relpermalink":"/post/2021-12-02-dmo-jump/","section":"post","summary":"Our Digital Music Observatory project spent a year in the JUMP Music Market Accelerator's program. Over the course of 9 months, co-founder Daniel Antal could meet many stakeholders from almost all European countries, meet other new music technology startups and projects, and got mentoring and other professional help to further develop the project.","tags":["JUMP","Digital Music Observatory","music streaming","data visualization"],"title":"Jumping Ahead With the Digital Music Observatory","type":"post"},{"authors":["Daniel Antal"],"categories":null,"content":"In this example, we show a simple indicator: the Turnover in Radio Broadcasting Enterprises in many European countries. This is an important demand driver in the Music economy pillar of our Digital Music Observatory, and important indicator in our more general Cultural \u0026amp; Creative Sectors and Industries Observatory. Of course, if you work with competition policy or antitrust, than any industry may be interesting to you–but not all of them are well-serverd with data.\nThis dataset comes from a public datasource, the data warehouse of the European statistical agency, Eurostat. Yet it is not trivial to use: unless you are familiar with national accounts, you will not find this dataset on the Eurostat website.\nThe data can be retrieved from the Annual detailed enterprise statistics for services NACE Rev.2 H-N and S95 Eurostat folder. Our version of this statistical indicator is documented following the FAIR principles: our data assets are findable, accessible, interoperable, and reusable. While the Eurostat data warehouse partly fulfills these important data quality expectations, we can improve them significantly. And we can also improve the dataset, too, as we will show in the next blogpost.\nTable of Contents Findable Data Accessible Data Interoperability Reuse Findable Data Our data observatories add value by curating the data–we bring this indicator to light with a more descriptive name, and we place it in a domain-specific context with our Digital Music Observatory and Cultural \u0026amp; Creative Sectors and Industries Observatory and a policy-specific context with our Competition Data Observatory and Green Deal Data Observatory. While many people may need this dataset in the creative sectors, or among cultural policy designers, most of them have no training in working with national accounts, which imply decyphering national account data codes in records that measure economic activity at a national level. Our curated data observatories bring together many available data around important domains. Our Digital Music Observatory, for example, aims to form an ecosystem of music data users and producers.\nWe added descriptive metadata that help you find our data and match it with other relevant data sources. We added descriptive metadata that help you find our data and match it with other relevant data sources. For example, we add keywords and standardized metadata identifiers from the Library of Congress Linked Data Services, probably the world’s largest standardized knowledge library description. This ensures that you can find relevant data around the same key term (\u0026#34;Radio broadcasting\u0026#34;) in addition to our turnover data. This allows connecting our dataset unambiguously with other information sources that use the same concept, but may be listed under different keywords, such as Radio–Broadcasting, or Radio industry and trade, or maybe Hörfunkveranstalter in German, or Emitiranje radijskog programa in Croatian or Actividades de radiodifusão in Portugese.\nAccessible Data Our data is accessible in two forms: in csv tabular format (which can be read with Excel, OpenOffice, Numbers, SPSS and many similar spreadsheet or statistical applications) and in JSON for automated importing into your databases. We can also provide our users with SQLite databases, which are fully functional, single user relational databases.\nTidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This makes the data easier to clean, and far more easier to use in a much wider range of applications than the original data we used. In theory, this is a simple objective, yet we find that even governmental statistical agencies–and even scientific publications–often publish untidy data. This poses a significant problem that implies productivity loses: tidying data will require long hours of investment, and if a reproducible workflow is not used, data integrity can also be compromised: chances are that the process of tidying will overwrite, delete, or omit a data or a label.\nTidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. While the original data source, the Eurostat data warehouse is accessible, too, we added value with bringing the data into a tidy format. Tidy data can immediately be imported into a statistical application like SPSS or STATA, or into your own database. It is immediately available for plotting in Excel, OpenOffice or Numbers.\nInteroperability Our data can be easily imported with, or joined with data from other internal or external sources.\nAll our indicators come with standardized descriptive metadata, and statistical (processing) metadata. See our API All our indicators come with standardized descriptive metadata, following two important standards, the Dublin Core and …","date":1636362000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636362000,"objectID":"0f375332304d9b26d06a73003cca93bd","permalink":"https://reprex.nl/post/2021-11-08-indicator_findable/","publishdate":"2021-11-08T09:00:00Z","relpermalink":"/post/2021-11-08-indicator_findable/","section":"post","summary":"Many people ask if we can really add value to free data that can be downloaded from the Internet by anybody. We do not only work with easy-to-download data, but we know that free, public data usually requires a lot of work to become really valuable. To start with, it is not always easy to find.","tags":["Radio broadcasting","FAIR","Metadata","Data interoperability","Documentation","Data curation"],"title":"How We Add Value to Public Data With Better Curation And Documentation?","type":"post"},{"authors":["Daniel Antal"],"categories":null,"content":"Public data sources are often plagued by missng values. Naively you may think that you can ignore them, but think twice: in most cases, missing data in a table is not missing information, but rather malformatted information. This approach of ignoring or dropping missing values will not be feasible or robust when you want to make a beautiful visualization, or use data in a business forecasting model, a machine learning (AI) applicaton, or a more complex scientific model. All of the above require complete datasets, and naively discarding missing data points amounts to an excessive waste of information. In this example we are continuing the example a not-so-easy to find public dataset.\nIn the previous blogpost we explained how we added value by documenting data following the FAIR principle and with the professional curatorial work of placing the data in context, and linking it to other information sources, such as other datasets, books, and publications, regardless of their natural language (i.e., whether these sources are described in English, German, Portugese or Croatian). Photo: Jack Sloop. Completing missing datapoints requires statistical production information (why might the data be missing?) and data science knowhow (how to impute the missing value.) If you do not have a good statistician or data scientist in your team, you will need high-quality, complete datasets. This is what our automated data observatories provide.\nTable of Contents Why is data missing? What can we improve? Can you trust our data? Avoid the data Sisyphus Get the data How can we do better? Why is data missing? International organizations offer many statistical products, but usually they are on an ‘as-is’ basis. For example, Eurostat is the world’s premiere statistical agency, but it has no right to overrule whatever data the member states of the European Union, and some other cooperating European countries give to them. And they cannot force these countries to hand over data if they fail to do so. As a result, there will be many data points that are missing, and often data points that have wrong (obsolete) descriptions or geographical dimensions. We will show the geographical aspect of the problem in a separate blogpost; for now, we only focus on missing data.\nSome countries have only recently started providing data to the Eurostat umbrella organization, and it is likely that you will find few datapoints for North Macedonia or Bosnia-Herzegovina. Other countries provide data with some delay, and the last one or two years are missing. And there are gaps in some countries’ data, too.\nSee the authoritative copy of the dataset. This is a headache if you want to use the data in some machine learning application or in a multiple or panel regression model. You can, of course, discard countries or years where you do not have full data coverage, but this approach usually wastes too much information–if you work with 12 years, and only one data point is available, you would be discarding an entire country’s 11-years’ worth of data. Another option is to estimate the values, or otherwise impute the missing data, when this is possible with reasonable precision. This is where things get tricky, and you will likely need a statistician or a data scientist onboard.\nWhat can we improve? Consider that the data is only missing from one year for a particular country, 2015. The naive solution would be to omit 2015 or the country at hand from the dataset. This is pretty destructive, because we know a lot about the radio market turnover in this country and in this year! But leaving 2015 blank will not look good on a chart, and will make your machine learning application or your regression model stop.\nA statistician or a radio market expert will tell you that you know more-or-less the missing information: the total turnover was certainly not zero in that year. With some statistical or radio domain-specific knowledge you will use the 2014, or 2016 value, or a combination of the two and keep the country and year in the dataset.\nOur improved dataset added backcasted (using the best time series model fitting the country’s actually present data), forecasted (again, using the best time series model), and approximated data (using linear approximation.) In a few cases, we add the last or next known value. To give a few quantiative indicators about our work:\nIncreased number of observations: 65% Reduced missing values: -48.1% Increased non-missing subset for regression or AI: +66.67% If your organization is working with panel (longitudional multiple) regressions or various machine learning applications, then your team knows that not havint the +66.67% gain would be a deal-breaker in the choice of models and punctuality of estimates or KPIs or other quantiative products. And that they would spent about 90% of their data resources on achieving this +66.67% gain in usability.\nIf you happen to work in an NGO, a business unit or a research institute that does not employ …","date":1636362000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636624860,"objectID":"64c18e37a183412e97b5041bcadff5d2","permalink":"https://reprex.nl/post/2021-11-06-indicator_value_added/","publishdate":"2021-11-08T10:00:00+01:00","relpermalink":"/post/2021-11-06-indicator_value_added/","section":"post","summary":"Public data sources are often plagued with missng values. Naively you may think that you can ignore them, but think twice: in most cases, missing data in a table is not missing information, but rather malformatted information which will destroy your beautiful visualization or stop your application from working. In this example we show how we increase the usable subset of a public dataset by 66.7%, rendering useful what would otherwise have been a deal-breaker in panel regressions or machine learning applications.","tags":["Digital Music Observatory","data-as-service","API","metadata","forecasting","missing data"],"title":"How We Add Value to Public Data With Imputation and Forecasting","type":"post"},{"authors":["Daniel Antal"],"categories":null,"content":"The Scuola Superiore di Studi Universitari e di Perfezionamento Sant’Anna and Università degli Studi di Trento (Italy); University of Glasgow (United Kingdom); Universiteit van Amsterdam and Stichting Europeana from the\tNetherlands; the National University of Ireland Maynooth\t(Ireland); Tartu Ulikool\t(Estonia); Szegedi Tudományegyetem (Hungary); Fundacion Santa Maria La Real del Patrimonio Historico from Spain; the Katholieke Universiteit Leuven,\t(Belgium); Culture Action Europe AISBL and IDEA Strategische Economische Consulting (Belgium) and Reprex created theREshaping CCSI REsearch: Open data, policy analysis and methods for evidence-based decision-making consortium consortium, which will mainly develop new policy evidence in the field of innovation and inclusiveness for the creative and cultural sectors, industries. The Consortium applies for a Horizon Europe grant with the HORIZON-CL2-2021-HERITAGE-01-03 Cultural and creative industries as a driver of innovation and competitiveness call of the European Commission.\nPolicymakers face challenges when trying to implement a strict evidence-based approach to decision-making in the field of cultural and creative sectors and industries (CCSI). This is mostly due to four phenomena:\nEvidence dissonances in mapping, measuring and analysis of key indicators, which lead to improper generalizations and gaps in decisionmakers’ knowledge and stakeholders’ awareness Fragmentation of hubs of production and concentration of platforms, which create statistical biases and have features that hardly fit with traditional impact assessment methods; Datafication, which is revolutionizing CCSI but remains difficult to investigate, thus broadening knowledge gaps; and Stakeholders’ fragmentation and conflicting interests, which hinders their engagement, awareness-raising and uptake of policy inputs.With its cross-disciplinary consortium of academics, practitioners and a strong network of stakeholders, engaged via participatory research strategies, RECREO will help policymakers and stakeholders tackling such challenges, by generating new knowledge and methods to fill in knowledge and awareness gaps. RECREO will achieve this goal through four actions. First, it will generate a wide array of horizontal and sector-specific datasets, made openly accessible via the CCSI Data Observatory and the Evidence Synthesis Platform. Second, it will offer an unprecedented EU and comparative mapping and impact assessment of key regulatory and policy measures relevant for CCSI, made available on the Law and Policy Observatory. Third, it will develop innovative methods to measure and assess CCSI innovation, competitiveness and spill-over effects, emphasizing inclusiveness, diversity and sustainability. Last, it will offer policy recommendations and best practices aimed at supporting the sustainable growth and competitiveness of culturally diverse CCSI, and their cross-fertilization with cultural heritage promotion and preservation.\n","date":1636214400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636275600,"objectID":"604036182594d3b916db5e29d1a377b4","permalink":"https://reprex.nl/post/2021-10-06-recreo/","publishdate":"2021-11-06T16:00:00Z","relpermalink":"/post/2021-10-06-recreo/","section":"post","summary":"Reprex joined the `REshaping CCSI REsearch: Open data, policy analysis and methods for evidence-based decision-making consortium` consortium, which will mainly develop new policy evidence in the field of innovation and inclusiveness for the creative and cultural sectors, industries.","tags":["ccsi","data-as-service","innovation","inclusiveness"],"title":"Reprex Joins RECREO Research Consortium To Develop Innovation Indicators","type":"post"},{"authors":["Daniel Antal"],"categories":null,"content":"Reprex’s co-founder, the main developer of the Digital Music Observatory, Daniel Antal and Digital Music Observatory curator, Marie Zhorová participated in the MaMA Festival \u0026amp; Convention in Paris on 13-15 October within the JUMP Music Market Accelerator Program Program. We introduced our Digital Music Observatory to national music organizations and encouraged them to try out a cooperation with us. (See Use Cases below)\nOur main aim was to find new users to our Digital Music Observatory, and to find partners for a future Horizon Europe R\u0026amp;D project to develop the scientific pillars of the Observatory in a manner that meets practical industry needs and the feature requirements laid out in hte Feasiblity Study for a Euroepan Music Observatory.\nOur concept was introduced in Le Trianon to a wider audience during the JUMP Music Market Accelerator Pitch Session and in one-to-one meetings to representatives of French national organizations. We have also started to investigate the possibility to cooperate with two startups to bring our data services closer to artists, labels, and publishers.\nUse Cases Fair Streaming Daniel introduced our work made for the UK IPO’s Music Creators’ Earnings in the Digital Era Project about the justified and not-justified differences among music rightsholders earnings and the diminishing market value of streams. We believe that our UK approach is a particularly interesting addition to join with the distribution analysis performed by the Centre Nationale de la Musique and Deloitte in France. Fair Value Daniel introduced to collective management professioanls our innovative approach for private copying valuation, royalty price setting, estimating the values of value transfer to media platforms, and other topics of interests for collective management and rights management organizations. Our approach has a proven track record to increase revenues for creators. Open Music Observatory We introduced our approach to building the European Music Observatory in a decentralized way, relying not only on the resources of Creative Europe but also on Open Science, Horizon Europe, bringing the music industry, music research in universities and cultural policy under one open collaboration. Because France is building its own music observatory of a kind, the decentralized approach could particularly benefit French stakeholders. Listen Local Marie and Daniel introduced the Listen Local project to startups. Our Listen Local project analyzes why recommendation engines do not recommend locally relevant music (such as music from Paris in Paris, Slovakian music for Slovaks) and offers alternative approaches and fixes. We were discussing with other startups serving artists and small labels to bring down our macro-level approaches’ benefits to the level of aritsts, as we did in our experimental project in Slovakia supported by our scientific research cooperation (see our pre-print manuscript.) Why Data Observatory? Our use cases highlight the value of having a wide range of data available for the industry players, researchers and policy-makers. In the era of big data, and when open data is becoming legally more and more available, it is important to have one place with a single data collection method. Copernicus built a permanent observatory for the ongoing observation of celestial bodies. We built an automated data observatory to permanently collect data about music.\n","date":1634324400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634324400,"objectID":"dd0a8a4f37a90b3e8c290235c85aa985","permalink":"https://reprex.nl/post/2021-10-15-mama/","publishdate":"2021-10-15T19:00:00Z","relpermalink":"/post/2021-10-15-mama/","section":"post","summary":"Reprex’s co-founder, Daniel Antal and our Listen Local curator, Marie Zhorová participated in the MaMA Festival \u0026 Convention in Paris on 13-15 October within the JUMP Music Market Accelerator Program. We introduced our Digital Music Observatory to national music organizations and encouraged them to try out a cooperation with us.","tags":["music","data-as-service","innovation","France"],"title":"Reprex on MaMA","type":"post"},{"authors":["Daniel Antal, CFA"],"categories":null,"content":"Currently more than half of the global music sales are made by autonomous AI systems owned by Google, Apple, or Spotify. These data monopolies are getting rich, because they reap the profit from music businesses with an average employee count of 1.8 Europe. European music businesses are easy to exploit with armies of data engineers and data scientists because they do not have a single data scientist or even an IT function.\nArtists in the UK had a difficulty explaining in Westminster how they are losing out in streaming– so we have created a streaming price index, like the Dow Jones, if you like, that explains the economic factors of the devaluation of music in the last 5 years in 20 countries. (See our report.)\nMusic organizations in Slovakia and Hungary were frustrated that their politicians and journalists believed music to be taxpayer funded, so we showed with data that they contribute more proportionally to the national budget than car manufacturers, the darling of local politicians (See our reports in Hungary (recast several times) and in Slovakia.)\nWe successfully challenged with data restaurant associations, hotel chains, telecom corporations and broadcasters who wanted to bring music prices down in court and via lobbying.\nThe music industry has envied the television and film industry which has a single go-to-point for data when it needs them, the European Audiovisual Observatory. It started lobbying for a publicly financed music observatory. But we did not wait. The music industry has a tragic track record of failed centralized international data projects. We built Reprex out of a 12-country, decentralized music project. We learned how to utilize hidden, but already existing data and research funds well, and how to manage the data governance among the poisonous conflicts of interests between rich and poor countries, authors vs producers, producer’s vs performers.\nOur Digital Music Observatory is not theoretical, it is practical, because it is built around real-life court cases, damage claims, lobbying and PR arguments.\nOur Digital Music Observatory is comprehensive – it contains more than a thousand indicators from all European countries. We have enough data to test the biases of the Spotify or the YouTube algorithm – you would be surprised what the data tells us.\nIt has data available much sooner, in much higher quality and in a more practical format than in the Audiovisual one.\nPresentation Slides You can see the presentation slides here.\n","date":1634209200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634216400,"objectID":"7ed9ef4dc4df4100f092253fc1db6b67","permalink":"https://reprex.nl/talk/digital-music-observatory-on-the-mama-convention-2021/","publishdate":"2021-10-14T11:00:00Z","relpermalink":"/talk/digital-music-observatory-on-the-mama-convention-2021/","section":"event","summary":"We are looking for partners in France for our Digital Music Observatory. You can find us in Le Trianon, in the JUMP Corner.","tags":["Open data","Music","Data observatory"],"title":"Digital Music Observatory on the MaMA Convention 2021","type":"event"},{"authors":["Daniel Antal, CFA"],"categories":null,"content":"Every year, the EU announces that billions and billions of data are now “open” again, but this is not gold. At least not in the form of nicely minted gold coins, but in gold dust and nuggets found in the muddy banks of chilly rivers. There is no rush for it, because panning out its value requires a lot of hours of hard work. Our goal is to automate this work to make open data usable at scale, even in trustworthy AI solutions.\nSummary In his presentation, Daniel compared the current state of open data (including governmental open data and scientific open data) to a thrift store. You can often find bargains, or historical data that would be impossible to source from data vendors, but on a strictly as-is basis, without a catalogue, service, or guarantee. Therefore, working with open data requires a careful reprocessing, validation, and in many cases, frequent re-validation. Open data is often over-estimated: it is never a finished product, often it cannot even be downloaded, therefore it requires further investment to make it valuable. However, because most open data arrives from the governmental sector, you can tap into information sources where no market alternative exists. Open data in some cases may be a cheaper substitute to market vendors, but often it is an exclusive source of information that do not have any market vendors.\nSisyphus was punished by being forced to roll an immense boulder up a hill only for it to roll down every time it neared the top, repeating this action for eternity. This is the price that project managers and analysts pay for the inadequate documentation of their data assets. The practices related to the exploitation of open data are not only relevant in an open data context: these are good data ingestion and procurement practices for any third party data, and in large organizations, for any cross-departmental data. (See the blogpost: The Data Sisyphus.)\nCase Study: Belgian Drought/Flood Risk Awareness, Financial Capacity \u0026amp; Hydrology a complex integration of various open data sources.\nIn the second part of the presentation, Daniel talked about our modern data observatory concept. We have reviewed about 80 functioning and already defunct international data collection programs. Data observatories, like Copernicus’ Observatory, are permanent infrastructure to record various domain-specific data, such as alternative fuel information, information on homelessness, or on the European music business. In our assessment, most of the EU, OECD, UNESCO recognized or endorsed observatories use obsolete technology and do not rely on the new achievements of data science. Reprex, our start-up offers an open source, open data based alternative solution to build largely automated data observatories. We believe that human judgement is needed in data curation, but processing, documentation and validation is best done by computers.\nCase Study: Reprocessing geographical information with administrative boundary changes At last, he presented a few development directions with our open-source software, mentioning our work withing the rOpenGov community. This part of the presentation was originally meant to open the way for a half-day open data workshop, but due to the current pandemic situation, the physical part of the conference and the workshops were not held.\nThe presentation largely included the topics of our Data \u0026amp; Lyrics blogpost: Open Data—The New Gold Without the Rush\nPresentation Slides See the presentation slides here.\n","date":1633687800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633687800,"objectID":"89932f77e8ba55e817c9e24cc0f405ef","permalink":"https://reprex.nl/talk/crunchconf-open-data-new-gold-without-the-rush/","publishdate":"2021-10-08T10:10:00Z","relpermalink":"/talk/crunchconf-open-data-new-gold-without-the-rush/","section":"event","summary":"Every year, the EU announces that billions and billions of data are now “open” again, but this is not gold. At least not in the form of nicely minted gold coins, but in gold dust and nuggets found in the muddy banks of chilly rivers. There is no rush for it, because panning out its value requires a lot of hours of hard work. Our goal is to automate this work to make open data usable at scale, even in trustworthy AI solutions.","tags":["Open data"],"title":"Crunchconf: Open Data, New Gold Without the Rush","type":"event"},{"authors":["Daniel Antal"],"categories":null,"content":"The creative and cultural sectors and industries are mainly made of networks of freelancers and microenterprises, with very few medium-sized companies. Their economic performance, problems, and innovation capacities hidden. Our open collaboration to create this data observatory is committed to change this. Relying on modern data science, the re-use of open governmental data, open science data, and novel harmonized data collection we aim to fill in the gaps left in the official statistics of the European Union.\nWe believe that introducing Open Policy Analysis standards with open data, open-source software and research automation can help better understanding how creative people and their enterprises and institutions add value to the European economy, how they create jobs, innovate, and increase the well-being of a diverse European society. Our collaboration is open for individuals, citizens scientists.\nThe new observatory can be reached on ccsi.dataobservatory.eu and will be institutionally hosted by IViR, the Institute for Information Law of the University of Amsterdam, where Reprex’s co-founder, Daniel Antal will coordinate the development of this new, open scientific tool. Reprex will continue to develop the working model of the data observatory and continue to build open source software tools within the rOpenGov community and the R-Universe initative of ROpenSci.\nThe Scuola Superiore di Studi Universitari e di Perfezionamento Sant’Anna and Università degli Studi di Trento (Italy); University of Glasgow (United Kingdom); Universiteit van Amsterdam and Stichting Europeana from the\tNetherlands; the National University of Ireland Maynooth\t(Ireland); Tartu Ulikool\t(Estonia); Szegedi Tudományegyetem (Hungary); Fundacion Santa Maria La Real del Patrimonio Historico from Spain; the Katholieke Universiteit Leuven,\t(Belgium); Culture Action Europe AISBL and IDEA Strategische Economische Consulting (Belgium) and Reprex created the the RECREO consortium, which will mainly develop new policy evidence in the field of innovation and inclusiveness for the creative and cultural sectors, industries. The Consortium applies for a Horizon Europe grant with the HORIZON-CL2-2021-HERITAGE-01-03 Cultural and creative industries as a driver of innovation and competitiveness call of the European Commission.\n","date":1633536000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633536000,"objectID":"3aa7c4c0649b0eb7fd9697e515fa6272","permalink":"https://reprex.nl/post/2021-10-05-ccsi/","publishdate":"2021-10-06T16:00:00Z","relpermalink":"/post/2021-10-05-ccsi/","section":"post","summary":"The creative and cultural sectors and industries are mainly made of networks of freelancers and microenterprises, with very few medium-sized companies. Their economic performance, problems, and innovation capacities hidden. Our open collaboration to create this data observatory is committed to change this. Relying on modern data science, the re-use of open governmental data, open science data, and novel harmonized data collection we aim to fill in the gaps left in the official statistics of the European Union.","tags":["ccsi","data-as-service","api","ccsi-data-observatory"],"title":"CCSI Data Observatory","type":"post"},{"authors":null,"categories":null,"content":"The creative and cultural sectors and industries are mainly made of networks of freelancers and microenterprises, with very few medium-sized companies. Their economic performance, problems, and innovation capacities hidden. Our open collaboration to create this data observatory is committed to change this. Relying on modern data science, the re-use of open governmental data, open science data, and novel harmonized data collection we aim to fill in the gaps left in the official statistics of the European Union.\nTable of Contents Our approach to a cultural and creative sector data observatory What are data observatories? Invitation for an open collaboration Download this page in a 2-page pdf document.\nOur approach to a cultural and creative sector data observatory The CCSI Data Observatory aims to be the go-to point for the cultural and creative sector and industry data. We want to help creative businesses, policy-makers, film funds, cultural heritage organizations, and civil society organizations with their data problems. Such organizations in Europe usually have a small team, often made of freelancers. Most of them have no data scientists or data engineers (and could not afford them). They usually do not even have in-house IT, or it has a very limited capacity.\nReprex is a Hauge-based impact startup currently developing the prototype of a decentralized, modern, web 3.0-compatible European Music Observatory. We are collecting and processing our users’ hard-to-get data and information in 20 countries. Reprex’s live prototype, the Digital Music Observatory, has successfully solved several countries’ complex problems (e.g. valuing and pricing music, providing evidence on piracy, predicting audiences, and finding algorithmic biases against small-country artists.) Our product/market fit was validated in the world’s 2nd-ranked university-backed incubator, the Yes!Delft AI+Blockchain Lab. We further developed the idea in the JUMP European Music Market Accelerator and are currently a finalist in the international impact innovation competition, The Hague Innovators Challenge. In 2022, our Digital Music Observatory collaboration won a Horizon Europe Research and Innovation Grant and three Culture Europe grants.\nWe realized in 2021 that most of the hard-to-get and difficult-to-process information sources of music are identical or very similar to those in film, gaming, books, and even fashion. We created a consortium with some of our partners in the music observatory, but unfortunately this project, unlike our music observatory project, did not get the desired funding yet. With our partners, the Scuola Superiore di Studi Universitari e di Perfezionamento Sant’Anna as original project initiator, the Institute for Information Law Research or the University of Amsterdam kept the unfunded project alive. The Stichting Europeana from the Netherlands supported with recommendation Reprex to compete with this idea for The Hague Innovation Award.\nWe want to help cultural organizations with top-notch market research, for example, survey recycling, big data collection, and reuse of not-yet-processed public sector data to provide a much better value-for-money service. We can also place the research data into innovative apps, such as audience prediction with machine learning. Make the digital presence of our creative partners more visible and usable in the era of web 3.0. Harmonize their website and information automatically with global knowledge graphs, and place their research material, films, 3D objects, and catalogs into international knowledge databases and web services to create a much more significant impact. Test if autonomous, AI-driven applications (such as music, film, or book streaming platforms, library recommended systems, and search engines) find their content, understand it well and recommend it to the correct audiences. Big data and AI create many inequalities and usually place European creative enterprises, particularly from smaller countries, in a disadvantageous position vis-a-vis American or English-language productions. With our world-class research partners in metadata and algorithmic biases, we improve. Provide so-called ‘smart policy documents,’ such as business or policy dashboards, newsletters, and advocacy reports that automatically refresh their international comparative data, its visualizations, and legal and official policy document references. We automate the work of an eminent research assistant: we find the correct version of data in your documents and remind you of outdated legal or policy references. We place your research on web 3.0 knowledge graphs so that the document will search for its appropriate audience and significantly increase your dissemination and advocacy outreach. What are data observatories? More than 60 EU, UN, or OECD-recognized data/social science observatories exist worldwide. Data observatories are public-private partnerships among businesses, consultancies, policy- and …","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633046400,"objectID":"83dc76040fc87fc7e369018af151757d","permalink":"https://reprex.nl/observatories/ccsi/","publishdate":"2021-10-01T00:00:00Z","relpermalink":"/observatories/ccsi/","section":"observatories","summary":"Relying on modern data science, the re-use of open governmental data, open science data, and novel harmonized data collection we aim to fill in the gaps left in the official statistics of the European Union about the creative and cultural sectors and industries.","tags":["Creative industries"],"title":"Cultural \u0026 Creative Sectors and Industries Data Observatory","type":"observatories"},{"authors":["Daniel Antal"],"categories":null,"content":" “Owing to the global nature of music earnings, the various currency translation and royalty payments applied, and because there is no global comprehensive database of rights-holders, works, and recordings, it is impossible to calculate average (mean) or typical (median) earnings with any accuracy. Even an estimate would require a very complex methodology. Understanding the earnings of an average rights-holder would require a careful disaggregation of volume, price, exchange rate, and distribution changes, and international data harmonisation.\nEstimating average or typical income requires advanced empirical sampling or surveying methods. The Digital Music Observatory (previously CEEMID) has worked on developing such methods, with the support of the state51 music group. We commissioned a report from the Digital Music Observatory on the earnings of UK rights-holders and this can be found here at \u0026lt;the Digital Music Observatory’s Zenodo repository\u0026gt; Among the Observatory’s findings are that use of streaming services is generally growing in terms of volume, but the price is diminishing, which leads to diminishing or flat earnings for a typical or average British rights-holder; that in the 2015-2019 period, falling prices were partly or fully compensated by favourable changes in the exchange rate of the British pound with major currencies used in the global music business (the US dollar, the euro and the Japanese yen), but since 2020 there may have been changes in the opposite direction; and that for various methodological reasons, without international data harmonisation, and survey harmonisation, it is impossible to take a fully representative, unbiased sample of music creator earnings in the United Kingdom alone.” Music Creator’s Earnings in the Digital Era, p28.\nExectuive Summary of Our Research Document The research questions asked in this report are related to the Music Creator Earnings’ Project (MCE), exploring issues concerning equitable remuneration and earnings distributions. We were tasked with providing a longitudinal analysis of earnings development and relating our findings to equitable remuneration. The starting point of our work was centred around a very broadly defined problem: how much money music creators (rightsholders) earn from streaming, how these earnings are distributed, and how the earnings and their distribution have developed during the last decade.\nThe highly globalized music industry generates two important international reports, as well as several national reports, but these are not suitable for the analysis of the typical or average rightsholder, nor for small labels and publishers who do not represent a large and internationally diversified portfolio of music works or recordings. Copyright and neighboring right revenues are collected in national jurisdictions. Because British artists are almost never constrained by their use of language, and the UK Music Industry is highly competitive in the global music markets, even relatively less known rightsholders earn revenues from dozens of national markets. The lack of market information on music sales volumes, prices for each jurisdiction, and the unaccounted for national, domestic, and foreign revenues makes the analysis of the rightholder’s earnings, or the economics of a certain distribution channel like music streaming or media platforms, impossible.\nWhile total earnings are reported by international and national organizations, they hide five important economic variables: changes in sales volumes, changes in prices, market share on various national jurisdictions (which have their own volume and price movements), the exchange rates applied, and the share of the repertoire exploited. Even worse, the global music industry has no comprehensive database of rightsholders, music works, and recordings. Many rights are represented by heirs or passive investors. And because of the enormous number of works and recordings, in any given royalty payment period, most works/recordings are not used and not compensated. The lack of a known population and distribution makes usual indicators as average or median earnings arithmetically impossible to compute, and the large number of disused works and recordings makes even the estimation of the typical (median) value useless for economic analysis. The estimation of the arithmetic mean is equally problematic, because it is distorted by the earnings of very few global stars. To understand the streaming economy from the perspective of a typical or average rightsholder, or from the perspective of a small independent label or music publisher, requires very challenging sampling techniques either in surveying or in empirically observing and aggregating data from royalty accounts. National and international music organizations are not equipped with the data processing and statistical capacity to do so.\nThe Effect of International Diversification on Revenues - a combination of international price differences and …","date":1632391200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632391200,"objectID":"b74046a5bd6a818f09f71bb0909d4d23","permalink":"https://reprex.nl/publication/mce_empirical_streaming_2021/","publishdate":"2021-09-23T10:00:00Z","relpermalink":"/publication/mce_empirical_streaming_2021/","section":"publication","summary":"This report was commissioned by the Music Creators’ Earnings Project as an empirical analysis of justified and unjustified differences in music creators’ music streaming earnings.","tags":["market-report","music-industry","United Kingdom","music-streaming","equitable remuneration"],"title":"An Empirical Analysis of Music Streaming Revenues and Their Distribution","type":"publication"},{"authors":["Daniel Antal"],"categories":null,"content":"Reprex with its Digital Music Observatory team was commissioned to prepare an analysis on the justified and not justified differences in music creators’ earnings. We have posted our most important findings in an earlier blogpost (Music Creators’ Earnings in the Streaming Era. United Kingdom Research Cooperation With the Digital Music Observatory.\nThe UK Intellectual Property Office has published the entire report on the music creators’ earnings, and we have made our detailed analysis available in a side-publication. Reprex also signed an agreement with the researchers of the Music Creators’ Earnings project to deposit all data published in the report in the Digital Music Observatory, and to promote the building of the observatory further.\nThe research questions asked in this report are related to the Music Creator Earnings’ Project (MCE), exploring issues concerning equitable remuneration and earnings distributions. We were tasked with providing a longitudinal analysis of earnings development and relating our findings to equitable remuneration. The starting point of our work was centred around a very broadly defined problem: how much money music creators (rightsholders) earn from streaming, how these earnings are distributed, and how the earnings and their distribution have developed during the last decade.\nThe highly globalized music industry generates two important international reports, as well as several national reports, but these are not suitable for the analysis of the typical or average rightsholder, nor for small labels and publishers who do not represent a large and internationally diversified portfolio of music works or recordings. Copyright and neighboring right revenues are collected in national jurisdictions. Because British artists are almost never constrained by their use of language, and the UK Music Industry is highly competitive in the global music markets, even relatively less known rightsholders earn revenues from dozens of national markets. The lack of market information on music sales volumes, prices for each jurisdiction, and the unaccounted for national, domestic, and foreign revenues makes the analysis of the rightholder’s earnings, or the economics of a certain distribution channel like music streaming or media platforms, impossible.\nThe Effect of International Diversification on Revenues - a combination of international price differences and exchange rate fluctuations. While total earnings are reported by international and national organizations, they hide five important economic variables: changes in sales volumes, changes in prices, market share on various national jurisdictions (which have their own volume and price movements), the exchange rates applied, and the share of the repertoire exploited. Even worse, the global music industry has no comprehensive database of rightsholders, music works, and recordings – this is the data gap that we would like fill with the Digital Music Observatory.\nOur report highlights some important lessons. First, we show that in the era of global music sales platforms it is impossible to understand the economics of music streaming without international data harmonization and advanced surveying and sampling. Paradoxically, without careful adjustments for accruals, market shares in jurisdictions, and disaggregation of price and volume changes, the British industry cannot analyze its own economics because of its high level of integration to the global music economy. Furthermore, the replacement of former public performances, mechanical licensing, and private copying remunerations (which has been available for British rightsholders in their European markets for decades) with less valuable streaming licenses has left many rightsholders poorer. Making adjustments on the distribution system without modifying the definition of equitable remuneration rights or the pro-rata distribution scheme of streaming platforms opens up many conflicts while solving not enough fundamental problems. Therefore, we suggest participation in international data harmonization and policy coordination to help regain the historical value of music.\nContext The idea of our Digital Music Observatory was brought to the UK policy debate on music streaming by the Written evidence submitted by The state51 Music Group to the Economics of music streaming review of the UK Parliaments’ DCMS Committee1.\nThe music industry requires a permanent market monitoring facility to win fights in competition tribunals, because it is increasingly disputing revenues with the world’s biggest data owners. This was precisely the role of the former CEEMID2 program, which was initiated by a group of collective management societies. Starting with three relatively data-poor countries, where data pooling allowed rightsholders to increase revenues, the CEEMID data collection program was extended in 2019 to 12 countries.The final regional report, after the release of the detailed Hungarian, Slovak and Croatian …","date":1632384000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633597200,"objectID":"8938f6147e394da8e229f796e9ff1272","permalink":"https://reprex.nl/post/2021-09-23-mce_reports/","publishdate":"2021-09-23T08:00:00Z","relpermalink":"/post/2021-09-23-mce_reports/","section":"post","summary":"Our Digital Music Observatory contributed to the Music Creators’ Earnings in the Streaming Era project with understanding the level of justified and unjustified differences in rightsholder earnings, and putting them into a broader music economy context. The entire research paper is published by the UK Intellectual Property office, and we made the details of our analysis available in a joint publication.","tags":["open-data","open-science","regional data","valuation","United Kingdom"],"title":"Research \u0026 Analysis: Music Creators’ Earnings in the Digital Era","type":"post"},{"authors":["Daniel Antal"],"categories":null,"content":" Sisyphus was punished by being forced to roll an immense boulder up a hill only for it to roll down every time it neared the top, repeating this action for eternity. This is the price that project managers and analysts pay for the inadequate documentation of their data assets. When was a file downloaded from the internet? What happened with it sense? Are their updates? Did the bibliographical reference was made for quotations? Missing values imputed? Currency translated? Who knows about it – who created a dataset, who contributed to it? Which is an intermediate format of a spreadsheet file, and which is the final, checked, approved by a senior manager?\nBig data creates inequality and injustice. On aspect of this inequality is the cost of data processing and documentation – a greatly underestimated, and usually not reported cost item. In small organizations, where there are no separate data science and data engineering roles, data is usually supposed to be processed and documented by (junior) analysts or researchers. This a very important source of the gap between Big Tech and them: the data usually ends up very expensive, ill-formatted, not readable by computers that use machine learning and AI. Usually the documentation steps are completely omitted.\n“Data is potential information, analogous to potential energy: work is required to release it.” – Jeffrey Pomerantz\nMetadata, which is information about the history of the data, and information how it can be technically and legally reused, has a hidden cost. Cheap or low-quality external data comes with poor or no metadata, and small organizations lack the resources to add high-quality metadata to their datasets. However, this only perpetuates the problem.\nThe hidden cost item behind the unbillable hours As we have shown with our research partners, such metadata problems are not unique to data analysis. Independent artists and small labels are suffering on music or book sales platforms, because their copyrighted content is not well documented. If you automatically document tens of thousands of songs or datasets, the documentation cost is very small per item. If you, do it manually, the cost may be higher than the expected revenue from the song, or the total cost of the dataset itself. (See our research consortiums’ preprint paper: Ensuring the Visibility and Accessibility of European Creative Content on the World Market: The Need for Copyright Data Improvement in the Light of New Technologies)\nIn the short run, small consultancies, NGOs, or as a matter of fact, musicians, seem to logically give up on high-quality documentation and logging. In the long run, this has two devastating consequences: computers, such as machine learning algorithms cannot read their documents, data, songs. And as memory fades, the ill-documented resources need to be re-created, re-checked, reformatted. Often, they are even hard to find on your internal server or laptop archive.\nMetadata is a hidden destroyer of the competitiveness of corporate or academic research, or independent content management. It never quoted on external data vendor invoices, it is not planned as a cost item, because metadata, the description of a dataset, a document, a presentation, or song, is meaningless without the resource that it describes. You never buy metadata. But if your dataset comes without proper metadata documentation, you are bound, like Sisyphus, to search for it, to re-arrange it, to check its currency units, its digits, its formatting. Data analysts are reported to spend about 80% of their working hours on data processing and not data analysis – partly, because data processing is a very laborious task that can be done by computers at a scale far cheaper, and partly because they do not know if the person who sat before them at the same desk has already performed these tasks, or if the person responsible for quality control checked for errors.\nUncut diamonds need to be cut, polished, and you have to make sure that they come from a legal source. Data is similar: it needs to be tidied up, checked and documented before use. Photo: Dave Fischer. Undocumented data is hardly informative – it may be a page in a book, a file in an obsolete file format on a governmental server, an Excel sheet that you do not remember to have checked for updates. Most data are useless, because we do not know how it can inform us, or we do not know if we can trust it. The processing can be a daunting task, not to mention the most boring and often neglected documentation duties after the dataset is final and pronounced error-free by the person in charge of quality control.\nOur observatory automatically processes and documents the data The good news about documentation and data validation costs is that they can be shared. If many users need GDP/capita data from all over the world in euros, then it is enough if only one entity, a data observatory, collects all GDP and population data expresed in dollars, korunas, and euros, …","date":1625734800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625734800,"objectID":"7fe21d2727803b3edcddd706a67fe6a2","permalink":"https://reprex.nl/post/2021-07-08-data-sisyphus/","publishdate":"2021-07-08T09:00:00Z","relpermalink":"/post/2021-07-08-data-sisyphus/","section":"post","summary":"Sisyphus was punished by being forced to roll an immense boulder up a hill only for it to roll down every time it neared the top, repeating this action for eternity.  When was a file downloaded from the internet?  What happened with it sense?  Are their updates? Did the bibliographical reference was made for quotations?  Missing values imputed?  Currency translated? Who knows about it – who created a dataset, who contributed to it?  Which is the final, checked, approved by a senior manager?","tags":["metadata","data-as-service","api"],"title":"The Data Sisyphus","type":"post"},{"authors":null,"categories":null,"content":"Finding reliable historic and new data and information about climate change, as well as the impact of various European Green Deal policies that try to mitigate it is surprisingly hard to find if you are a scientific researcher. And it is even more hopeless if you work as a (data) journalist, a policy researcher in an NGO, or in the sustainability unit of a company that does not provide you with an army of (geo)statisticians, data engineers, and data scientists who can render various data into usable format, i.e.something that you can trust, quote, visualize, import, or copy \u0026amp; paste.\nVisit the Green Deal Data Observatory\nTry the Green Deal Data Observatory API\nConnect on LinkedIn\nBetter, Bigger, Faster, More Novel data products\nOfficial statistics at the national and European levels follow legal regulations, and in the EU, compromises between member states. New policy indicators often appear 5-10 years after demand appears. We employ the same methodology, software, and often even the same data that Eurostat might use to develop policy indicators, but we do not have to wait for a political and legal consensus to create new datasets. See our 100,000 Opinions on the Most Pressing Global Problem blogpost. Better data\nStatistical agencies, old fashioned observatories, and data providers often do not have the mandate, know-how or resources to improve data quality. Using peer-reviewed statistical software and hundreds of computational tests, we are able to correct mistakes, impute missing data, generate forecasts, and increase the information content of public data by 20-200% percent. This makes the data usable for NGOs, journalists, and visual artists—among other potential users—who do not have this statistical know-how to make incomplete, mislabelled or low quality data usable for their needs and applications. See our example with the Government Budget Allocations for R\u0026amp;D in Environment indicator. Never seen data\nThe 2019/1024 directive on open data and the re-use of public sector information of the European Union (which is an extension and modernization of the earlier directives on re-use of public sector information since 2003) makes data gathered in EU institutions, national institutions, and municipalities, as well as state-owned companies legally available. According to the European Data Portal the estimated historical cost of the data released annually is in the billions of euros. But if this data is a gold mine, its full potential can only be unlocked by an experienced data mining partner like Reprex. Here is why: data is not readily downloadable; it sits in various obsolete file formats in disorganized databases; it is documented in various languages, or not documented at all; it is plagued with various processing errors. We make the powerful promise of open data of the EU legislation a reality in the field of the Green Deal policy context. Increase Your Impact, Avoid Old Mistakes Reprex helps its policy, business, and scientific partners by providing efficient solutions for necessary data engineering, data processing and statistical tasks that are as complex as they are tedious to perform. We deploy validated, open-source, peer-reviewed scientific software to create up-to-date, reliable, high-quality, and immediately usable data and visualizations. Our partners can leave the burden of this task, share the cost of data processing, and concentrate on what they do best: disseminating and advocating, researching, or setting sustainable business or underwriting indicators and creating early warning systems.\nImpact\nWe publish the data in a way that it is easy to find—as a separate data publication with a DOI, full library metadata, and place it in open science repositories. Our data is more findable than 99% of the open science data, and therefore makes far bigger impact. See our data on the European open science repository Zenodo managed by CERN (the European Organization for Nuclear Research). Easy-to-use data\nOur data follows the tidy data principle and comes with all the recommended Dublin Core and DataCite metadata. This increases our data compatibility, allowing users to open it in any spreadsheet application or import into their databases. We publish the data in tabular form, and in JSON form through our API enabling automatic retrieval for heavy users, especially if they plan to automatically use our data in daily or weekly updates. Using the best practice of data formatting and documentation with metadata ensures reproducibility and data integrity, rather than repeating data processing and preparation steps (e.g. changing data formats, removing unwanted characters, creating documentation, and other data processing steps that take up thousands of working hours. See our blogpost on the data Sisyphus. Ethical Big Data for All Big data creates inequalities, because only the largest corporations, government bureaucracies and best endowed universities can afford large data collection programs, the use of …","date":1625616000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639180800,"objectID":"367a63f643d85b66f24a8b35d97beab5","permalink":"https://reprex.nl/observatories/greendeal/","publishdate":"2021-07-07T00:00:00Z","relpermalink":"/observatories/greendeal/","section":"observatories","summary":"An ambitious project to connect environmental sensory data, political and policy survey data with socio-economic indicators.","tags":["Climate change"],"title":"Green Deal Data Observatory","type":"observatories"},{"authors":null,"categories":null,"content":"Adding metadata exponentially increases the value of data. Did your region add a new town to its boundaries? How do you adjust old data to conform to constantly changing geographic boundaries? What are some practical ways of combining satellite sensory data with my organization’s records? And do I have the right to do so? Metadata logs the history of data, providing instructions on how to reuse it, also setting the terms of use. We automate this labor-intensive process applying the FAIR data concept.\nIn our observatory we apply the concept of FAIR (findable, accessibe, interoperable, and reusable digital assets) in our APIs and in our open-source statistical software packages.\nThe hidden cost item Metadata gets less attention than data, because it is never acquired separately, it is not on the invoice, and therefore it remains an a hidden cost, and it is more important from a budgeting and a usability point of view than the data itself. Metadata is responsible for industry non-billable hours or uncredited working hours in academia. Poor data documentation, lack of reproducible processing and testing logs, inconsistent use of currencies, keywords, and storing messy data make reusability and interoperability, integration with other information impossible.\nFAIR Data and the Added Value of Rich Metadata we introduce how we apply the concept of FAIR (findable, accessibe, interoperable, and reusable digital assets) in our APIs.\nOrganizations pay many times for the same, repeated work, because these boring tasks, which often comprise of tens of thousands of microtasks, are neglected. Our solution creates automatic documentation and metadata for your own historical internal data or for acquisitions from data vendors. We apply the more general Dublin Core and the more specific, mandatory and recommended values of DataCite for datasets – these are new requirements in EU-funded research from 2021. But they are just the minimal steps, and there is a lot more to do to create a diamond ring from an uncut gem.\nMap your data: bibliographis, catalogues, codebooks, versioning Updating descriptive metadata, such as bibliographic citation files, descriptions and sources to data files downloaded from the internet, versioning spreadsheet documents and presentations is usually a hated and often neglected task withing organization, and rightly so: these boring and error-prone tasks are best left to computers.\nAlready adjusted spreadsheets are re-adjusted and re-checked. Hours are spent on looking for the right document with the rigth version. Duplicates multiply. Already downloaded data is downloaded again, and miscategorized, again. Finding the data without map is a treasure hunt. Photo: © N. The lack of time and resources spend on documentation over time reduces reusability and significantly increases data processing and supervision or auditing costs.\nOur observatory metadata is compliant with the Dublin Core Cross-Domain Attribute Set metadata standard, but we use different formatting. We offer simple re-formatting from the richer DataCite to Dublin Core for interoperability with a wider set of data sources. We use all mandatory DataCite metadata fields, all the the recommended and optional ones. It complies with the tidy data principles. In other words: very easy to import into your databases, or join with other databases, and the information is easy to find. Corrections, updates can automatically managed.\nWhat happened with the data before? We are creating Codebooks that are following the SDMX statistical metadata codelists, and resemble the SMDX concepts used by international statistical agencies. (See more technical information here.) Small organizations often cannot afford to have data engineers and data scientists on staff, and they employ analysts who work with Excel, OpenOffice, PowerBI, SPSS or Stata. The problem with these applications is that they often require the user to manually adjust the data, with keyboard entries or mouse clicks. Furthermore, they do not provide a precise logging of the data processing, manipulation history. The manual data processing and manipulation is very error prone and makes the use of complex and high value resources, such as harmonized surveys or symmetric input-output tables, to name two important source we deal with, impossible to use. The use of these high-value data sources often requires tens of thousands of data processing steps: no human can do it faultlessly.\nWhat is even more problematic that simple applications for analysis do not provide a log of these manipulations’ steps: pulling over a column with the mouse, renaming a row, adding a zero to an empty cell. This makes senior supervisory oversight and external audit very costly.\nOur data comes with full history: all changes are visible, and we even open the code or algorithm that processed the raw data. Your analysts can still use their favourite spreadsheet or statistical software application, but they can start from a …","date":1625616000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625616000,"objectID":"8ac5f27972f957d4b5d4188584738e4c","permalink":"https://reprex.nl/services/metadata/","publishdate":"2021-07-07T00:00:00Z","relpermalink":"/services/metadata/","section":"services","summary":"Adding metadata exponentially increases the value of data. Did somebody already adjust old data to conform to constantly changing geographic boundaries? What are some practical ways of combining satellite sensory data with my organization's records? And do I have the right to do so? Metadata logs the history of data, providing instructions on how to reuse it, also setting the terms of use. We automate this labor-intensive process applying the FAIR data concept.","tags":["metadata"],"title":"Metadata","type":"services"},{"authors":null,"categories":null,"content":"We provide retrospecitve, ex post, and ex ante survey harmonization to our partners.\nThe aim of retrospective survey harmonization is to pool data from pre-existing surveys made with a similar methodology in different points in time and different countries or territories. Ex post survey harmonization is in a way a passive form of pooling research funding because you can utilize information from surveying that were made on somebody else’s expense. The Arab Barometer surveys do not have a consolidated codebook, but our retroharmonize software created one, and put together data from three years and collected in many countries about various public policy issues. The aim of ex ante survey harmonization is to maximize the value from future retrospective harmonization; in a way, it is an active form of pooling research funding, because you benefit from money spent on related open governmental and open science survey programs. In this example we designed a survey representative among music professionals that it can be compared with large-sample, national surveys on living conditions and attitudes, and with occupational groups. Nationally representative surveys do not question enough musicians to allow such specific use; musician only surveys do not allow comparison. retorhamonize is a peer-reviewed, scientfic statistcal software that allows the programmatic retrospective harmonization of surveys, such as the last 35 years of all Eurobarometer microdata, or all Afrobarometer microdata. Eurobarometer grew out of certain CEE member states’ need for comparable data about their music and audiovisual sectors. We commissioned surveys following ESSNet-Culture guidelines and combined our survey data with open access European microdata-level surveys.\nregions solves the problems caused by Europe’s shifting regional boundaries, which have undergone changes in several thousand places over the last twenty years, meaning member states’ and Eurostat’s regional statistics are not comparable over more than two to three years. This software validates and, where possible, changes the regional coding from NUTS1999 until the not yet used NUTS2021, opening up vast, valuable, untapped data sources that can be used for longitudinal analysis or for panel analysis far more precise than what national data alone would allow. It was originally designed in a research project at IVIR in the University of Amsterdam to understand the geographical dynamics of book piracy. Because of the needs this software fills, it had 700 users in the first month after publication. It is particularly useful to re-code old surveys, as regional boundaries are changing in each decade several hundred times in Europe.\n","date":1625472000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625472000,"objectID":"395517f5bd9a85f85c9fbd68e92b6d7d","permalink":"https://reprex.nl/data/surveys/","publishdate":"2021-07-05T08:00:00Z","relpermalink":"/data/surveys/","section":"data","summary":"Ex post survey harmonization is in a way a passive form of pooling research funding because you can utilize information from surveying that were made on somebody else’s expense.  The aim of ex ante survey harmonization is to maximize the value from future retrospective harmonization; in a way, it is an active form of pooling research funding, because you benefit from money spent on related open governmental and open science survey programs.","tags":["surveys","survey harmonization"],"title":"Survey Harmonization","type":"data"},{"authors":["Daniel Antal"],"categories":null,"content":"A new version of the retroharmonize R package – which is working with retrospective, ex post harmonization of survey data – was released yesterday after peer-review on CRAN. It allows us to compare opinion polling data from the Arab Barometer with the Eurobarometer and Afrorbarometer. This is the first version that is released in the rOpenGov community, a community of R package developers on open government data analytics and related topics.\nSurveys are the most important data sources in social and economic statistics – they ask people about their lives, their attitudes and self-reported actions, or record data from companies and NGOs. Survey harmonization makes survey data comparable across time and countries. It is very important, because often we do not know without comparison if an indicator value is low or high. If 40% of the people think that climate change is a very serious problem, it does not really tell us much without knowing what percentage of the people answered this question similarly a year ago, or in other parts of the world.\nWith the help of Ahmed Shabani and Yousef Ibrahim, we created a third case study after the Eurobarometer, and Afrobarometer, about working with the Arab Barometer harmonized survey data files.\nEx ante survey harmonization means that researchers design questionnaires that are asking the same questions with the same survey methodology in repeated, distinct times (waves), or across different countries with carefully harmonized question translations. Ex post harmonizations means that the resulting data has the same variable names, same variable coding, and can be joined into a tidy data frame for joint statistical analysis. While seemingly a simple task, it involves plenty of metadata adjustments, because established survey programs like Eurobarometer, Afrobarometer or Arab Barometer have several decades of history, and several decades of coding practices and file formatting legacy.\nVariable harmonization means that if the same question is called in one microdata source Q108 and the other eval-parl-elections then we make sure that they get a harmonize and machine readable name without spaces and special characters. Variable label harmonization means that the same questionnaire items get the same numeric coding and same categorical labels. Missing case harmonization means that various forms of missingness are treated the same way. For the evaluation of the economic situation dataset, get the country averages and aggregates from Zenodo, and the plot in jpg or png from figshare. In our new Arab Barometer case study, the evaulation of parliamentary elections has the following labels. We code them consistently 1: free_and_fair, 2: some_minor_problems, 3: some_major_problems and 4: not_free.\n“0. missing” “1. they were completely free and fair” “2. they were free and fair, with some minor problems” “3. they were free and fair, with some major problems” “4. they were not free and fair” “8. i don’t know” “9. declined to answer” “Missing” “They were completely free and fair” “They were free and fair, with some minor breaches” “They were free and fair, with some major breaches” “They were not free and fair” “Don’t know” “Refuse” “Completely free and fair” “Free and fair, but with minor problems” “Free and fair, with major problems” “Not free or fair” “Don’t know (Do not read)” “Decline to answer (Do not read)” Of course, this harmonization is essential to get clean results like this:\nFor evaluation or reuse of parliamentary elections dataset get the replication data and the code from the Zenodo open repository. In our case study, we had three forms of missingness: the respondent did not know the answer, the respondent did not want to answer, and at last, in some cases the respondent was not asked, because the country held no parliamentary elections. While in numerical processing, all these answers must be left out from calculating averages, for example, in a more detailed, categorical analysis they represent very different cases. A high level of refusal to answer may be an indicator of surpressing democratic opinion forming in itself.\nSurvey harmonization with many countries entails tens of thousands of small data management task, which, unless automatically documented, logged, and created with a reproducible code, is a helplessly error-prone process. We believe that our open-source software will bring many new statistical information to the light, which, while legally open, was never processed due to the large investment needed.\nWe also started building experimental APIs data is running retroharmonize regularly. We will place cultural access and participation data in the Digital Music Observatory, climate awareness, policy support and self-reported mitigation strategies into the Green Deal Data Observatory, and economy and well-being data into our Economy Data Observatory.\nFurther plans Retrospective survey harmonization is a far more complex task than this blogpost suggest. …","date":1624870800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624870800,"objectID":"ed5892c8c036e56b13a3ea3390d80d8d","permalink":"https://reprex.nl/post/2021-06-28-arabbarometer/","publishdate":"2021-06-28T09:00:00Z","relpermalink":"/post/2021-06-28-arabbarometer/","section":"post","summary":"A new version of the retroharmonize R package – which is working with retrospective, ex post harmonization of survey data – was released yesterday after peer-review on CRAN. It allows us to compare opinion polling data from the Arab Barometer with the Eurobarometer and Afrorbarometer. This is the first version that is released in the rOpenGov community, a community of R package developers on open government data analytics and related topics.","tags":["Open data","Open science","R","data collection","Arab Barometer","survey harmonization"],"title":"Including Indicators from Arab Barometer in Our Observatory","type":"post"},{"authors":null,"categories":null,"content":"Our observatory is monitoring the certain segments of the European economy, and develops tools for computational antitrust in Europe. We take a critical SME-, intellectual property policy and competition policy point of view automation, robotization, and the AI revolution on the service-oriented European social market economy.\nWe aim to create early-warning, risk, economic effect, and impact indicators that can be used in scientific, business and policy contexts for professionals who are working on re-setting the European economy after a devastating pandemic and in the age of AI. We would like to map data between economic activities (NACE), antitrust markets, and sub-national, regional, metropolitian area data.\nVisit the Competition Data Observatory\nTry the Competition Data Observatory API\nConnect on LinkedIn\nFinding reliable historic and new data that can fuel large market monitoring schemes or computational antitrust models is surprisingly hard. And it is even more hopeless if you work as a (data) journalist, a policy researcher in an NGO, or in a competition law practice that does not provide you with an army of (geo)statisticians, data engineers, and data scientists who can render various data into usable format, i.e. something that you can trust, quote, visualize, import, or copy \u0026amp; paste.\nBetter, Bigger, Faster, More Get more information from public datasets, or data you had paid for. Find more data in higher quality that is available sooner than in other sources.\nNovel data products\nOfficial statistics at the national and European levels follow legal regulations, and in the EU, compromises between member states. New policy indicators often appear 5-10 years after demand appears. We employ the same methodology, software, and often even the same data that Eurostat might use to develop policy indicators, but we do not have to wait for a political and legal consensus to create new datasets. See our 100,000 Opinions on the Most Pressing Global Problem blogpost. Better data\nStatistical agencies, old fashioned observatories, and data providers often do not have the mandate, know-how or resources to improve data quality. Using peer-reviewed statistical software and hundreds of computational tests, we are able to correct mistakes, impute missing data, generate forecasts, and increase the information content of public data by 20-200% percent. This makes the data usable for NGOs, journalists, and visual artists—among other potential users—who do not have this statistical know-how to make incomplete, mislabelled or low quality data usable for their needs and applications. See our example with the Turnover of the Radio Broadcasting Industry in Europe indicator. Never seen data\nThe 2019/1024 directive on open data and the re-use of public sector information of the European Union (which is an extension and modernization of the earlier directives on re-use of public sector information since 2003) makes data gathered in EU institutions, national institutions, and municipalities, as well as state-owned companies legally available. According to the European Data Portal the estimated historical cost of the data released annually is in the billions of euros. But if this data is a gold mine, its full potential can only be unlocked by an experienced data mining partner like Reprex. Here is why: data is not readily downloadable; it sits in various obsolete file formats in disorganized databases; it is documented in various languages, or not documented at all; it is plagued with various processing errors. We make the powerful promise Government Budget Allocations for R\u0026amp;D in Environment of the EU legislation a reality in the field of the Green Deal policy context. Increase Your Impact, Avoid Old Mistakes Reprex helps its policy, business, and scientific partners by providing efficient solutions for necessary data engineering, data processing and statistical tasks that are as complex as they are tedious to perform. We deploy validated, open-source, peer-reviewed scientific software to create up-to-date, reliable, high-quality, and immediately usable data and visualizations. Our partners can leave the burden of this task, share the cost of data processing, and concentrate on what they do best: disseminating and advocating, researching, or setting sustainable business or underwriting indicators and creating early warning systems.\nImpact\nWe publish the data in a way that it is easy to find—as a separate data publication with a DOI, full library metadata, and place it in open science repositories. Our data is more findable than 99% of the open science data, and therefore makes far bigger impact. See our data on the European open science repository Zenodo managed by CERN (the European Organization for Nuclear Research). Easy-to-use data\nOur data follows the tidy data principle and comes with all the recommended Dublin Core and DataCite metadata. This increases our data compatibility, allowing users to open it in any spreadsheet …","date":1624406400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639267200,"objectID":"d1c094e920e3fd8fb5c5ce7b23200cf8","permalink":"https://reprex.nl/observatories/competition/","publishdate":"2021-06-23T00:00:00Z","relpermalink":"/observatories/competition/","section":"observatories","summary":"Our observatory is monitoring the certain segments of the European economy, and develops tools for computational antitrust in Europe.","tags":["Competition"],"title":"Competition Data Observatory","type":"observatories"},{"authors":["Daniel Antal"],"categories":null,"content":"If open data is the new gold, why even those who release fail to reuse it? We created an open collaboration of data curators and open-source developers to dig into novel open data sources and/or increase the usability of existing ones. We transform reproducible research software into research- as-service.\nEvery year, the EU announces that billions and billions of data are now “open” again, but this is not gold. At least not in the form of nicely minted gold coins, but in gold dust and nuggets found in the muddy banks of chilly rivers. There is no rush for it, because panning out its value requires a lot of hours of hard work. Our goal is to automate this work to make open data usable at scale, even in trustworthy AI solutions.\nThere is no rush for it, because panning out its value requires a lot of hours of hard work. Our goal is to automate this work to make open data usable at scale, even in trustworthy AI solutions. Most open data is not public, it is not downloadable from the Internet – in the EU parlance, “open” only means a legal entitlement to get access to it. And even in the rare cases when data is open and public, often it is mired by data quality issues. We are working on the prototypes of a data-as-service and research-as-service built with open-source statistical software that taps into various and often neglected open data sources.\nWe are in the prototype phase in June and our intentions are to have a well-functioning service by the time of the conference, because we are working only with open-source software elements; our technological readiness level is already very high. The novelty of our process is that we are trying to further develop and integrate a few open-source technology items into technologically and financially sustainable data-as-service and even research-as-service solutions.\nOur review of about 80 EU, UN and OECD data observatories reveals that most of them do not use these organizations’s open data - instead they use various, and often not well processed proprietary sources. We are taking a new and modern approach to the data observatory concept, and modernizing it with the application of 21st century data and metadata standards, the new results of reproducible research and data science. Various UN and OECD bodies, and particularly the European Union support or maintain more than 60 data observatories, or permanent data collection and dissemination points, but even these do not use these organizations and their members open data. We are building open-source data observatories, which run open-source statistical software that automatically processes and documents reusable public sector data (from public transport, meteorology, tax offices, taxpayer funded satellite systems, etc.) and reusable scientific data (from EU taxpayer funded research) into new, high quality statistical indicators.\nWe are taking a new and modern approach to the ‘data observatory’ concept, and modernizing it with the application of 21st century data and metadata standards, the new results of reproducible research and data science We are building various open-source data collection tools in R and Python to bring up data from big data APIs and legally open, but not public, and not well served data sources. For example, we are working on capturing representative data from the Spotify API or creating harmonized datasets from the Eurobarometer and Afrobarometer survey programs. Open data is usually not public; whatever is legally accessible is usually not ready to use for commercial or scientific purposes. In Europe, almost all taxpayer funded data is legally open for reuse, but it is usually stored in heterogeneous formats, processed into an original government or scientific need, and with various and low documentation standards. Our expert data curators are looking for new data sources that should be (re-) processed and re-documented to be usable for a wider community. We would like to introduce our service flow, which touches upon many important aspects of data scientist, data engineer and data curatorial work. We believe that even such generally trusted data sources as Eurostat often need to be reprocessed, because various legal and political constraints do not allow the common European statistical services to provide optimal quality data – for example, on the regional and city levels. With rOpenGov and other partners, we are creating open-source statistical software in R to re-process these heterogenous and low-quality data into tidy statistical indicators to automatically validate and document it. We are carefully documenting and releasing administrative, processing, and descriptive metadata, following international metadata standards, to make our data easy to find and easy to use for data analysts. We are automatically creating depositions and authoritative copies marked with an individual digital object identifier (DOI) to maintain data integrity. We are building simple databases and supporting APIs …","date":1624035600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624035600,"objectID":"a5962e972994ae1aa5811355d21781c6","permalink":"https://reprex.nl/post/2021-06-18-gold-without-rush/","publishdate":"2021-06-18T17:00:00Z","relpermalink":"/post/2021-06-18-gold-without-rush/","section":"post","summary":"If open data is the new gold, why even those who release fail to reuse it? We created an open collaboration of data curators and open-source developers to dig into novel open data sources and/or increase the usability of existing ones. We transform reproducible research software into research- as-service.","tags":["Open data","Open science","R","data collection"],"title":"Open Data - The New Gold Without the Rush","type":"post"},{"authors":["Daniel Antal","rOpenGov","leo_lahti","kasia_kulma"],"categories":null,"content":" The new version of our rOpenGov R package regions was released today on CRAN. This package is one of the engines of our experimental open data-as-service Green Deal Data Observatory , Economy Data Observatory , Digital Music Observatory prototypes, which aim to place open data packages into open-source applications.\nIn international comparison the use of nationally aggregated indicators often have many disadvantages: they inhibit very different levels of homogeneity, and data is often very limited in number of observations for a cross-sectional analysis. When comparing European countries, a few missing cases can limit the cross-section of countries to around 20 cases which disallows the use of many analytical methods. Working with sub-national statistics has many advantages: the similarity of the aggregation level and high number of observations can allow more precise control of model parameters and errors, and the number of observations grows from 20 to 200-300.\nThe change from national to sub-national level comes with a huge data processing price: internal administrative boundaries, their names, codes codes change very frequently. Yet the change from national to sub-national level comes with a huge data processing price. While national boundaries are relatively stable, with only a handful of changes in each recent decade. The change of national boundaries requires a more-or-less global consensus. But states are free to change their internal administrative boundaries, and they do it with large frequency. This means that the names, identification codes and boundary definitions of sub-national regions change very frequently. Joining data from different sources and different years can be very difficult.\nOur regions R package helps the data processing, validation and imputation of sub-national, regional datasets and their coding. There are numerous advantages of switching from a national level of the analysis to a sub-national level comes with a huge price in data processing, validation and imputation, and the regions package aims to help this process.\nYou can review the problem, and the code that created the two map comparisons, in the Maping Regional Data, Maping Metadata Problems vignette article of the package. A more detailed problem description can be found in Working With Regional, Sub-National Statistical Products.\nThis package is an offspring of the eurostat package on rOpenGov. It started as a tool to validate and re-code regional Eurostat statistics, but it aims to be a general solution for all sub-national statistics. It will be developed parallel with other rOpenGov packages.\nGet the Package You can install the development version from GitHub with:\ndevtools::install_github(\u0026#34;rOpenGov/regions\u0026#34;) or the released version from CRAN:\ninstall.packages(\u0026#34;regions\u0026#34;) You can review the complete package documentation on regions.dataobservaotry.eu. If you find any problems with the code, please raise an issue on Github. Pull requests are welcome if you agree with the Contributor Code of Conduct\nIf you use regions in your work, please cite the package as: Daniel Antal, Kasia Kulma, Istvan Zsoldos, \u0026amp; Leo Lahti. (2021, June 16). regions (Version 0.1.7). CRAN. http://doi.org/10.5281/zenodo.4965909\nJoin us Join our open collaboration Economy Data Observatory team as a data curator, developer or business developer. More interested in environmental impact analysis? Try our Green Deal Data Observatory team! Or your interest lies more in data governance, trustworthy AI and other digital market problems? Check out our Digital Music Observatory team!\n","date":1623844800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623844800,"objectID":"bddf0a5d0c8dcdea162b11029d3b81b5","permalink":"https://reprex.nl/post/2021-06-16-regions-release/","publishdate":"2021-06-16T12:00:00Z","relpermalink":"/post/2021-06-16-regions-release/","section":"post","summary":"There are numerous advantages of switching from a national level of the analysis to a sub-national level comes with a huge price in data processing, validation and imputation, and the regions package aims to help this process.","tags":["Open data","Open science","regional data","sub-national data","R","data collection"],"title":"There are Numerous Advantages of Switching from a National Level of the Analysis to a Sub National Level","type":"post"},{"authors":["Daniel Antal"],"categories":null,"content":" Open data is like gold in the mud below the chilly waves of mountain rivers. Panning it out requires a lot of patience, or a good machine. As the founder of the automated data observatories that are part of Reprex’s core activities, what type of data do you usually use in your day-to-day work?\nThe automated data observatories are results of syndicated research, data pooling, and other creative solutions to the problem of missing or hard-to-find data. The music industry is a very fragmented industry, where market research budgets and data are scattered in tens of thousands of small organizations in Europe. Working for the music and film industry as a data analyst and economist was always a pain because most of the efforts went into trying to find any data that can be analyzed. I spent most of the last 7-8 years trying to find any sort of information—from satellites to government archives—that could be formed into actionable data. I see three big sources of information: textual,numeric, and continuous recordings for on-site, offsite, and satellite sensors. I am much better with numbers than with natural language processing, and I am improving with sensory sources. But technically, I can mint any systematic information—the text of an old book, a satellite image, or an opinion poll—into datasets.\nFor you, what would be the ultimate dataset, or datasets that you would like to see in the Economy Data Observatory?\nI am a data scientist now, but I used to be a regulatory economist, and I have worked a lot with competition policy and monopoly regulation issues. Our observatories can automatically monitor market and environmental processes, which would allow us to get into computational antitrust. Peter Ormosi, our competition curator, is particularly interested in killer acquisitions: approved mergers of big companies that end up piling up patents that are not used. I am more interested in describing systematically which markets are getting more concentrated and more competitive, in real time. Does data concentration coincide with market concentration?\nTo bring an example from the realm of our Digital Music Observatory, which was a prototype to this one, I have been working for some time on creating streaming volume and price indexes, like the Dow Jones Industrial Average or the various bond market indexes, that talk more about price, demand, and potential revenue in music streaming markets all over the world. We did a first take on this in the Central European Music Industry Report and recently we iterated on the model for the UK Intellectual Property Office and the UK Music Creators’ Earnings project. We want to take this further to create a pan-Europe streaming market index, and we will be probably the first to actually be able to report on music market concentrations, and in fact, more or less in a real-time mode.\nWe would like to further developer our 20-country streaming indexes into a global music market index. Is there a number or piece of information that recently surprised you? If so, what was it?\nThere were a few numbers that surprised me, and some of them were brought up by our observatory teams. Karel is talking about the fact that not all green energy is green at all: many hydropower stations contribute to the greenhouse effect and not reduce it. Annette brought up the growing interest in the Dalmatian breed after the Disney 101 Dalmatians movies, and it reminded me of the astonishing growth in interest for chess sets, chess tutorials, and platform subscriptions after the success of Netflix’s The Queen’s Gambit.\nThe Queen’s Gambit’ Chess Boom Moves Online By Rachael Dottle on bloomberg.com Annette is talking about the importance of cultural influencers, and on that theme, what could be more exciting that Netflix’s biggest success so far is not a detective series or a soap opera but a coming-of-age story of a female chess prodigy. Intelligence is sexy, and we are in the intelligence business.\nBut to tell a more serious and more sobering number, I recently read with surprise that there are more people smoking cigarettes on Earth in 2021 than in 1990. Population growth in developing countries replaced the shrinking number of developed country smokers. While I live in Europe, where smoking is strongly declining, it reminds me that Europe’s population is a small part of the world. We cannot take for granted that our home-grown experiences about the world are globally valid.\nDo you have a good example of really good, or really bad use of data?\nFiveThirtyEight.com had a wonderful podcast series, produced by Jody Avirgan, called What’s the Point. It is exactly about good and bad uses of data, and each episode is super interesting. Maybe the most memorable is Why the Bronx Really Burned. New York City tried to measure fire response times, identify redundancies in service, and close or re-allocate fire stations accordingly. What resulted, though, was a perfect storm of bad data: The methodology was flawed, the …","date":1623308400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623315600,"objectID":"3e8ae6bc2572e2e950d012bbe16a1c35","permalink":"https://reprex.nl/post/2021-06-10-founder-daniel-antal/","publishdate":"2021-06-10T07:00:00Z","relpermalink":"/post/2021-06-10-founder-daniel-antal/","section":"post","summary":"Open data is like gold in the mud below the chilly waves of mountain rivers. Panning it out requires a lot of patience, or a good machine. I think we will come to as surprising and strong findings as Bellingcat, but we are not focusing on individual events and stories, but on social and environmental processes and changes.","tags":["Open data","Open science","trustworthy AI","service-design","data collection"],"title":"Open Data is Like Gold in the Mud Below the Chilly Waves of Mountain Rivers","type":"post"},{"authors":["pyry_kantanen"],"categories":null,"content":"As a developer at rOpenGov, and as an economic sociologist, what type of data do you usually use in your work?\nGenerally speaking, people’s access to (or inequalities in accessing) different types of resources and their ability in transforming these resources to other types of resources is what interests me. The data I usually work with is the kind of data that is actually nicely covered by existing rOpenGov tools: data about population demographics and administrative units from Statistics Finland, statistical information on welfare and health from Sotkanet and also data from Eurostat. Aside from these a lot of information is of course data from surveys and texts scraped from the internet.\nWe are placing the growing number of rOpenGov tools in a modern application with a user-friendly service and a modern data API. In your ideal data world, what would be the ultimate dataset, or datasets that you would like to see in the Music Data Observatory?\nLate spring and early summer time is, at least for me, defined by the Eurovision Song Contest. Every year watching the contest makes me ponder the state of the music industry in my home country Finland as well as in Europe. Was the song produced by homegrown talent or was it imported? Was it better received by the professional jury or the public? How well does the domestic appeal of an artist translate to the international stage? Many interesting phenomena are difficult to quantify in a meaningful way and writing a catchy song with international appeal is probably more an art than a science. Nevertheless that should not deter us from trying as music, too, is bound by certain rules and regularities that can be researched.\nMusic, too, is bound by certain rules and regularities that can be researched. Our Digital Music Observatory and its Listen Local experimental App does this exactly, and we would love to create Eurovision musicology datasets. Photo: Eurovision Song Contest 2021 press photo by Jordy Brada Why did you decide to join the EU Datathon challenge team and why do you think that this would be a game changer for researchers and policymakers?\nThe challenge has, in my opinion, great potential in leading by example when it comes to open data access and reproducible research. Comparing data to oil is a common phrase but fitting in the sense that crude oil has to go through a number of steps and pipes before it becomes useful. Most users and especially policymakers appreciate ease-of-use of the finished product, but the quality of the product and the process must also be guaranteed somehow. Openness and peer-review practices are the best guarantors in the field of data, just as industrial standards and regulations are in the oil industry.\nWe provide many layers of fully transparent quality control about the data we are placing in our data APIs and provide for our end-users. Join us Join our open collaboration Economy Data Observatory team as a data curator, developer or business developer. More interested in environmental impact analysis? Try our Green Deal Data Observatory team! Or your interest lies more in data governance, trustworthy AI and other digital market problems? Check out our Digital Music Observatory team!\n","date":1623060000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623060000,"objectID":"fdb475346ab7d01f9ead6530e48ade00","permalink":"https://reprex.nl/post/2021-06-07-data-curator-pyry-kantanen/","publishdate":"2021-06-07T10:00:00Z","relpermalink":"/post/2021-06-07-data-curator-pyry-kantanen/","section":"post","summary":"Many interesting phenomena are difficult to quantify in a meaningful way and writing a catchy song with international appeal is probably more an art than a science. Nevertheless that should not deter us from trying as music, too, is bound by certain rules and regularities that can be researched.","tags":["Open data","Open science","Reproducible research","open government","Eurovision","musicology"],"title":"Comparing Data to Oil is a Cliché: Crude Oil Has to Go Through a Number of Steps and Pipes Before it Becomes Useful","type":"post"},{"authors":["leo_lahti"],"categories":null,"content":"As a developer at rOpenGov, what type of data do you usually use in your work?\nAs an academic data scientist whose research focuses on the development of general-purpose algorithmic methods, I work with a range of applications from life sciences to humanities. Population studies play a big role in our research, and often the information that we can draw from public sources - geospatial, demographic, environmental - provides invaluable support. We typically use open data in combination with sensitive research data but some of the research questions can be readily addressed based on open data from statistical authorities such as Statistics Finland or Eurostat.\nIn your ideal data world, what would be the ultimate dataset, or datasets that you would like to see in the Music Data Observatory?\nOne line of our research analyses the historical trends and spread of knowledge production, in particular book printing based on large-scale metadata collections. It would be interesting to extend this research to music, to understand the contemporary trends as well as the broader historical developments. Gaining access to a large systematic collection of music and composition data from different countries across long periods of time would make this possible.\nWhy did you decide to join the challenge and why do you think that this would be a game changer for researchers and policymakers?\nJoining the challenge was a natural development based on our overall activities in this area; the rOpenGov project has been around for a decade now, since the early days of the broader open data movement. This has also created an active international developer network and we felt well equipped for picking up the challenge. The game changer for researchers is that the project highlights the importance of data quality, even when dealing with official statistics, and provides new methods to solve these issues efficiently through the open collaboration model. For policymakers, this provides access to new high-quality curated data and case studies that can support evidence-based decision-making.\nDo you have a favorite, or most used open governmental or open science data source? What do you think about it? Could it be improved?\nRegarding open government data, one of my favorites is not a single data source but a data representation standard. The px format is widely used by statistical authorities in various countries, and this has allowed us to create R tools that allow the retrieval and analysis of official statistics from many countries across Europe, spanning dozens of statistical institutions. Standardization of open data formats allows us to build robust algorithmic tools for downstream data analysis and visualization. Open government data is still too often shared in obscure, non-standard or closed-source file formats and this is creating significant bottlenecks for the development of scalable and interoperable AI and machine learning methods that can harness the full potential of open data.\nRegarding open government data, one of my favorites is not a single data source but a data representation standard, the Px format. From your perspective, what do you see being the greatest problem with open data in 2021?\nAlthough there are a variety of open data sources available (and the numbers continue to increase), the availability of open algorithmic tools to interpret and communicate open data efficiently is lagging behind. One of the greatest challenges for open data in 2021 is to demonstrate how we can maximize the potential of open data by designing smart tools for open data analytics.\nWhat can our automated data observatories do to make open data more credible in the European economic policy community and be accepted as verified information?\nThe role of the professional network backing up the project, and the possibility of getting critical feedback and later adoption by the academic communities will support the efforts. Transparency of the data harmonization operations is the key to credibility, and will be further supported by concrete benchmarks that highlight the critical differences in drawing conclusions based on original sources versus the harmonized high-quality data sets.\nWe need to get critical feedback and later adoption by the academic communities. How we can ensure the long-term sustainability of the efforts?\nThe extent of open data space is such that no single individual or institution can address all the emerging needs in this area. The open developer networks play a huge role in the development of algorithmic methods, and strong communities have developed around specific open data analytical environments such as R, Python, and Julia. These communities support networked collaboration and provide services such as software peer review. The long-term sustainability will depend on the support that such developer communities can receive, both from individual contributors as well as from institutions and governments.\nJoin our open …","date":1622800800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622800800,"objectID":"fcf382863b28f6f8f721290cf2d05608","permalink":"https://reprex.nl/post/2021-06-04-developer-leo-lahti/","publishdate":"2021-06-04T10:00:00Z","relpermalink":"/post/2021-06-04-developer-leo-lahti/","section":"post","summary":"Although there are a variety of open data sources available (and the numbers continue to increase), the availability of open algorithmic tools to interpret and communicate open data efficiently is lagging behind. One of the greatest challenges for open data in 2021 is to demonstrate how we can maximize the potential of open data by designing smart tools for open data analytics.","tags":["Open data","Open science","Reproducible research","open government","R"],"title":"Creating Algorithmic Tools to Interpret and Communicate Open Data Efficiently","type":"post"},{"authors":["Daniel Antal"],"categories":null,"content":"We have released a new version of iotables as part of the rOpenGov project. The package, as the name suggests, works with European symmetric input-output tables (SIOTs). SIOTs are among the most complex governmental statistical products. They show how each country’s 64 agricultural, industrial, service, and sometimes household sectors relate to each other. They are estimated from various components of the GDP, tax collection, at least every five years.\nSIOTs offer great value to policy-makers and analysts to make more than educated guesses on how a million euros, pounds or Czech korunas spent on a certain sector will impact other sectors of the economy, employment or GDP. What happens when a bank starts to give new loans and advertise them? How is an increase in economic activity going to affect the amount of wages paid and and where will consumers most likely spend their wages? As the national economies begin to reopen after COVID-19 pandemic lockdowns, is to utilize SIOTs to calculate direct and indirect employment effects or value added effects of government grant programs to sectors such as cultural and creative industries or actors such as venues for performing arts, movie theaters, bars and restaurants.\nMaking such calculations requires a bit of matrix algebra, and understanding of input-output economics, direct, indirect effects, and multipliers. Economists, grant designers, policy makers have those skills, but until now, such calculations were either made in cumbersome Excel sheets, or proprietary software, as the key to these calculations is to keep vectors and matrices, which have at least one dimension of 64, perfectly aligned. We made this process reproducible with iotables and eurostat on rOpenGov\nOur iotables package creates direct, indirect effects and multipliers programatically. Our observatory will make those indicators available for all European countries. Accessing and tidying the data programmatically The iotables package is in a way an extension to the eurostat R package, which provides a programmatic access to the Eurostat data warehouse. The reason for releasing a new package is that working with SIOTs requires plenty of meticulous data wrangling based on various metadata sources, apart from actually accessing the data itself. When working with matrix equations, the bar is higher than with tidy data. Not only your rows and columns must match, but their ordering must strictly conform the quadrants of the a matrix system, including the connecting trade or tax matrices.\nWhen you download a country’s SIOT table, you receive a long form data frame, a very-very long one, which contains the matrix values and their labels like this:\n## Table naio_10_cp1700 cached at C:\\Users\\...\\Temp\\RtmpGQF4gr/eurostat/naio_10_cp1700_date_code_FF.rds # we save it for further reference here saveRDS(naio_10_cp1700, \u0026#34;not_included/naio_10_cp1700_date_code_FF.rds\u0026#34;) # should you need to retrieve the large tempfiles, they are in dir (file.path(tempdir(), \u0026#34;eurostat\u0026#34;)) dplyr::slice_head(naio_10_cp1700, n = 5) ## # A tibble: 5 x 7 ## unit stk_flow induse prod_na geo time values ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; \u0026lt;dbl\u0026gt; ## 1 MIO_EUR DOM CPA_A01 B1G EA19 2019-01-01 141873. ## 2 MIO_EUR DOM CPA_A01 B1G EU27_2020 2019-01-01 174976. ## 3 MIO_EUR DOM CPA_A01 B1G EU28 2019-01-01 187814. ## 4 MIO_EUR DOM CPA_A01 B2A3G EA19 2019-01-01 0 ## 5 MIO_EUR DOM CPA_A01 B2A3G EU27_2020 2019-01-01 0 The metadata reads like this: the units are in millions of euros, we are analyzing domestic flows, and the national account items B1-B2 for the industry A01. The information of a 64x64 matrix (the SIOT) and its connecting matrices, such as taxes, or employment, or C**O2 emissions, must be placed exactly in one correct ordering of columns and rows. Every single data wrangling error will usually lead in an error (the matrix equation has no solution), or, what is worse, in a very difficult to trace algebraic error. Our package not only labels this data meaningfully, but creates very tidy data frames that contain each necessary matrix of vector with a key column.\niotables package contains the vocabularies (abbreviations and human readable labels) of three statistical vocabularies: the so called COICOP product codes, the NACE industry codes, and the vocabulary of the ESA2010 definition of national accounts (which is the government equivalent of corporate accounting).\nOur package currently solves all equations for direct, indirect effects, multipliers and inter-industry linkages. Backward linkages show what happens with the suppliers of an industry, such as catering or advertising in the case of music festivals, if the festivals reopen. The forward linkages show how much extra demand this creates for connecting services that treat festivals as a ‘supplier’, such as cultural tourism.\nLet’s seen an example ## Downloading employment data from the Eurostat database. ## Table lfsq_egan22d cached at …","date":1622736000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622736000,"objectID":"fc5992af6c8de60c64b311b09922b493","permalink":"https://reprex.nl/post/2021-06-03-iotables-release/","publishdate":"2021-06-03T16:00:00Z","relpermalink":"/post/2021-06-03-iotables-release/","section":"post","summary":"rOpenGov, Reprex, and other open collaboration partners teamed up to build on our expertise of open source statistical software development further: we want to create a technologically and financially feasible data-as-service to put our reproducible research products into wider user for the business analyst, scientific researcher and evidence-based policy design communities. Our new release will help with automated economic impact and environmental impact analysis.","tags":["open-data","open-science","iotables","datathon","economic impact analysis","environmental impact analysis"],"title":"Economic and Environment Impact Analysis, Automated for Data-as-Service","type":"post"},{"authors":["peter_ormosi"],"categories":null,"content":"As someone who’s worked in data for almost 20 years, what type of data do you usually use in your research?\nIn my field (industrial organisation, competition policy), company level financial data, and product price and sales data have been the conventional building blocks of research papers. Ideally this has been the sort of data that I would seek out for my work. Of course as academic researchers we often get knocked back by the reality of data access and availability. I would think that industrial organisation is one of those fields where researchers have to be quite innovative in terms of answering interesting and relevant policy questions, whilst having to operate in an environment where most relevant data is proprietary and very expensive. Against this backdrop, I have worked with neatly organised proprietary datasets, self-assembled data collections, and also textual data.\nFrom your experience working with various data sets, models, and frameworks, what would be the ultimate dataset, or datasets that you would like to see from the Economy Data Observatory?\nThere seems to be an emerging consensus that market concentration and markups have been continuously increasing across the economy. But most of these works use industry classification to define markets. One of the things I’d really like to see coming out of the Economy Data Observatory is a mapping of what we call antitrust markets.\nMapping NACE to Antitrust Markets. Available datasets use standard industry classification (such as NACE in the EU), which is often very different from what we call a product market in microeconomics. Product markets are defined by demand, and supply-side substitutability, which is a dynamically evolving feature and difficult to capture systematically on a wider scale. But with the recent proliferation of data and the growth (and fall in price) of computing power, I am positive that we could attempt to map out the European economy along these product market boundaries. Of course this is not without any challenge. For example in digital markets, traditional ways to define markets have caused serious challenges to competition authorities around the world.\nI believe that there is an immensely rich, and largely unexplored source of information in unstructured textual data that would be hugely useful for applied microeconomic works, including my own area of IO and competition policy. This includes a large corpus of administrative and court decisions that relate to businesses, such as merger control decisions of the European Commission. To give two examples from my experience, we’ve used a large corpus of news reports related to various firms to gauge the reputational impact of European Commission cartel investigations, or we’ve trained an algorithm to be able to classify US legislative bills and predict whether they have been lobbied or not. Finding a way to collect and convert this unstructured data into a format that is relevant and useful for users is not a trivial challenge, but is one of the most exciting parts of our Economy Data Observatory plans (see related project plan).\nFinding a way to collect and convert this unstructured data into a format that is relevant and useful for users is not a trivial challenge, but is one of the most exciting parts of our Economy Data Observatory plans. What is an idea that you consider will be a game changer for researchers and/or policymakers?\nPartly talking in the past tense, the use of data driven approaches, automation in research, and machine learning have been increasingly influential and I think this trend will continue to all areas of social science. 10 years ago, to do machine learning, you had to build your models from scratch, typically requiring a solid understanding of programming and linear algebra. Today, there are readily available deep learning frameworks like TensorFlow, Keras, PyTorch, to design a neural network for your own application. 10 years ago, natural language processing would have only been relevant for a small group of computational linguists. Today we have massive word embedding models trained on an enormous corpus of texts, at the fingertip of any researcher. 10 years ago, the cost of computing power would have made it prohibitive for most researchers to run even relatively shallow neural networks. Today, I can run complex deep learning models on my laptop using cloud computing servers. As a result of these developments, whereas 10 years ago one would have needed a small (or large) research team to explore certain research questions, much of this can now be automated and be done by a single researcher. For researchers without access to large research grants and without the ability to hire a research team, this has truly been an amazing victory for the democratisation of research.\nYou can already try out our API. Do you have a favorite, or most used open governmental or open science data source? What do you think about it? Could it be improved?\nAs a …","date":1622653200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622653200,"objectID":"90e3f33d7c682514f515b645293537eb","permalink":"https://reprex.nl/post/2021-06-02-data-curator-peter-ormosi/","publishdate":"2021-06-02T17:00:00Z","relpermalink":"/post/2021-06-02-data-curator-peter-ormosi/","section":"post","summary":"I believe that there is an immensely rich, and largely unexplored source of information in unstructured textual data that would be hugely useful for applied microeconomic works, including my own area of IO and competition policy.","tags":["Open data","Open science,","Computational antitrust","Curators","Economics"],"title":"New Indicators for Computational Antitrust","type":"post"},{"authors":["Daniel Antal","Botond Vitos"],"categories":null,"content":"Our observatory has a new data API which allows access to our daily refreshing open data. You can access the API via api.economy.dataobservatory.eu (apologies for the ugly, temporary subdomain masking!).\nAll the data and the metadata are available as open data, without database use restrictions, under the ODbL license. However, the metadata contents are not finalized yet. We are currently working on a solution that applies the FAIR Guiding Principles for scientific data management and stewardship, and fulfills the mandatory requirements of the Dublic Core metadata standards and at the same time the mandatory requirements, and most of the recommended requirements of DataCite. These changes will be effective before 1 July 2021.\nThe Competition Data Observatory temporarily shares an API with the Economy Data Observatory, which serves as an incubator for similar economy-oriented reproducible research resources.\nIndicator table The indicator table contains the actual values, and the various estimated/imputed values of the indicator, clearly marking missing values, too.\napi.economy.dataobservatory.eu: indicator retrieval You can get the data in CSV or json format, or write SQL querries. (Tutorials in SQL, R, Python will be posted shortly.)\nDescription metadata table Processing Metadata table The metadata table contains various data processing information, such as the first and last actual observation of the indicator, the number of approximated, forecasted, backcasted values, last update at source and in our system, and so on.\napi.economy.dataobservatory.eu: processing metadata Authoritative Copies Greendeal Data Observatory on Zenodo\n","date":1622545200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625655600,"objectID":"1fa58637f02a8941c5b61274a0207f37","permalink":"https://reprex.nl/data/api/","publishdate":"2021-06-01T11:00:00Z","relpermalink":"/data/api/","section":"data","summary":"Get data from the Competition Data Observatory via our API","tags":["api"],"title":"Data API","type":"data"},{"authors":["Daniel Antal"],"categories":null,"content":"Our observatory has a new data API which allows access to our daily refreshing open data. You can access the API via api.economy.dataobservatory.eu (apologies for the ugly, temporary subdomain masking!).\nAll the data and the metadata are available as open data, without database use restrictions, under the ODbL license. However, the metadata contents are not finalized yet. We are currently working on a solution that applies the FAIR Guiding Principles for scientific data management and stewardship, and fulfills the mandatory requirements of the Dublic Core metadata standards and at the same time the mandatory requirements, and most of the recommended requirements of DataCite. These changes will be effective before 1 July 2021.\nThe Competition Data Observatory temporarily shares an API with the Economy Data Observatory, which serves as an incubator for similar economy-oriented reproducible research resources.\napi.economy.dataobservatory.eu: processing metadata Descriptive Metadata Identifier An unambiguous reference to the resource within a given context. (Dublin Core item), but several identifiders allowed, and we will use several of them. Creator The main researchers involved in producing the data, or the authors of the publication, in priority order. To supply multiple creators, repeat this property. (Extends the Dublin Core with multiple authors, and legal persons, and adds affiliation data.) Title A name given to the resource. Extends Dublin Core with alternative title, subtitle, translated Title, and other title(s). Publisher The name of the entity that holds, archives, publishes prints, distributes, releases, issues, or produces the resource. This property will be used to formulate the citation, so consider the prominence of the role. For software, use Publisher for the code repository. (Dublin Core item.) Publication Year The year when the data was or will be made publicly available. Resource Type We publish Datasets, Images, Report, and Data Papers. (Dublin Core item with controlled vocabulary.) Recommended for discovery The Recommended (R) properties are optional, but strongly recommended for interoperability.\nSubject The topic of the resource. (Dublin Core item.) Contributor The institution or person responsible for collecting, managing, distributing, or otherwise contributing to the development of the resource. (Extends the Dublin Core with multiple authors, and legal persons, and adds affiliation data.) When applicable, we add Distributor (of the datasets and images), Contact Person, Data Collector, Data Curator, Data Manager, Hosting Institution, Producer (for images), Project Manager, Researcher, Research Group, Rightsholder, Sponsor, Supervisor Date A point or period of time associated with an event in the lifecycle of the resource, besides the Dublin Core minimum we add Collected, Created, Issued, Updated, and if necessary, Withdrawn dates to our datasets. Related Identifier An identifier or identifiers other than the primary Identifier applied to the resource being registered. Rights We give SPDX License List standards rights description with URLs to the actual license. (Dublin Core item: Rights Management) Description Recommended for discovery.(Dublin Core item.) GeoLocation Similar to Dublin Core item Coverage The Subject property: we need to set standard coding schemas for each observatory. Contributor property: DataCurator the curator of the dataset, who sets the mandatory properties. DataManager the person who keeps the dataset up-to-date. ContactPerson the person who can be contacted for reuse requests or bug reports. The Date property contains the following dates, which are set automatically by the dataobservatory R package: Updated when the dataset was updated; EarliestObservation, which the earliest, not backcasted, estimated or imputed observation. LatestObservation, which the earliest, not backcasted, estimated or imputed observation. UpdatedatSource, when the raw data source was last updated. The GeoLocation is automatically created by the dataobservatory R package. The Description property optional elements, and we adopted them as follows for the observatories: The Abstract is a short, textual description; we try to automate its creation as much as a possible, but some curatorial input is necessary. In the TechnicalInfo sub-field, we record automatically the utils::sessionInfo() for computational reproducability. This is automatically created by the dataobservatory R package. In the Other sub-field, we record the keywords for structuring the observatory. Optional The Optional (O) properties are optional and provide richer description. For findability they are not so important, but to create a web service, they are essential. In the mandatory and recommended fields, we are following other metadata standards and codelists, but in the optional fields we have to build up our own system for the observatories.\nLanguage A language of the resource. (Dublin Core item.) Alternative …","date":1622545200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625735400,"objectID":"882a6a70ec8965c6a0246cec45271324","permalink":"https://reprex.nl/data/metadata/","publishdate":"2021-06-01T11:00:00Z","relpermalink":"/data/metadata/","section":"data","summary":"Uncut diamonds need to be cut, polished, and you have to make sure that they come from a legal source.","tags":["metadata"],"title":"Metadata","type":"data"},{"authors":["Daniel Antal","Andrés García Molina"],"categories":null,"content":"Reprex, a Dutch start-up enterprise formed to utilize open source software and open data, is looking for partners in an agile, open collaboration to win at least one of the three EU Datathon Prizes. We are looking for policy partners, academic partners and a consultancy partner. Our project is based on agile, open collaboration with three types of contributors.\nWith our competing prototypes we want to show that we have a research automation technology that can find open data, process it and validate it into high-quality business, policy or scientific indicators, and release it with daily refreshments in a modern API.\nWe are looking for institutions to challenge us with their data problems, and sponsors to increase our capacity. Over then next 5 months, we need to find a sustainable business model for a high-quality and open alternative to other public data programs.\nThe EU Datathon 2021 Challenge To take part, you should propose the development of an application that links and uses open datasets. - our data curator team\nYour application … is also expected to find suitable new approaches and solutions to help Europe achieve important goals set by the European Commission through the use of open data.” - this application is developed by our technology contributors\nYour application should showcase opportunities for concrete business models or social enterprises. - our service development team is working to make this happen!\nWe use open source software and open data. The applications are hosted on the cloud resources of Reprex, an early-stage technology startup currently building a viable, open-source, open-data business model to create reproducible research products.\nWe are working together with experts in the domain as curators (check out our guidelines if you want to join: Data Curators: Get Inspired!).\nOur development team works on an open collaboration basis. Our indicator R packages, and our services are developed together with rOpenGov.\nMission statement We want to win an EU Datathon prize by processing the vast, already-available governmental and scientific open data made usable for policy-makers, scientific researchers, and business researcher end-users.\n“To take part, you should propose the development of an application that links and uses open datasets. Your application should showcase opportunities for concrete business models or social enterprises. It is also expected to find suitable new approaches and solutions to help Europe achieve important goals set by the European Commission through the use of open data.”\nWe aim to win at least one first prize in the EU Datathon 2021. We are contesting all three challenges, which are related to the EU’s official strategic policies for the coming decade.\nChallenge 1: A European Grean Deel Our Green Deal Data Observatory connects socio-economic and environmental data to help understanding and combating climate change. Challenge 1: A European Green Deal, with a particular focus on the The European Climate Pact, the Organic Action Plan, and the New European Bauhaus, i.e., mitigation strategies.\nClimate change and environmental degradation are an existential threat to Europe and the world. To overcome these challenges, the European Union created the European Green Deal strategic plan, which aims to make the EU’s economy sustainable by turning climate and environmental challenges into opportunities and making the transition just and inclusive for all.\nOur Green Deal Data Observatory is a modern reimagination of existing ‘data observatories’; currently, there are over 70 permanent international data collection and dissemination points. One of our objectives is to understand why the dozens of the EU’s observatories do not use open data and reproducible research. We want to show that open governmental data, open science, and reproducible research can lead to a higher quality and faster data ecosystem that fosters growth for policy, business, and academic data users.\nWe provide high quality, tidy data through a modern API which enables data flows between public and proprietary databases. We believe that introducing Open Policy Analysis standards with open data, open-source software, and research automation, can help the Green Deal policymaking process. Our collaboration is open for individuals, citizens scientists, research institutes, NGOS, and companies.\nChallenge 2: A Europe fit for the digital age Our Economy Data Observatory will focus on competition, small and medium sized enterprizes and robotization. Challenge 2: An economy that works for people, with a particular focus on the Single market strategy, and particular attention to the strategy’s goals of 1. Modernising our standards system, 2. Consolidating Europe’s intellectual property framework, and 3. Enabling the balanced development of the collaborative economy strategic goals.\nBig data and automation create new inequalities and injustices and have the potential to create a jobless growth economy. Our …","date":1621627200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622041200,"objectID":"f80ec31b8781fc70a9f26fd4288e4450","permalink":"https://reprex.nl/post/2021-05-21-eu-datathon-2021/","publishdate":"2021-05-21T20:00:00Z","relpermalink":"/post/2021-05-21-eu-datathon-2021/","section":"post","summary":"Reprex, a Dutch start-up enterprise formed to utilize open source software and open data in open collaboration with its partners is contesting all three challenges of the EU Datathon 2021 Prizes.","tags":["open-data","open-science","data-altruism","data-observatory","datathon","competition"],"title":"Reprex is Contesting all Three Challenges of the EU Datathon 2021 Prize","type":"post"},{"authors":null,"categories":null,"content":"we would like to actively encourage the sharing of data assets.\n","date":1621123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621123200,"objectID":"ebd4557c0a6e81227426e984ce16d9a4","permalink":"https://reprex.nl/data/data-sharing/","publishdate":"2021-05-16T00:00:00Z","relpermalink":"/data/data-sharing/","section":"data","summary":"Data altruismm, sharing, and collaborative data resources.","tags":["data-sharing","data-altruism"],"title":"Data Sharing","type":"data"},{"authors":null,"categories":null,"content":"Many countries in the world allow access to a vast array of information, such as documents under freedom of information requests, statistics, datasets. In the European Union, most taxpayer financed data in government administration, transport, or meteorology, for example, can be usually re-used. More and more scientific output is expected to be reviewable and reproducible, which implies open access.\nWhat’s the Problem with Open Data? How We Add Value? Is There Value in It? If it’s money on the street, why nobody’s picking it up? Datasets Should Work Together to Give InformationData is only potential information, raw and unprocessed. What’s the Problem with Open Data? “Data is stuff. It is raw, unprocessed, possibly even untouched by human hands, unviewed by human eyes, un-thought-about by human minds.” [1]\nMost open data cannot be just “downloaded.” Often, you need to put more than $100 value of work into processing, validating, documenting a dataset that is worth $100. But you can share this investment with our data observatories. Open data is almost always lacking of documentation, and no clear references to validate if the data is reliable or not corrupted. This is why we always start with reprocessing and redocumenting. Our review of about 80 EU, UN and OECD data observatories reveals that most of them do not use these organizations’s open data - instead they use various, and often not well processed proprietary sources. Read more: Open Data - The New Gold Without the Rush\nHow We Add Value? We believe that even such generally trusted data sources as Eurostat often need to be reprocessed, because various legal and political constraints do not allow the common European statistical services to provide optimal quality data – for example, on the regional and city levels. With rOpenGov and other partners, we are creating open-source statistical software in R to re-process these heterogenous and low-quality data into tidy statistical indicators to automatically validate and document it. Metadata is a potentially informative data record about a potentially informative dataset. We are carefully documenting and releasing administrative, processing, and descriptive metadata, following international metadata standards, to make our data easy to find and easy to use for data analysts. We are automatically creating depositions and authoritative copies marked with an individual digital object identifier (DOI) to maintain data integrity. Is There Value in Open Data? A well-known story tells of a finance professor and a student who come across a $100 bill lying on the ground. As the student stops to pick it up, the professor says, “Don’t bother—if it were really a $100 bill, it wouldn’t be there.”\nBut this is not the case with open data. Often, you need to put more than $100 into processing, validating, documenting a dataset that is worth $100.\nIn the EU, open data is governed by the Directive on open data and the re-use of public sector information - in short: Open Data Directive (EU) 2019 / 1024. It entered into force on 16 July 2019. It replaces the Public Sector Information Directive, also known as the PSI Directive which dated from 2003 and was subsequently amended in 2013.\nOpen Data is potentially useful data that can potentially replace costlier or hard to get data sources to build information. It is analogous to potential energy: work is required to release it. We build automated systems that reduce this work and increase the likelihood that open data will offer the best value for money.\nMost open data is not publicy accessible, and available upon request. Our real curatorial advantage is that we know where it is and how to get this request processed. Most European open data comes from tax authorities, meteorological offices, managers of transport infrastructure, and other governmental bodies whose data needs are very different from yours. Their data must be carefully evaluated, re-processed, and if necessary, imputed to be usable for your scientific, business or policy goals. The use of open science data is problematic in different ways: usually understanding the data documentation requires domain-specific specialist knowledge. Open science data is even more scattered and difficult to access than technically open, but not public governmental data. From Datasets to Data Integration, Data to Information “Data is only potential information, raw and unprocessed, prior to anyone actually being informed by it.” ^[2]\nWe are building simple databases and supporting APIs that release the data without restrictions, in a tidy format that is easy to join with other data, or easy to join into databases, together with standardized metadata. Our service flow and value chain FAQ Why Downloading Does Not Work? Most open data is not available on the internet. If it is available, it is not in a form that you can easily import into a spreadsheet application like Excel or OpenOffice, or into a statistical application like SPSS or …","date":1621123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624633200,"objectID":"c02f0e35bf46fd958fd3ec2bd0a929fb","permalink":"https://reprex.nl/data/open-gov/","publishdate":"2021-05-16T00:00:00Z","relpermalink":"/data/open-gov/","section":"data","summary":"Many countries in the world allow access to a vast array of information, such as documents under freedom of information requests, statistics, datasets. In the European Union, most taxpayer financed data in government administration, transport, or meteorology, for example, can be usually re-used. More and more scientific output is expected to be reviewable and reproducible, which implies open access.","tags":["open-data","FOI","PSI"],"title":"Open Data","type":"data"},{"authors":null,"categories":null,"content":" OpenMusE brings together music industry stakeholders and researchers from 11 EU countries and Ukraine. Our consortium recognises that placing European music ecosystems on a more competitive, fair, and sustainable footing requires evidence-based policymaking, business planning, and accuracy.\nWe provide the data needed for these actions. Using transparent methods and tools, OpenMusE maps the policy and data landscape; bridges data gaps; and empowers stakeholders and policymakers to take data-driven actions. Our project is grounded on principles of open policy analysis, open science, and open-source software development. We work with stakeholders to identify data gaps on the EU, national, and regional levels; co-create indicators and methods for bridging them; develop free software tools for data collection and analysis; and report not just our findings, but every step taken to reach them.\nThis is the logic behind our Open Music Observatory (OMO, developed from the earlier CEEMID and the Digital Music Observatory concept), an open-source platform that provides 360-degree intelligence on the music industry by integrating numerous data sources. The OMO is highly automated, providing “living policy documents” that refresh when the backend datasets are updated: these datasets include official statistics on music goods and services; data on musical participation via pan-European surveys, rights-holder data voluntarily shared by industry partners, and streaming service data sampled using novel algorithms developed by our consortium. Using the OMO and our open-source software, music MSMEs without technical departments or expertise will be able to access and analyse open data; model volume and value, including of zero-price uses; create better business models; and generate corporate social responsibility and sustainability reports; all at a fraction of current costs. We validate these tools in four pilot studies that will bring concrete benefits to stakeholders within the project lifespan.\nThe Open Music Observatory is not an alternative to the legal structure of the European Music Observatory. It is an open project that shows how the best practice of open knowledge managements, the use of the Open Data Directive and the Open Policy Analysis framework, with the new instruments of data altruism and the Data Governance Act can help building an observatory that can fulfill most of the purposes of the European Music Observatory—and remain open for global music industry players, too. See our planned data correspondence to the planned European Music Observatory pillars at the end of this document. Open collaboration Our project is based on open collaboration. Our proposal, will provide us with resources to supply further music businesses, music civil society organizations and researchers with high-quality data (during the duration of the project for free.) The open collaboration means that\nwe will ask all representative music organizations to join our advisory board and set priorities so that we can work for the benefit of all the European Music Ecosystem. our improved valuation, ESG/SDG reporting, diversity promotion tools will be open for national public organizations and businesses to use; for-profit and non-profit organizations who are not members of our Consortium can solve in the form of public use case studies some of their valuation/ESG; reporting/diversity measurement issues provided that they pay for their own project management and translations costs; our cases studies intended to improve the economic situation, resilience and diversity problems of organizations in the Consortium can be freely replicated with our online tools, live policy documents, and our Open Data Observatory. See existing business partners, civil society \u0026amp; social enterprise partners and academic partners.\nThe project’s scoping aim is to create an open, scalable data-to-policy pipeline for European music ecosystems.\nMAP the policy and data landscape all over Europe, but with a focus on select countries BRIDGE data gaps with open data that anybody can use EMPOWER stakeholders and policymakers to take data-driven actions The objectives are designed to advance the state of the art with regard to data collection, policymaking, and business practices in these three pillars of the music industry. Both the objectives and the outputs will be optimised for transferability to other cultural and creative industries.\nMAP the policy and data landscape all over Europe “Develop indicators to better detect the performance of the European music sector and its contribution to economic and social development, as well as to sustainability”\nDevelop policy-relevant indicators for the total economic value of music Develop policy-relevant indicators for music diversity and circulation Develop policy-relevant indicators for the societal impact of music ecosystems, within an SDG framework Develop policy-relevant indicators for the resilience of music ecosystems, …","date":1620323520,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659120720,"objectID":"d0fd2327fb2e29bb76b378696ea91e2c","permalink":"https://reprex.nl/project/openmuse/","publishdate":"2021-05-06T17:52:00Z","relpermalink":"/project/openmuse/","section":"project","summary":"OpenMusE brings together music industry stakeholders and researchers from 12 European countries. Our partners represent the diversity of the industry, as well as the shared need to find financially, socially, and environmentally sustainable policy and business models in multiple, sometimes-fragmented streams (e.g., live music, composers/publishers, and recordings with producers and performers).","tags":["Digital Music Observatory","Music Moves Europe","Horizon Europe"],"title":"OpenMusE Consortium","type":"project"},{"authors":["Daniel Antal"],"categories":null,"content":"Traitors in a war used to be executed by firing squad, and it was a psychologically burdensome task for soldiers to have to shoot former comrades. When a 10-marksman squad fired 8 blank and 2 live ammunition, the traitor would be 100% dead, and the soldiers firing would walk away with a semblance of consolation in the fact they had an 80% chance of not having been the one that killed a former comrade. This is a textbook example of assigning responsibility and blame in systems. AI-driven systems such as the YouTube or Spotify recommendation systems, the shelf organization of Amazon books, or the workings of a stock photo agency come together through complex processes, and when they produce undesirable results, or, on the contrary, they improve life, it is difficult to assign blame or credit.\nThis is the edited text of my presentation on Copyright Data Improvement in the EU – Towards Better Visibility of European Content and Broader Licensing Opportunities in the Light of New Technologies - download the entire webinar’s agenda.\nAssigning and avoding blame. If you do not see enough women on streaming charts, or if you think that the percentage of European films on your favorite streaming provider—or Slovak music on your music streaming service—is too low, you have to be able to distribute the blame in more precise terms than just saying “it’s the system” that is stacked up against women, small countries, or other groups. We need to be able to point the blame more precisely in order to effect change through economic incentives or legal constraints.\nThis is precisely the type of work we are doing with the continued support of the Slovak national rightsholder organizations, as well as in our research in the United Kingdom. We try to understand why classical musicians are paid less, or why 15% of Slovak, Estonian, Dutch, and Hungarian artists never appear on anybody’s personalized recommendations. We need to understand how various AI-driven systems operate, and one approach would at the very least model and assign blame for undesirable outcomes in probabilistic terms. The problem is usually not that an algorithm is nasty and malicious; Algorithms are often trained through “machine learning” techniques, and often, machines “learn” from biased, faulty, or low-quality information.\nOutcomes: What Can Go Wrong With a Recommendation System? In complex systems there are hardly ever singular causes that explain undesired outcomes; in the case of algorithmic bias in music streaming, there is no single bullet that eliminates women from charts or makes Slovak or Estonian language content less valuable than that in English. Some apparent causes may in fact be “blank cartridges,” and the real fire might come from unexpected directions. Systematic, robust approaches are needed in order to understand what it is that may be working against female or non-cisgender artists, long-tail works, or small-country repertoires.\nSome examples of “undesirable outcomes” in recommendation engines might include:\nRecommending too small a proportion of female or small country artists; or recommending artists that promote hate and violence. Placing Slovak books on lower shelves. Making the works of major labels easier to find than those of independent labels. Placing a lower number of European works on your favorite video or music streaming platform’s start window than local television or radio regulations would require. Filling up your social media newsfeed with fake news about covid-19 spread by some malevolent agents. These undesirable outcomes are sometimes illegal as they may go against non-discrimination or competition law. (See our ideas on what can go wrong – Music Streaming: Is It a Level Playing Field?) They may undermine national or EU-level cultural policy goals, media regulation, child protection rules, and fundamental rights protection against discrimination without basis. They may make Slovak artists earn significantly less than American artists.\nMetadata problems: no single bullet theory In our work in Slovakia, we reverse engineered some of these undesirable outcomes. Popular video and music streaming recommendation systems have at least three major components based on machine learning:\nThe users’ history – Is it that users’ history is sexist, or perhaps the training metadata database is skewed against women?\nThe works’ characteristics – are Dvorak’s works as well documented for the algorithm as Taylor Swift’s or Drake’s?\nIndependent information from the internet – Does the internet write less about women artists?\nIn the making of a recommendation or an autonomous playlist, these sources of information can be seen as “metadata” concerning a copyright-protected work (as well as its right-protected recorded fixation.) More often than not, we are not facing a malicious algorithm when we see undesirable system outcomes. The usual problem is that the algorithm is learning from data that is historically biased against women or biased …","date":1620285000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621149000,"objectID":"76c746e2453286b153759760e1b7866a","permalink":"https://reprex.nl/post/2021-05-16-recommendation-outcomes/","publishdate":"2021-05-06T07:10:00Z","relpermalink":"/post/2021-05-16-recommendation-outcomes/","section":"post","summary":"In complex systems there are hardly ever singular causes that explain undesired outcomes; in the case of algorithmic bias in music streaming, there is no single bullet that eliminates women from charts or makes Slovak or Estonian language content less valuable than that in English.","tags":["Algorithms","Slovakia","Trustworthy AI","recommendations"],"title":"Recommendation Systems: What can Go Wrong with the Algorithm?","type":"post"},{"authors":["Daniel Antal"],"categories":null,"content":"How to help promote local music? The new study opens the question of the local music promotion within the digital environment. The Slovak Performing and Mechanical Rights Society (SOZA), the State51 music group in the United Kingdom, and the Slovak Arts Council commissioned Reprex to created a feasibility study which provides recommendations for better use of quotas for Slovak radio stations and which also maps the share and promotion of Slovak music within large streaming and media platforms such as Spotify.\nWhat should a good local content policy (radio quota, recommendation system, streaming quota) achieve? The study proposes best practices for the introduction of mandatory quotas for Slovak radio stations and points out how current recommendation systems used by large platforms such as Spotify, YouTube, or Apple hardly consider local music from smaller countries. Local music stands against competition consisting of million songs from the whole world, and for ordinary Slovak musicians, whose music doesn’t belong to the global hits playlists, it is almost impossible to get recommended by the recommendation systems of large platforms.\nListen Local App for discovering new music We aimed to create a demo version of a utility-based, transparent, accountable recommendation system. The solution to this problem could be the Listen Local App, built on a comprehensive reference database of local music, which we created as a demo version within the study. The app aims to help listeners discover more local music; the app also presents new and alternative ways for large digital platforms to recommend local artists. Through Listen Local, listeners search for artists and bands based on their taste and the city they are situated in. In this way, listeners can easily search for music by artists from particular cities or from the town they are about to visit. We are releasing today the feasibility study in English and Slovak. We call for an open consultation to evaluate the results of this work and continue developing the Slovak Music Database, the Listen Local recommendation, and the AI validation system.\nCheck out the Demo Listen Local App. We explain here why.\nScreenshot of the first verison of the demo app. Database The Slovak Music Database is connected to Reprex’s flagship project, the Demo Music Observatory, an open collaboration-based demo version of the planned European Music Observatory, currently being further developed in the JUMP Music Market Accelerator Programme supported by Music Moves Europe.\nThe project website contains the demo version of the Slovak Music Database.\nDownload the Study You can download the study herein Slovak or in English.\nNext steps In the next phase of the work, we add further data to our Slovak Demo Music Database and carry out more and more experiments and educational activities to understand how Slovak music can become more visible and targeted. We are also bringing this project into an international collaboration for better utilization of R\u0026amp;D efforts and experiences throughout Europe. This agile project method originated in reproducible scientific practice and open-source software development and allows participation in large projects on any scale: from individual musicians and educators to large research universities and music distributors. Anyone can join in on the effort.\nReprex is looking for further international partners; Reprex is currently part of the Dutch AI Coalition and the European AI Alliance project. SOZA and Reprex are committed to opening this project for international collaboration while ensuring that a significant part of the R\u0026amp;D activities remains in the Slovak Republic.\nWe are preparing informal, online information sessions for artists, promoters, researchers, and developers to join our project.\nContributors The Reprex team who contributed to the English version:\nBudai, Sándor, programming and deployment Dr. Emily H. Clarke, musicologist Stef Koenis, musicologist, musician Dr. Andrés Garcia Molina, data scientist, musicologist, editor Kátya Nagy, music journalist, research assistant; and the Slovak version:\nDáša Bulíková, musician, translator Dominika Semaňáková, musicologist, editor, layout. Special thanks to Tammy Nižňanska \u0026amp; the Youniverse for the case study.\n","date":1616670000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616670000,"objectID":"b0cd1770b22d6ac819c4b5547bc949f2","permalink":"https://reprex.nl/post/2021-03-26-listen-local-feasibility/","publishdate":"2021-03-25T11:00:00Z","relpermalink":"/post/2021-03-26-listen-local-feasibility/","section":"post","summary":"Our new study opens the question of the local music promotion within the digital environment. The Slovak Performing and Mechanical Rights Society (SOZA), the State51 music group in the United Kingdom, and the Slovak Arts Council commissioned Reprex to created a feasibility study which provides recommendations for better use of quotas for Slovak radio stations and which also maps the share and promotion of Slovak music within large streaming and media platforms such as Spotify.","tags":["Slovakia","trustworthy-AI","recommendations","music-distribution","local-content-regulation"],"title":"Feasibility Study On Promoting Slovak Music In Slovakia \u0026 Abroad","type":"post"},{"authors":[],"categories":null,"content":"Open Data Day is an annual celebration of open data all over the world. It is an opportunity to show the benefits of open data and encourage the adoption of open data policies in government, business, and civil society. Reprex is a start-up that utilizes open data with open-source reproducible research: please challenge us with your data requests and participate in our web events.\nThe Reprex Open Data Day 2021 will be two informal conversations based on a series of run up introductory blogposts centered around two themes. Because important guests became ill in the last days, we are going to consolidate the two talks into one with less structure. We want to create an informal, inclusive, collaborative online event on International Open Data Day 2021. Please, grab a tea, coffee, or even a beer, and join us for an informal conversation. We hope that we will finish the afternoon with ideas on new, open-data driven collaborations.\n9.30 EST / 15.30 CET: Open collaboration in business, policy and science. Creating evidence-based policy, business strategy or scientific research with small contributions with independent components with incentives. Short introduction with examples: joining environmental sensory data and public opinion data on maps; creating harmonized datasets across the Arab world. Survey harmonization, mapping, data products. Scaling up open collaboration: making small organizations competitive with big tech in the big data era. Data sharing, data pooling, data altruism and observatories. The new European trustworthy AI and data governance agenda.\nYou can click through a short presentation to familiarize yourself with our topics.\nSee you here.\nCase studies:\nWe are connecting raw survey data about Climate Awareness in Eurobarometer surveys. Here is the reproduction code (intermediate to advanced R needed.) You should use the development version of our retroharmonize package at github.com/antaldaniel/retroharmonize\nWe are tracking changes in the boundaries of provinces, states, counties, parishes with our regions open source software – reproduction code here. You will need our regions package which is available on CRAN or in the rOpenGov GitHub repo.\nWe will talk about how to join this with air pollution data and put it on the map with Milos Popovic, who prepared this nice choropleth animation.\nWe will discuss data observatories (permanent data collection programs), open collaboration (open-source inspired way of cooperation among small and large independent actors) and data altruism. Any questions: send Daniel a message on Keybase, Whatsapp or email.\nHello on International #OpenDataDay2021 from🌷 the Hague!\n- We have brought some new data to the light about 🌡climate change awareness - We created some tutorials how to harmonize survey and geographical data\n- Join us at 9.30 EST/15.30 CET 👇https://t.co/7J7pvi3sPC #ODD2021 pic.twitter.com/DwkGQaDhW1\n— dataandlyrics (@dataandlyrics) March 6, 2021 ","date":1615037400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615037400,"objectID":"ecc73affcfc1427fc7b6300d0b5e126b","permalink":"https://reprex.nl/talk/reprex-open-data-day-2021/","publishdate":"2021-02-03T10:10:00Z","relpermalink":"/talk/reprex-open-data-day-2021/","section":"event","summary":"Open Data Day 2021 focusing on environmental, sustainability and public spending data mapping.","tags":["open-data"],"title":"Reprex Open Data Day 2021","type":"event"},{"authors":["Daniel Antal"],"categories":["R-bloggers"],"content":"library(regions) library(lubridate) library(dplyr) if ( dir.exists(\u0026#39;data-raw\u0026#39;) ) { data_raw_dir \u0026lt;- \u0026#34;data-raw\u0026#34; } else { data_raw_dir \u0026lt;- file.path(\u0026#34;..\u0026#34;, \u0026#34;..\u0026#34;, \u0026#34;data-raw\u0026#34;) } The first results of our longitudinal table were difficult to map, because the surveys used an obsolete regional coding. We will adjust the wrong coding, when possible, and join the data with the European Environment Agency’s (EEA) Air Quality e-Reporting (AQ e-Reporting) data on environmental pollution. We recoded the annual level for every available reporting stations [not shown here] and all values are in μg/m3. The period under observation is 2014-2016. Data file: https://www.eea.europa.eu/data-and-maps/data/aqereporting-8 (European Environment Agency 2021).\nRecoding the Regions Recoding means that the boundaries are unchanged, but the country changed the names and codes of regions because there were other boundary changes which did not affect our observation unit. We explain the problem and the solution in greater detail in our tutorial that aggregates the data on regional levels.\npanel \u0026lt;- readRDS((file.path(data_raw_dir, \u0026#34;climate-panel.rds\u0026#34;))) climate_data_geocode \u0026lt;- panel %\u0026gt;% mutate ( year: lubridate::year(date_of_interview)) %\u0026gt;% recode_nuts() Let’s join the air pollution data and join it by corrected geocodes:\nload(file.path(\u0026#34;data\u0026#34;, \u0026#34;air_pollutants.rda\u0026#34;)) ## good practice to use system-independent file.path climate_awareness_air \u0026lt;- climate_data_geocode %\u0026gt;% rename ( region_nuts_codes : .data$code_2016) %\u0026gt;% left_join ( air_pollutants, by: \u0026#34;region_nuts_codes\u0026#34; ) %\u0026gt;% select ( -all_of(c(\u0026#34;w1\u0026#34;, \u0026#34;wex\u0026#34;, \u0026#34;date_of_interview\u0026#34;, \u0026#34;typology\u0026#34;, \u0026#34;typology_change\u0026#34;, \u0026#34;geo\u0026#34;, \u0026#34;region\u0026#34;))) %\u0026gt;% mutate ( # remove special labels and create NA_numeric_ age_education: retroharmonize::as_numeric(age_education)) %\u0026gt;% mutate_if ( is.character, as.factor) %\u0026gt;% mutate ( # we only have responses from 4 years, and this should be treated as a categorical variable year: as.factor(year) ) %\u0026gt;% filter ( complete.cases(.) ) The climate_awareness_air data frame contains the answers of 75086 individual respondents. 17.07% thought that climate change was the most serious world problem and 33.6% mentioned climate change as one of the three most important global problems.\nsummary ( climate_awareness_air ) ## rowid serious_world_problems_first ## ZA5877_v2-0-0_1 : 1 Min. :0.0000 ## ZA5877_v2-0-0_10 : 1 1st Qu.:0.0000 ## ZA5877_v2-0-0_100 : 1 Median :0.0000 ## ZA5877_v2-0-0_1000 : 1 Mean :0.1707 ## ZA5877_v2-0-0_10000: 1 3rd Qu.:0.0000 ## ZA5877_v2-0-0_10001: 1 Max. :1.0000 ## (Other) :75080 ## serious_world_problems_climate_change isocntry ## Min. :0.000 BE : 3028 ## 1st Qu.:0.000 CZ : 3023 ## Median :0.000 NL : 3019 ## Mean :0.336 SK : 3000 ## 3rd Qu.:1.000 SE : 2980 ## Max. :1.000 DE-W : 2978 ## (Other):57058 ## marital_status age_education ## (Re-)Married: without children :13242 18 :15485 ## (Re-)Married: children this marriage :12696 19 : 7728 ## Single: without children : 7650 16 : 5840 ## (Re-)Married: w children of this marriage: 6520 still studying: 5098 ## (Re-)Married: living without children : 6225 17 : 5092 ## Single: living without children : 4102 15 : 4528 ## (Other) :24651 (Other) :31315 ## age_exact occupation_of_respondent ## Min. :15.0 Retired, unable to work :22911 ## 1st Qu.:36.0 Skilled manual worker : 6774 ## Median :51.0 Employed position, at desk : 6716 ## Mean :50.1 Employed position, service job: 5624 ## 3rd Qu.:65.0 Middle management, etc. : 5252 ## Max. :99.0 Student : 5098 ## (Other) :22711 ## occupation_of_respondent_recoded ## Employed (10-18 in d15a) :32763 ## Not working (1-4 in d15a) :37125 ## Self-employed (5-9 in d15a): 5198 ## ## ## ## ## respondent_occupation_scale_c_14 ## Retired (4 in d15a) :22911 ## Manual workers (15 to 18 in d15a) :15269 ## Other white collars (13 or 14 in d15a): 9203 ## Managers (10 to 12 in d15a) : 8291 ## Self-employed (5 to 9 in d15a) : 5198 ## Students (2 in d15a) : 5098 ## (Other) : 9116 ## type_of_community is_student no_education ## DK : 34 Min. :0.0000 Min. :0.000000 ## Large town :20939 1st Qu.:0.0000 1st Qu.:0.000000 ## Rural area or village :24686 Median :0.0000 Median :0.000000 ## Small or middle sized town: 9850 Mean :0.0679 Mean :0.008151 ## Small/middle town :19577 3rd Qu.:0.0000 3rd Qu.:0.000000 ## Max. :1.0000 Max. :1.000000 ## ## education year region_nuts_codes country_code ## Min. :14.00 2013:25103 LU : 1432 DE : 4531 ## 1st Qu.:17.00 2015: 0 MT : 1398 GB : 3538 ## Median :18.00 2017:25053 CY : 1192 BE : 3028 ## Mean :19.61 2019:24930 SK02 : 1053 CZ : 3023 ## 3rd Qu.:22.00 EL30 : 974 NL : 3019 ## Max. :30.00 EE : 973 SK : 3000 ## (Other):68064 (Other):54947 ## pm2_5 pm10 o3 BaP ## Min. : 2.109 Min. : 5.883 Min. : 66.37 Min. :0.0102 ## 1st Qu.: 9.374 1st Qu.: 28.326 1st Qu.: 90.89 1st Qu.:0.1779 ## Median :11.866 Median : 33.673 Median :102.81 Median :0.4105 ## Mean :12.954 Mean : 38.637 Mean :101.49 Mean :0.8759 ## 3rd Qu.:15.890 3rd Qu.: 49.488 3rd Qu.:110.73 3rd Qu.:1.0692 ## Max. :41.293 Max. …","date":1614988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614988800,"objectID":"a62b7e3d7582ea5a29027c11a0b18178","permalink":"https://reprex.nl/post/2021-03-06-individual-join/","publishdate":"2021-03-06T00:00:00Z","relpermalink":"/post/2021-03-06-individual-join/","section":"post","summary":"We created a longitudinal dataset that contains data on the attitudes European people in various countries, provinces and regions thought climate change was a serious world problem back in 2013, 2015, 2017 and 2019. We join the data with air pollution data so that we can see how serious is the environmental degradation in the smaller area of each (anonymous) respondent.","tags":["retrospective-harmonization","surveys","climate-change","climate-awareness"],"title":"Where Are People More Likely To Treat Climate Change as the Most Serious Global Problem?","type":"post"},{"authors":["Daniel Antal"],"categories":null,"content":" According to the announcement of JUMP, the European Music Market Accelerator, after a careful screening of all applications received, the selection committee composed of all JUMP board members has selected the most promising ideas and projects to be developed together with renowned tutors for this 2021 fellowship.\nFor nine months, the 20 fellows living in many European countries will develop their innovative projects, while receiving a comprehensive 360° training. In addition to specialised workshops by highly qualified experts, each fellow will receive one-on-one tutoring sessions from the most renowned music professionals coming from all over Europe.\nThe 20 selected projects cover a great variety of urgent needs faced within the music sector. They will:\nhelp fostering social change with projects focusing on diversity in the industry, more fairness and transparency as well as raising awareness on timely issues.\nenhance technological development with projects using blockchain, immersive sound and VR and AR.\nbuild bridges between different key actors of the ecosystem.\nDownload the entire JUMP press release.\nReprex’s project, the automated Demo Music Observatory will be represented by Daniel Antal, co-founder of Reprex among other building bridges projects. This project offers a different approach to the planned European Music Observatory based on the principles of open collaboration, which allows contributions from small organizations and even individuals, and which provides higher levels of quality in terms of auditability, timeliness, transparency and general ease of use. Our open collaboration approach allows to power trustworthy, ethical AI systems like our Listen Local that we started out from Slovakia with the support of the Slovak Arts Council.\nJUMP fellows building bridges between different key actors of the ecosystem. Apart from our Demo Music Observatory the build bridges section Groovly with Martin Zenzerovich, From Play To Rec by Jeremy Dunne, Hajde Radio by Thibaut Boudaud, LowDee by Alex Davidson and ONO-HU! by Gina Akers.\nMeet all the JUMP 2021 Fellows, including the technology and social change professionals!\nReprex is a start-up company based in the Netherlands and the United States that validated its early products in the Yes!Delft AI+Blockchain Lab in the Hague. In 2021 we joined the Dutch AI Coalition – NL AIC and requested membership in the European AI Alliance. Reprex is committed to applying reproducible in an open collaboration with our business, scientific, policy and civil society partners, and facilitate the use of open data and open-source software. Many fellows in the program are connected to other regions, like North America and Australia – because music is one of the most globalized industries and forms of art in the world! Reprex is a startup based in the Netherlands and the United States, and we are very excited to collaborate with our peers in new European territories, and in Canada and Australia.\nHope to meet you in these great events - maybe not only online! Further links:\nFrom Play to Rec on Facebook HAJDE FR/EN ","date":1614862800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614862800,"objectID":"e4aa666776c92ad88310df3ed54e0267","permalink":"https://reprex.nl/post/2021-03-04-jump-2021/","publishdate":"2021-03-04T15:00:00+02:00","relpermalink":"/post/2021-03-04-jump-2021/","section":"post","summary":"Reprex's project, the automated Demo Music Observatory will be represented by Daniel Antal, co-founder of Reprex among other building bridges projects. This project offers a different approach to the planned European Music Observatory based on the principles of open collaboration, which allows contributions from small organizations and even individuals, and which provides higher levels of quality in terms of auditability, timeliness, transparency and general ease of use.","tags":["listen-local","music-observatory","JUMP","EU","Music Moves Europe"],"title":"Our Music Observatory in the Jump European Music Market Accelerator: Meet the 2021 Fellows and their Tutors","type":"post"},{"authors":["Daniel Antal"],"categories":["R-bloggers"],"content":"Reproducible ex post harmonization of survey microdata Retrospective survey harmonization allows the comparison of opinion poll data conducted in different countries or time. In this example we are working with data from surveys that were ex ante harmonized to a certain degree – in our tutorials we are choosing questions that were asked in the same way in many natural languages. For example, you can compare what percentage of the European people in various countries, provinces and regions thought climate change was a serious world problem back in 2013, 2015, 2017 and 2019.\nWe developed the retroharmonize R package to help this process. We have tested the package with about 80 Eurobarometer, 5 Afrobarometer survey files extensively, and a bit with Arabbarometer files. This allows the comparison of various survey answers in about 70 countries. This policy-oriented survey programs were designed to be harmonized to a certain degree, but their ex post harmonization is still necessary, challenging and errorprone. Retrospective harmonization includes harmonization of the different coding used for questions and answer options, post-stratification weights, and using different file formats.\nEurobarometer, Afrobaromer, Arab Barometer and Latinobarómetro make survey files that are harmonized across countries available for research with various terms. Our retroharmonize is not affiliated with them, and to run our examples, you must visit their websites, carefully read their terms, agree to them, and download their data yourself. What we add as a value is that we help to connect their files across time (from different years) or across these programs.\nThe survey programs mentioned above publish their data in the proprietary SPSS format. This file format can be imported and translated to R objects with the haven package; however, we needed to re-design haven’s labelled_spss class to maintain far more metadata, which, in turn, a modification of the labelled class. The haven package was designed and tested with data stored in individual SPSS files.\nThe author of labelled, Joseph Larmarange describes two main approaches to work with labelled data, such as SPSS’s method to store categorical data in the Introduction to labelled.\nTwo main approaches of labelled data conversion. Our approach is a further extension of Approach B. Survey harmonization in our case always means the joining data from several SPSS files, which requires a consistent coding among several data sources. This means that data cleaning and recoding must take place before conversion to factors, character or numeric vectors. This is particularly important with factor data (and their simple character conversions) and numeric data that occasionally contains labels, for example, to describe the reason why certain data is missing. Our tutorial vignette labelled_spss_survey gives you more information about this.\nIn the next series of tutorials, we will deal with an array of problems. These are not for the faint heart – you need to have a solid intermediate level of R to follow.\nTidy, joined survey data The original files identifiers may not be unique, we have to create new, truly unique identifiers. Weighting may not be straightforward. Neither the number of observations or the number of variables (which represents the survey questions and their translation to coded data) is the same. Certain data may be only present in one survey and not the other. This means that you will likely to run loops on lists and not data.frames, but eventually you must carefully join them. Class conversion Similar questions may be imported from a non-native R format, in our case, from an SPSS files, in an inconsistent manner. SPSS’s variable formats cannot be translated unambiguously to R classes. retroharmonize introduced a new S3 class system that handles this problem, but eventually you will have to choose if you want to see a numeric or character coding of each categorical variable. The harmonized surveys, with harmonized variable names and harmonized value labels, must be brought to consistent R representations (most statistical functions will only work on numeric, factor or character data) and carefully joined into a single data table for analysis. Harmonization of variables and variable labels Same variables may come with dissimilar variable names and variable labels. It may be a challenge to match age with age. We need to harmonize the names of variables. The harmonized variables may have different labeling. One may call refused answers as declined and the other refusal. On a simple choice, climate change may be ‘Climate change’ or Problem: Climate change. Binary choices may have survey-specific coding conventions. Value labels must be harmonized. There are good tools to do this in a single file - but we have to work with several of them. Missing value harmonization There are likely to be various types of missing values. Working with missing values is probably where most human …","date":1614816000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614816000,"objectID":"1cacf8f9f78c3f525ce934648cb8eca4","permalink":"https://reprex.nl/post/2021-03-04_retroharmonize_intro/","publishdate":"2021-03-04T00:00:00Z","relpermalink":"/post/2021-03-04_retroharmonize_intro/","section":"post","summary":"Retrospective survey harmonization allows the comparison of opinion poll data conducted in different countries or time.  In this example we are working with data from surveys that were ex ante harmonized to a certain degree – in our tutorials we are choosing questions that were asked in the same way in many natural languages.  For example, you can compare what percentage of the European people in various countries, provinces and regions thought climate change was a serious world problem back in 2013, 2015, 2017 and 2019.","tags":["retrospective-harmonization","surveys"],"title":"What is Retrospective Survey Harmonization?","type":"post"},{"authors":["Daniel Antal"],"categories":null,"content":"Milos Popovic is a researcher, a data scientist, Marie Curie postdoc \u0026amp; Top 10 dataviz \u0026amp; R contributor on Twitter according to NodeXL. He took part in policy debates about terrorism and military intervention and appeared on a number of TV channels including N1 (the CNN affiliate in the Western Balkans), Serbian National Television and Al-Jazeera Balkans. My research interests are at the intersection of civil war dynamics and postwar politics in the Balkans. He is going to join the Data \u0026amp; Lyrics team on International Open Data Day to help us put harmonized environmental degradation perception and environmental sensory data on maps. We asked him four questions about his passion, mapping data. Please join us 6 March 2021 9.30 EST / 15.30 CET for an informal digital coffee.\nAs a researcher, why are you so much drawn into maps? Is this connected to your interest in territorial conflicts, or you have some other inspiration?\nThat’s a great question that really makes me pause and look back at the past 5 years. My mapping story started out of curiosity: I found interesting data on the post-WWII violence in Serbia and thought how cool it would be to make a map in R. I quickly made an unimpressive choropleth map and noticed some unexpected patterns. Then I realized just how much unused violence and census data sits out there while we have no clue about geographic patterns. So, it began. I started off with map-making but my curiosity took me to the world of georeferencing and geospatial analysis. In the process, I created over 300 maps hosted on my website as well as dozens of shapefiles from the scratch.\nI used to think that my interest is linked to growing up in a war-torn country. But, as my map-making evolved, I discovered that my passion is to use maps as a way to democratize the data: to take the scores of unused, and often buried datasets, place them on the map and share the dataviz with people.\nCan you show us an example of the best use of mapped data, and the best map that you have personally created? What is their distinctive value?\nI’m immensely proud of my work that required making the shapefiles from the scratch. For instance, my shapefile of over 1500 Kosovo cadastral settlements came into being after I turned dozens of high-resolution raster files into a shapefile fully compatible with Open Street Maps. After months of hard work, I managed to merge the shapefile with the 2011 Kosovo census and present several laser-focused demographic maps to my audience. Same goes for the settlement shapefile of Republika Srpska [the Serb-speaking entity of Bosnia-Herzegovina — the editor], which I made out of a pdf file and merged with the 2013 census data. Whereas most existing maps take a bird’s eye view, my work offers a more fine-grained view of the local dynamics to stakeholders.\nAnother similar undertaking was my transformation of the pre-WWII German military map of Yugoslavia into a unique shapefile of a few hundred Yugoslav municipalities. I combined this shapefile with the 1931 census data, 80 years after it was first published (better late than never!). It took me almost a year to complete this tremendous project but I enjoyed every bit of it. I have teamed up with my brother who is a web developer and we even made an interactive map of Yugoslavia based on the 1931 census.[The screenshot of this interactive map is the top image in the post – the editor] We hope this project would serve not only scholars but also history enthusiasts to better understand a history of the country that is no more.\nCheck out Milos’s beautiful static and interactive maps on https://milosp.info/ What do you think about collaboration based on open data and open-source software that processes such data?\nIt’s a fantastic opportunity for small teams to bypass traditional gatekeepers such as state institutions or big companies and use open source apps for the benefit of their local communities. For example, the access to Open Street Map allows small teams to map pressing communal issues as crime, deceases, or environmental degradation and come up with innovative solutions. In my work, too, I used OSM has helped me create several fine-grained maps that shed more light on local problems in Serbia such as pollution, car accidents or violence.\nWe are hoping to bring together environmental, sensory data and public attitude data on environmental issues? How can mapping help? What do you expect from this project?\nMore than ever, we are compelled to figure out how maladies spreads locally. Without mapping the hotspots, our understanding of the consequences of, for example, viral transmission or pollution is shrouded with a lot of uncertainty. We might have no clue how environmental issues shape public attitudes in localities until we use the mapping to turn on the light. Mapping would help this project pin down geographic clusters that require immediate attention from the private and public stakeholders.\nPlease join us for a digital coffee, tea …","date":1614802980,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614802980,"objectID":"c54d327e4abb3f2b980e418fceacd701","permalink":"https://reprex.nl/post/2021-03-03-ood_interview_maps/","publishdate":"2021-03-03T22:23:00+02:00","relpermalink":"/post/2021-03-03-ood_interview_maps/","section":"post","summary":"Milos Popovic is a researcher, a data scientist, Marie Curie postdoc \u0026 Top 10 dataviz \u0026 R contributor on Twitter according to NodeXL. He is going to join the Data \u0026 Lyrics team on International Open Data Day to help us put harmonized environmental degradation perception and environmental sensory data on maps. We asked him four questions about his passion, mapping data. Please join us 6 March 2021 9.30 EST / 15.30 CET for an informal digital coffee.","tags":["open data","music-observatory","open data day","maps"],"title":"Open Data Day Interview: Mapping Data with Milos Popovic","type":"post"},{"authors":["Daniel Antal"],"categories":["R-bloggers"],"content":"In our tutorial series, we are going to harmonize the following questionnaire items from five Eurobarometer harmonized survey files. The Eurobarometer survey files are harmonized across countries, but they are only partially harmonized in time.\nAll data must be downloaded from the GESIS Data Archive in Cologne. We are not affiliated with GESIS and you must read and accept their terms to use the data.\nEurobarometer 80.2 (2013) GESIS Data Archive, Cologne. ZA5877 Data file Version 2.0.0, https://doi.org/10.4232/1.12792\nData file: ZA6595 data file (European Commission 2017). Questionnaire: Eurobarometer 83.4 Basic Bilingual Questionnaire Citation: ZA6595 Bibtex QA1a Which of the following do you consider to be the single most serious problem facing the world as a whole? (single choice)\nQA1b Which others do you consider to be serious problems? (multiple choice)\nQA2 And how serious a problem do you think climate change is at this moment? Please use a scale from 1 to 10, with \u0026#39;1\u0026#39; meaning it is \u0026#34;not at all a serious problem (scale 1-10)\nQA4 To what extent do you agree or disagree with each of the following statements? - Fighting climate change and using energy more efficiently can boost the economy and jobs in the EU (agreement-disagreement 4-scale)\nQA4 To what extent do you agree or disagree with each of the following statements? - Reducing fossil fuel imports from outside the EU could benefit the EU economically (agreement-disagreement 4-scale)\nQA5 Have you personally taken any action to fight climate change over the past six months? (binary)\nEurobarometer 83.4 (2015) European Commission, Brussels; Directorate General Communication COMM.A.1 ´Strategy, Corporate Communication Actions and Eurobarometer´GESIS Data Archive, Cologne. ZA6595 Data file Version 3.0.0, https://doi.org/10.4232/1.13146\nData file: ZA6595 data file (European Commission 2018). Questionnaire: Eurobarometer 83.4 Basic Bilingual Questionnaire Citation: ZA6595 Bibtex Eurobarometer 87.1 (2017) European Commission, Brussels; Directorate General Communication, COMM.A.1 ‘Strategic Communication’; European Parliament, Directorate-General for Communication, Public Opinion Monitoring Unit GESIS Data Archive, Cologne. ZA6861 Data file Version 1.2.0, https://doi.org/10.4232/1.12922\nData file: ZA6861 data file. Questionnaire: Eurobarometer 90.2 Basic Bilingual Questionnaire Citation: ZA6861 Bibtex QC1a Which of the following do you consider to be the single most serious problem facing the world as a whole? (single choice)\nQC1b Which others do you consider to be serious problems? (multiple choice)\nQC2 And how serious a problem do you think climate change is at this moment? Please use a scale from 1 to 10, with \u0026#39;1\u0026#39; meaning it is \u0026#34;not at all a serious problem (scale 1-10)\nQc4 To what extent do you agree or disagree with each of the following statements? - Fighting climate change and using energy more efficiently can boost the economy and jobs in the EU (agreement-disagreement 4-scale)\nQc4 To what extent do you agree or disagree with each of the following statements? - Promoting EU expertise in new clean technologies to countries outside the EU can benefit the EU economically (agreement-disagreement 4-scale)\nQc4 To what extent do you agree or disagree with each of the following statements? - Reducing fossil fuel imports from outside the EU can benefit the EU economically (agreement-disagreement 4-scale)\nQc4 To what extent do you agree or disagree with each of the following statements? - Reducing fossil fuel imports from outside the EU can increase the security of EU energy supplies (agreement-disagreement 4-scale)\nQc4 To what extent do you agree or disagree with each of the following statements? - More public financial support should be given to the transition to clean energies even if it means subsidies to fossil fuels should be reduced. (agreement-disagreement 4-scale)\nQc5 Have you personally taken any action to fight climate change over the past six months? (binary)\nEurobarometer 90.2 (2018) European Commission, Brussels; Directorate General Communication, COMM.A.3 ‘Media Monitoring and Eurobarometer’ GESIS Data Archive, Cologne. ZA7488 Data file Version 1.0.0, https://doi.org/10.4232/1.13289\nData file: ZA7488 data file (European Commission 2019a) Questionnaire: Eurobarometer 90.2 Basic Bilingual Questionnaire Citation: ZA7488 Bibtex QB5 To what extent do you agree or disagree with each of the following statements? - Fighting climate change and using energy more efficiently can boost the economy and jobs in the EU (agreement-disagreement 4-scale)\nQB5 To what extent do you agree or disagree with each of the following statements? - Promoting EU expertise in new clean technologies to countries outside the EU can benefit the EU economically (agreement-disagreement 4-scale)\nQB5 To what extent do you agree or disagree with each of the following statements? - Reducing fossil fuel imports from outside the EU can benefit the EU economically (agreement-disagreement …","date":1614729600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614729600,"objectID":"458c154b8079191eb3ad0e229857dd05","permalink":"https://reprex.nl/post/2021-03-04-eurobarometer_data/","publishdate":"2021-03-03T00:00:00Z","relpermalink":"/post/2021-03-04-eurobarometer_data/","section":"post","summary":"In our [tutorial series](http://netzero.dataobservatory.eu/post/2021-03-04_retroharmonize_intro/), we are going to harmonize the following questionnaire items from five Eurobarometer harmonized survey files. The Eurobarometer survey files are harmonized across countries, but they are only partially harmonized in time.","tags":["surveys","eurobarometer"],"title":"Eurobarometer Surveys Used In Our Project","type":"post"},{"authors":["Daniel Antal","Amelia Fletcher","Peter Ormosi"],"categories":null,"content":"Our article, Music Streaming: Is It a Level Playing Field? is published in the February 2021 issue of CPI Antitrust Chronicle, which is fully devoted to competition policy issues in the music industry.\nThe dramatic growth of music streaming over recent years is potentially very positive. Streaming provides consumers with low cost, easy access to a wide range of music, while it provides music creators with low cost, easy access to a potentially wide audience. But many creators are unhappy about the major streaming platforms. They consider that they act in an unfair way, create an unlevel playing field and threaten long-term creativity in the music industry.\nOur paper describes and assesses the basis for one element of these concerns, competition between recordings on streaming platforms. We argue that fair competition is restricted by the nature of the remuneration arrangements between creators and the streaming platforms, the role of playlists, and the strong negotiating power of the major labels. It concludes that urgent consideration should be given to a user-centric payment system, as well as greater transparency of the factors underpinning playlist creation and of negotiated agreements.\nYou can read the entire issue and the full text of our article on Competition Policy International in pdf.\n","date":1614108180,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614194580,"objectID":"4c51178c81835af9e29c60bf9a8a4ce4","permalink":"https://reprex.nl/post/2021-02-24-music-level-playing-field/","publishdate":"2021-02-23T21:23:00+02:00","relpermalink":"/post/2021-02-24-music-level-playing-field/","section":"post","summary":"Our paper argues that fair competition in music streaming is restricted by the nature of the remuneration arrangements between creators and the streaming platforms, the role of playlists, and the strong negotiating power of the major labels. It concludes that urgent consideration should be given to a user-centric payment system, as well as greater transparency of the factors underpinning playlist creation and of negotiated agreements.","tags":["listen-local","music-observatory","competition","music-streaming","UCPS"],"title":"Music Streaming: Is It a Level Playing Field?","type":"post"},{"authors":["Daniel Antal","Amelia Fletcher","Peter Ormosi"],"categories":null,"content":"Our article, Music Streaming: Is It a Level Playing Field? is published in the February 2021 issue of CPI Antitrust Chronicle, which is fully devoted to competition policy issues in the music industry.\nThe dramatic growth of music streaming over recent years is potentially very positive. Streaming provides consumers with low cost, easy access to a wide range of music, while it provides music creators with low cost, easy access to a potentially wide audience. But many creators are unhappy about the major streaming platforms. They consider that they act in an unfair way, create an unlevel playing field and threaten long-term creativity in the music industry.\nOur paper describes and assesses the basis for one element of these concerns, competition between recordings on streaming platforms. We argue that fair competition is restricted by the nature of the remuneration arrangements between creators and the streaming platforms, the role of playlists, and the strong negotiating power of the major labels. It concludes that urgent consideration should be given to a user-centric payment system, as well as greater transparency of the factors underpinning playlist creation and of negotiated agreements.\nYou can read the entire issue and the full text of our article on Competition Policy International in pdf.\n","date":1614078000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614078000,"objectID":"ebd10a8cae343149004f3acb51abacd0","permalink":"https://reprex.nl/publication/music_level_playing_field_2021/","publishdate":"2021-02-23T11:00:00Z","relpermalink":"/publication/music_level_playing_field_2021/","section":"publication","summary":"Urgent consideration should be given to a user-centric payment system, as well as greater transparency of the factors underpinning playlist creation and of negotiated agreements","tags":["Market reports","Trustworthy AI","Computational Antitrust","Spotify","YouTube","Deezer"],"title":"Music Streaming: Is It a Level Playing Field?","type":"publication"},{"authors":["Daniel Antal"],"categories":null,"content":"Daniel Antal, co-founder of Reprex, was selected into 2021 Fellowship program of JUMP, the European Music Market Accelerator. Jump provides a framework for music professionals to develop innovative business models, encouraging the music sector to work on a transnational level. The European Music Market Accelerator composed of MaMA Festival and Convention, UnConvention, MIL, Athens Music Week, Nouvelle Prague and Linecheck support him in the development of our two, interrelated projects over the next nine months.\nOur Demo Music Observatory is a demo version of the European Music Observatory based on open data, open source, automated research in open collaboration with music stakeholders. We hope that we can further develop our business model and find new users, and help the recovery of the festival and live music segment.\nListen Local is our AI system that validated third party music AI, such as Spotify’s or YouTube’s recommendation systems, and provides trustworthy, accountable, transparent alternatives for the European music industry. We hope to expand our pilot project from Slovakia to several European countries in 2021.\nReprex is a start-up company based in the Netherlands and the United States that validated its early products in the Yes!Delft AI+Blockchain Lab in the Hague. In 2021 we joined the Dutch AI Coalition – NL AIC and requested membership in the European AI Alliance.\nReprex is committed to applying reproducible in an open collaboration with our business, scientific, policy and civil society partners, and facilitate the use of open data and open-source software.\n","date":1614021780,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614021780,"objectID":"e5902afbf69c3e26a77ffb2af3c57924","permalink":"https://reprex.nl/post/2021-02-22-jump/","publishdate":"2021-02-22T21:23:00+02:00","relpermalink":"/post/2021-02-22-jump/","section":"post","summary":"Daniel Antal, co-founder of Reprex, was selected into 2021 Fellowship program of JUMP, the European Music Market Accelerator. Jump provides a framework for music professionals to develop innovative business models, encouraging the music sector to work on a transnational level.  The European Music Market Accelerator composed of MaMA Festival and Convention, UnConvention, MIL, Athens Music Week, Nouvelle Prague and Linecheck support him in the development of our two, interrelated projects over the next nine months.","tags":["listen-local","music-observatory","JUMP","EU"],"title":"Daniel Antal, co-founder of Reprex Was Selected into the 2021 Fellowship Program of the European Music Market Accelerator","type":"post"},{"authors":["Daniel Antal"],"categories":null,"content":"Reprex, our start-up, is based in the Netherlands and the United States that validated its early products in the Yes!Delft AI+Blockchain Lab in the Hague. In 2021, we decided to join the Dutch AI Coalition – NL AIC.\nThe NL AIC is a public-private partnership in which the government, the business sector, educational and research institutions, as well as civil society organisations collaborate to accelerate and connect AI developments and initiatives. The ambition is to position the Netherlands at the forefront of knowledge and application of AI for prosperity and well-being. We are continually doing so with due observance of both the Dutch and European standards and values. The NL AIC functions as the catalyst for AI applications in our country.\nWe are particularly looking forward to participating in the Culture working group of NLAIC, but we will also take a look at the Security, Peace and Justice and the Energy and Sustainability working groups. Reprex is committed to use and further develop AI solutions that fulfil the requirements of trustworthy AI, a human-centric, ethical, and accountable use of artificial intelligence. We are committed to develop our data platforms, or automated data observatories, and our Listen Local system in this manner. Furthermore, we are involved in various scientific collaborations that are researching ideas on future regulation of copyright and fair competition with respect to AI algorithms.\nWe are committed to applying reproducible in an open collaboration with our business, scientific, policy and civil society partners, and facilitate the use of open data and open-source software.\n","date":1613488200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613488200,"objectID":"aa6a24ef31ed0c5b0bad3d7948f822d7","permalink":"https://reprex.nl/post/2021-02-16-nlaic/","publishdate":"2021-02-16T17:10:00+02:00","relpermalink":"/post/2021-02-16-nlaic/","section":"post","summary":"Reprex is committed to develop its data platforms, or automated data observatories, and its Listen Local system in a trustworthy manner. Our startup participates in various scientific collaborations that are researching ideas on future regulation of copyright and fair competition with respect to AI algorithms, and joined the Dutch AI Coalition to position the company and the Netherlands at the forefront of knowledge and application of AI for prosperity and well-being, respecting Dutch and European values.","tags":["listen-local","AI","Netherlands","algorithms","NLAIC"],"title":"Reprex Joins The Dutch AI Coalition","type":"post"},{"authors":["Daniel Antal"],"categories":null,"content":"The majority of music sales in the world is driven by AI-algorithm powered robots that create personalized playlists, recommendations and help programming radio music streams or festival lineups. It is critically important that an artist’s work is documented, described in a way that the algorithm can work with it.\nIn our research paper – soon to be published – made for the Listen Local Initiative we found that 15% of Dutch, Estonian, Hungarian, or Slovak artists had no chance to be recommended, and they usually end up on Forgetify, an app that lists never-played songs of Spotify. In another project with rights management organizations, we found that about half of the rightsholders are at risk of not getting all their royalties from the platforms because of poor documentation.\nBut how come that distributors give streaming platforms songs that are not properly documented? What sort of information is missing for the European repertoire’s visibility? Reprex is exploring this problem in a practical cooperation with SOZA, the Slovak Performing and Mechanical Rights Society, and in an academic cooperation that involves leading researchers in the field. A manuscript co-authored Martin Senftleben, director of the Institute for Information Law in Amsterdam, and eminent researchers in copyright law and music economics, Reprex’s co-founder makes the case that Europe must invest public money to resolve this problem, because in the current scenario, the documentation costs of a song exceed the expected income from streaming platforms.\nIn the European Strategy for Data, the European Commission highlighted the EU’s ambition to acquire a leading role in the data economy. At the same time, the Commission conceded that the EU would have to increase its pools of quality data available for use and re-use. In the creative industries, this need for enhanced data quality and interoperability is particularly strong. Without data improvement, unprecedented opportunities for monetising the wide variety of EU creative and making this content available for new technologies, such as artificial intelligence training systems, will most probably be lost. The problem has a worldwide dimension. While the US have already taken steps to provide an integrated data space for music as of 1 January 2021, the EU is facing major obstacles not only in the field of music but also in other creative industry sectors. Weighing costs and benefits, there can be little doubt that new data improvement initiatives and sufficient investment in a better copyright data infrastructure should play a central role in EU copyright policy. A trade-off between data harmonisation and interoperability on the one hand, and transparency and accountability of content recommender systems on the other, could pave the way for successful new initiatives. Download the manuscript from SSRN\nOur Slovak Demo Music Database project is a best example for this. We started systematically collect publicly available information from Slovak artists (in our write-in process) and ask them to give GDPR-protected further data (in our opt-in process) to create a comprehensive database that can help recommendation engines as well as market-targeting or educational AI apps.\nWe believe that one of the problems of current AI algorithms that they solely or almost only work with English language documentation, putting other, particularly small language repertoires at risk of being buried below well-documented music mainly arriving from the United States.\nWe are looking for rightsholders and their organizations, artists, researchers to work with us to find out how we can increase the visibility of European music.\n","date":1613232600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613578200,"objectID":"5886c1d52fa056b6436c70138f3cd4eb","permalink":"https://reprex.nl/post/2021-02-13-european-visibility/","publishdate":"2021-02-13T18:10:00+02:00","relpermalink":"/post/2021-02-13-european-visibility/","section":"post","summary":"While the US have already taken steps to provide an integrated data space for music as of 1 January 2021, the EU is facing major obstacles not only in the field of music but also in other creative industry sectors. Weighing costs and benefits, there can be little doubt that new data improvement initiatives and sufficient investment in a better copyright data infrastructure should play a central role in EU copyright policy. Preprint of our article with copyright researchers.","tags":["listen-local","trustworthy-ai","music-observatory","metadata","copyright"],"title":"Ensuring the Visibility and Accessibility of European Creative Content on the World Market: The Need for Copyright Data Improvement in the Light of New Technologies","type":"post"},{"authors":["Martin Senfleben","Thomas Margoni","Daniel Antal","Balazs Bodó","Stef van Gompel","Christian Handke","Martin Kretschmer","Joost Poort","João Quintais","Sebastian Felix Schwemer"],"categories":null,"content":"In the European Strategy for Data, the European Commission highlighted the EU’s ambition to acquire a leading role in the data economy. At the same time, the Commission conceded that the EU would have to increase its pools of quality data available for use and re-use. In the creative industries, this need for enhanced data quality and interoperability is particularly strong. Without data improvement, unprecedented opportunities for monetising the wide variety of EU creative and making this content available for new technologies, such as artificial intelligence training systems, will most probably be lost. The problem has a worldwide dimension. While the US have already taken steps to provide an integrated data space for music as of 1 January 2021, the EU is facing major obstacles not only in the field of music but also in other creative industry sectors. Weighing costs and benefits, there can be little doubt that new data improvement initiatives and sufficient investment in a better copyright data infrastructure should play a central role in EU copyright policy. A trade-off between data harmonisation and interoperability on the one hand, and transparency and accountability of content recommender systems on the other, could pave the way for successful new initiatives.\nThe published article: https://www.jipitec.eu/issues/jipitec-13-1-2022/5515\nPreprint version The earlier preprint version on SSRN our for direct download here on Data \u0026amp; Lyrics. Senftleben, Martin and Margoni, Thomas and Antal, Daniel and Bodó, Balázs and Gompel, Stef van and Handke, Christian and Kretschmer, Martin and Poort, Joost and Quintais, João and Schwemer, Sebastian Felix, Ensuring the Visibility and Accessibility of European Creative Content on the World Market - The Need for Copyright Data Improvement in the Light of New Technologies and the Opportunity Arising from Article 17 of the CDSM Directive (February 12, 2021). Available at SSRN: https://ssrn.com/abstract=3785272 or http://dx.doi.org/10.2139/ssrn.3785272\n","date":1613214000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649952000,"objectID":"e70e0b6d3a205639554d42dc6662aeb0","permalink":"https://reprex.nl/publication/european_visibilitiy_2022/","publishdate":"2021-02-13T11:00:00Z","relpermalink":"/publication/european_visibilitiy_2022/","section":"publication","summary":"While the US have already taken steps to provide an integrated data space for music as of 1 January 2021, the EU is facing major obstacles not only in the field of music but also in other creative industry sectors. Weighing costs and benefits, there can be little doubt that new data improvement initiatives and sufficient investment in a better copyright data infrastructure should play a central role in EU copyright policy. A trade-off between data harmonisation and interoperability on the one hand, and transparency and accountability of content recommender systems on the other, could pave the way for successful new initiatives.","tags":["Metadata","Trustworthy AI","Royalties"],"title":"Ensuring the Visibility and Accessibility of European Creative Content on the World Market: The Need for Copyright Data Improvement in the Light of New Technologies","type":"publication"},{"authors":["Daniel Antal, CFA"],"categories":null,"content":"IViRtual 9 April 2021\n","date":1612260600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614712200,"objectID":"1158beb08af9e403fdb31c68034bfaf1","permalink":"https://reprex.nl/talk/reprex-introduction-in-ivir/","publishdate":"2021-02-02T10:10:00Z","relpermalink":"/talk/reprex-introduction-in-ivir/","section":"event","summary":"Reprex introduces our research automation products on the IViRtual seminar.","tags":["Open data","sustainability"],"title":"Reprex introduction in IVIR","type":"event"},{"authors":null,"categories":null,"content":"If you cannot find the right data for your policy evaluation, your consulting project, your PhD thesis, your market research, or your scientific research project, it does not mean that the data does not exist, or that it is not available for free. In our experience, up to 95% of available open data is never used, because potential users do not realize it exists or do not know how to access it.\nEvery day, thousands of new datasets become available via the EU open data regime, freedom of information legislation in the United States and other jurisdictions, or open science and scientific reproducibility requirements — but as these datasets have been packaged or processed for different primary, original uses, they often require open data experts to locate them and adapt them to a usable form for reuse in business, scientific, or policy research.\nThe creative and cultural industries often do not participate in government statistics programs because these industries are typically comprised of microenterprises that are exempted from statistical reporting and that file only simplified financial statements and tax returns. This means that finding the appropriate private or public data sources for creative and cultural industry uses requires particularly good data maps.\nData curation means that we are continuously mapping potential data sources and sending requests to download and quality test the most current data sources. Our CEEMID project has produced several thousand indicators, of which a few dozen are available in our Demo Music Observatory.If you have specific data needs for a scientific research, policy evaluation, or business project, we can find and provide the most suitable, most current, and best value data for analysis or for ethical AI applications.\n","date":1611187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611187200,"objectID":"26cccae28579337ef19d4e2d3e6c56c6","permalink":"https://reprex.nl/services/data-curation/","publishdate":"2021-01-21T00:00:00Z","relpermalink":"/services/data-curation/","section":"services","summary":"We create high value key business and policy evaluation indicators. Scientific proofs require the combination of correctly matching, formatting, and verifying controlled pieces of data. Our data comes from verified and legal sources, with information about use rights and a complete history. You can always take a look at the processing code, too. We do not deal in blood diamonds.","tags":["curation"],"title":"Data Curation","type":"services"},{"authors":null,"categories":null,"content":"Data analysts spend 80% of their time on data processing, even though computers can perform these task much faster, with far less errors, and they can document the process automatically. Data processing can be shared: an analyst in a company and an analyst in an NGO does not have to reprocess the very same data twice*\nSee our blogpost How We Add Value to Public Data With Imputation and Forecasting?.\nPublic data sources are often plagued by missng values. Naively you may think that you can ignore them, but think twice: in most cases, missing data in a table is not missing information, but rather malformatted information. This approach of ignoring or dropping missing values will not be feasible or robust when you want to make a beautiful visualization, or use data in a business forecasting model, a machine learning (AI) applicaton, or a more complex scientific model. All of the above require complete datasets, and naively discarding missing data points amounts to an excessive waste of information. In this example we are continuing the example a not-so-easy to find public dataset.\nCompleting missing datapoints requires statistical production information (why might the data be missing?) and data science knowhow (how to impute the missing value.) If you do not have a good statistician or data scientist in your team, you will need high-quality, complete datasets. This is what our automated data observatories provide.\nSee our blogpost about the Data Sisyphus blogpost. We have a better solution. You can always rely on our API to import directly the latest, best data, but if you want to be sure, you can use our regular backups on Zenodo. Zenodo is an open science repository managed by CERN and supported by the European Union. On Zenodo, you can find an authoritative copy of our indicator (and its previous versions) with a digital object identifier, for example, 10.5281/zenodo.5652118. These datasets will be preserved for decades, and nobody can manipulate them. You cannot accidentally overwrite them, and we have no backdoor access to modify them.\n","date":1611187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611187200,"objectID":"d51ed70385001d6a6fc7e9ebd3da38c2","permalink":"https://reprex.nl/services/data-processing/","publishdate":"2021-01-21T00:00:00Z","relpermalink":"/services/data-processing/","section":"services","summary":"We create high value key business and policy evaluation indicators. Scientific proofs require the combination of correctly matching, formatting, and verifying controlled pieces of data. Our data comes from verified and legal sources, with information about use rights and a complete history. You can always take a look at the processing code, too. We do not deal in blood diamonds.","tags":["data-processing"],"title":"Data Processing","type":"services"},{"authors":null,"categories":null,"content":"We want to ensure that individual researchers, artists, and professionals, as well as NGOs and small and large organizations can benefit equally from big data in the age of artificial intelligence.\nBig data creates inequality and injustice because it is only the big corporations, big government agencies, and the biggest, best endowed universities that can finance long-lasting, comprehensive data collection programs. Big data, and large, well-processed, tidy, and accurately imputed datasets allow them to unleash the power of machine learning and AI. These large entities are able to create algorithms that decide the commercial success of your product and your artwork, giving them a competitive edge against smaller competitors while helping them evade regulations.\nCheck out our iotables software that helps the use of national accounts data from all EU members states to create economic direct, indirect and induced economic impact calculation, such as employment multipliers or GVA affects of various cultural and creative economy policies.\nCheck out our regions software that helps the harmonization of various European and African standardized surveys.\nCheck out our retroharmonize software that helps the harmonization of various European and African standardized surveys.\n","date":1611187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625616000,"objectID":"96b2cb649d5ffdcef063e548e1e2e92f","permalink":"https://reprex.nl/services/data-as-service/","publishdate":"2021-01-21T00:00:00Z","relpermalink":"/services/data-as-service/","section":"services","summary":"We provide our clients with simple datasets, databases, harmonized survey data, and various other rich data applications; we provide them with continuous access to high-quality, re-processed, re-usable public sector and scientific data.","tags":["daas","api"],"title":"Data-as-Service","type":"services"},{"authors":null,"categories":null,"content":"Big data and automation create new inequalities and injustices and has a potential to create a jobless growth. Our Economy Observatory is a fully automated, open source, open data observatory that produces new indicators from open data sources and experimental big data sources, with authoritative copies and a modern API.\nOur observatory is monitoring the European economy to protect the consumers and the small companies from unfair competition both from data and knowledge monopolization and robotization. We take a critical SME-, intellectual property policy and competition policy point of view automation, robotization, and the AI revolution on the service-oriented European social market economy.\nWe would like to create early-warning, risk, economic effect, and impact indicators that can be used in scientific, business and policy contexts for professionals who are working on re-setting the European economy after a devastating pandemic and in the age of AI. We would like to map data between economic activities (NACE), antitrust markets, and sub-national, regional, metropolitian area data.\nGet involved in services: our ongoing projects, team of contributors, open-source libraries and use our data for publications. See some use cases.\nFollow news about us or the more comprehensive Data \u0026amp; Lyrics blog.\nContact us .\nDownload our competition presentation\nOur Product/Market Fit was validated in the world’s 2nd ranked university-backed incubator program, the Yes!Delft AI Validation Lab.\n","date":1611187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611187200,"objectID":"1801f54c73eaa82e71a6082b244a6fce","permalink":"https://reprex.nl/observatories/economy/","publishdate":"2021-01-21T00:00:00Z","relpermalink":"/observatories/economy/","section":"observatories","summary":"An incubator for socio-economic data observatories. Its first offspring is the Competition Data Observatory.","tags":["economy"],"title":"Economy Data Observatory","type":"observatories"},{"authors":["Daniel Antal","Dáša Bulíková (translator)"],"categories":null,"content":"Download the study in Slovak or in English.\nIn 2015, realizing the low visibility and income-generating potential of Slovak music, the legislation introduced an amendment to the broadcasting act to regulate local content in radiostreams. The Slovak content promoting policy was well-intended but not based on any impact assessment, and it reached its goal only partially.\nThe Slovak broadcasting quotas in comparison with other national quotas a very simple, and they are impossible to measure, which makes both compliance and enforcement very difficult. Radio editors do not get any help to find music that fits into the playlists and fulfil the quota obligations – in many cases, it is impossible for them to find out if a song actually meets the quota requirements. For the same reason, neither is enforcement possible.\nAnother deficiency of the broadcasting quotas is that because of its fuzzy target, it is not clear whom it tries to help, and it has few friends. It is unclear how performers, composers or Slovak music producers can benefit from the system. Furthermore, it only helps a few genres, and it decreases the chances of other Slovak music in instrumental and non-Slovak language genres (for example, classical, jazz, rock) to be heard.\nAnd at last, radio is losing its importance in music discovery. New generation find the music during their music discovery age on YouTube and digital streaming platforms. A Slovak content promoting policy that does not work on digital streaming platforms will be obsolete when radio content providers will switch to digital streaming in the foreseeable future.\nOur Feasibility Study follows the following logic: In the first chapter we introduce various music recommendation systems in the context of local content promotion polices, like local mandatory content quota regulations.\nIn the second chapter, we consider the market-based or creative industry economy supporting policy goals, measurements, and potential support given to artists and producers.\nWe then turn in the third chapter to content-based local regulations promoting the use of the Slovak language or Slovak music content, irrespective of the performers and producers nationality, residence or ethnicity.\nWe introduce the idea of the Slovak Music Database, a comprehensive, mainly opt-in, opt-out database that of Slovak artists and Slovak music that should be supported by the local content regulation and other policies. We also create a Demo Slovak Music Database to understand the problem and scope of the creation of the comprehensive version.\nThe project website contains the Demo Slovak Music Database.\nWe also created a Demo Recommendation System. We explain here why.\nResearch questions Why are the total market shares of Slovak music relatively low both on the domestic and the foreign markets? How can we measure the market share of the Slovak music in the domestic and foreign markets? How can we measure the value gap between what some media platforms, most particularly the biggest YouTube, does not pay out to the Slovak stakeholders within Slovakia? What is the interplay of the various definitions on market share and national quota targets? How ‘shadow-markets’ of home copying and unlicensed media platforms, such as YouTube impact market shares directly and national quotas indirectly? How can modern data science, predictive microeconomics and statistics help increase the market share of Slovak music in Slovakia and abroad? Thanks for the entire Reprex team who contributed to the English version:\nDr. Emily H. Clarke, musicology Stef Koenis, musicologist, musician Dr. Andrés Garcia Molina, data scientist, musicologist, editor Kátya Nagy, music journalist, research assistant; and the Slovak version:\nDominika Semaňáková, musicologist, editor Dáša Bulíková, musician, translator. ","date":1609066800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609066800,"objectID":"16950d94b575c4889e897c4522ae7f4d","permalink":"https://reprex.nl/publication/listen_local_2020/","publishdate":"2020-12-27T11:00:00Z","relpermalink":"/publication/listen_local_2020/","section":"publication","summary":"Why are the total market shares of Slovak music relatively low both on the domestic and the foreign markets? How can we measure the market share of the Slovak music in the domestic and foreign markets? We offer some answers and solution based on empirical research and with the creation of a database and an AI application.\"","tags":["Listen Local","Trustworthy AI","Music recommender systems"],"title":"Feasibility Study On Promoting Slovak Music In Slovakia \u0026 Abroad","type":"publication"},{"authors":["Daniel Antal"],"categories":null,"content":"We are finalizing our first local recommendation system, Listen Local Slovakia, and the accompanying Demo Slovak Music Database. Our aim is\nShow how the Slovak repertoire is seen by media and streaming platforms What are the possibilities to give greater visibility to the Slovak repertoire in radio and streaming platforms What are the specific problems why certain artists and music is almost invisible. In the next year, we would like to create a modern, comprehensive national music database that serves music promotion in radio, streaming, live music within Slovakia and abroad.\nTo train our locally relevant, alternative recommendation system, we filled the Demo Slovak Music Database from two sources. In the opt-in process we asked artists to participate in Listen Local, and we selected those artists who opted in from Slovakia, or whose language is Slovak. In the write-in process we collected publicly available data from other artists that our musicology team considered to be Slovak, mainly on the basis of their language use, residence, and other public biographical information. The following artists form the basis of our experiment. (If you want to be excluded from the write-in list, write to us, or you want to be included, please, fill out this form.)\nClick here to view the table on a separate page\nModern recommendation systems usually rely on data provided by artists or their representatives, data on who and how is listening to their music, and what music is listened to by the audience of the artists, and certain musicological features of the music. Usually they collect data from various data sources, but these data sources are mainly English language sources.\nThe problem with these recommendation systems is that they do not help music discovery, and make starting new acts very difficult. Recommendation systems tend to help already established artists, and artists whose work is well described in the English language.\nOur alternative recommendation system is a utility-based system that gives a user-defined priority to artists released in Slovakia, or artists identified as Slovak, or both. The system can be extended for lyrics language priorities, too. Currently, our app is demonstration to provide a more comprehensive database-driven tool that can support various music discovery, recommendation or music export tools. Our Feasibility Study to build such tools and our Demo App is currently under consultation with Slovak stakeholders.\nListen Local is developing transparent algorithms and open source solutions to find new audiences for independent music. We want to correct the injustice and inherent bias of market leading big data algorithms. If you want your music and audience to be analysed in Listen Local, fill this form in. We will include you in our demo application for local music recommendations and our analysis to be revealed in December.\n","date":1608217800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608217800,"objectID":"4fbaf6ba4ffcfe3c149756a9645d50ab","permalink":"https://reprex.nl/post/2020-12-17-demo-slovak-music-database/","publishdate":"2020-12-17T17:10:00+02:00","relpermalink":"/post/2020-12-17-demo-slovak-music-database/","section":"post","summary":"We needed a database of Slovak music to show how that national repertoire is seen by media and streaming platforms, how can we give it greater visibility in radio and streaming platforms, and what are the specific problems why certain artists and music is almost invisible.","tags":["listen-local","Slovakia","justice","algorithms","big-data","recommendations","local-content-requirements"],"title":"Demo Slovak Music Database","type":"post"},{"authors":["Daniel Antal"],"categories":null,"content":" The first version of our demo application Recommendation systems utilize knowledge about music content and their audiences while also pursuing the objectives or needs of recommenders.\nThe simplest recommendation systems just follow the charts: for example, they select from well-known current or perennial greatest hits. Such a system may work well for an amateur DJ in a home party or a small local radio that just wants to make sure that the music in its programme will be liked by many people. They reinforce existing trends and make already popular songs and their creators even more popular.\nIf the recommendation engine is supported by big data and a machine learning system – or increasingly, a combination of several machine learning algorithms – the general modus operandi is to exploit information about both content and users in order to achieve certain goals.\nHow algorithmic recommendation systems work? How recommendation systems work? Spotify’s recommendation system is a mix of content- and collaborative filtering that exploits information about users’ past behaviour (e.g. liked, skipped, and re-listened songs), the behaviour of similar users, as well as data collected from the users’ social media and other online activities, or from blogs. Deezer uses a similar system that is boosted by the acquisition of Last.fm – big data created from user comments are used to understand the mood of the songs, for example.\nSpotify makes 16 billion music recommendations each month in 2020. YouTube, which plays an even larger role in music discovery, uses a system comprised of two neural networks: one for candidate generation and one for ranking. The candidate generation deep neural network provides works on the basis of collaborative filtering, while the ranking system is based on content-based filtering and a form of utility ranking that takes into consideration the user’s languages, for example.\nWhat makes these systems common is that they maximize the algorithm creators’ corporate key performance indicators. Spotify wants to be ‘your playlist to life’ and increase the amount of music played during work or sports in the background, during travelling, or active music listening –- i.e. maximizing the number of hours spent using it, and do not let empty timeslots for other music providers, such as radio stations. YouTube and Netflix have similar targets. They are in many ways like commercial radio targets, which want to maximize the time spent listening to the broadcast stream. Radios and YouTube, in particular, have similar goals because they are mainly financed through advertising. For Spotify or Netflix, their key financial motivation is to avoid users’ cancelling their subscriptions or changing it to different providers, such as Amzon, Apple or Deezer.\nWhat is the problem with black box recommendation systems? What they also have in common is that they do not aim to give a fair chance to each uploaded song, serve equally every artist, or provide whatever equality of chances for English, Slovak or Farsi language content.\nThey tend to reinforce trends similarly to music charts, but with far bigger efficiency. As the Dutch comedian, author and journalist Arjen Lubach explains the YouTube algorithm, to keep their personal recommendations engaging all the day and all of the night, they create a comfortable universe for the user allows little distraction in. If the user wants to listen to global hit music, or stoner rock, it will never be distracted with anything else.\nZondag met Lubach on Dutch public broadcaster VPRO. Click settings sign to change the language of the captions.\nThe problem with such hyper-personalized media is that they leave no room for public activities. Public broadcasters, which had a monopoly to television broadcasting in most European countries until the early 1990s, for example, were aiming to air a diversity of news, knowledge and access to local culture. Many countries on all continents have maintained local content guidelines for broadcasting on public, commercial and community television and radio channels, for example, local music and films, and reliable news as a public service. Personalized media-, social media- and streaming platforms do not have such obligations.\nBlack box recommendation systems usually maximize a corporate key performance indicator, and they are not subject to usual public new service or local content regulations that traditional broadcast media is.\nThe goal and the steps that the algorithm is pursuing is not know to content creators, and they do not know when will the algorithm work for their benefit or against them.\nTransparent and regulated AI In our view, utility-based recommendation system can provide a bridge between current, corporate-owned systems that maximize a media or streaming platforms’ business indicators.\nPublic new service requirements or local content requirements (“national quotas”) set for commercial broadcasting are similar to utility or …","date":1607958600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607958600,"objectID":"47f57bbd20cd48de6adc243ce9e2328b","permalink":"https://reprex.nl/post/2020-12-15-alternative-recommendations/","publishdate":"2020-12-14T17:10:00+02:00","relpermalink":"/post/2020-12-15-alternative-recommendations/","section":"post","summary":"Regulating black box, private algorithms and data monopolies is only a first step to damage control. Deploying white, transparent algorithms and building collaborative or open data pools can only guarantee fairness in the digital platforms, in recommendations, and generally in the use of AI.","tags":["listen-local","Slovakia","justice","algorithms","big-data","recommendations","local-content-requirements"],"title":"Listen Local: Why We Need Alternative Recommendation Systems","type":"post"},{"authors":["Daniel Antal"],"categories":null,"content":"PLOS One is the fourth most influential multidisciplinary journal after Nature, and Science, and Proceedings of the National Academy of Sciences of the United States of America (based on H index.) On December 3, 2020 it published a paper co-authored by Dr. Balazs Bodo, associate professor at the Institute for Information Law (IViR), Daniel Antal (Reprex, Demo Music Observatory), a data scientist interested in reproducible research, as an independent researcher, and Zoltan Puha, a Data Science PhD at Tilburg University, JADS. PLOS (Public Library of Science) is a nonprofit Open Access publisher, empowering researchers to accelerate progress in science and medicine by leading a transformation in research communication.\nThe article utilizes the our reproducible datasets created with our regions package, and builds on many years of expertise in empirical research on the field of music and audiovisual piracy, home copying and private copying compensation (see for example Private Copying in Croatia.) Our aim is to provide reliable, high quality indicators for the creative industries not only on national, but provincial, state, regional and metropolitan area level, too, because these levels are often more relevant for creators, performers and policy-makers.\nThe topic of the paper is Library Genesis (LG), the biggest piratical scholarly library on the internet, which provides copyright infringing access to more than 2.5 million scientific monographs, edited volumes, and textbooks. The paper uses advanced statistical methods to explain why researchers around the globe use copyright infringing knowledge resources. The analysis is based on a huge usage dataset from LG, as well as data from the World Bank, Eurostat, and Eurobarometer, to identify the role of macroeconomic factors, such as R\u0026amp;D and higher education spending, GDP, researcher density in scholarly copyright infringing activities.\nWe created a global and a far more detailed European model for pirate book downloads. The main finding of the paper is that open access, even if it is radical, is not a panacea. The hypothesis of the research was that researchers in low-income regions use piratical open knowledge resources relatively more to compensate for the limitations of their legal access infrastructures. The authors found evidence to the contrary. Researchers in high income countries and European regions with access to high quality knowledge infrastructures, and high levels of funding use radical open access resources more intensively than researchers in lower income countries and regions, with less resourceful libraries. This means that while open knowledge is an important resource to close the knowledge gap between centrum and periphery, equality in access does not translate into equality in use. Structural knowledge inequalities are both present and are being reproduced in the context of open access resources.\nThe paper is unique not just because of the data it is based on. It also sets new standards in interdisciplinary legal research by publishing the paper, the data and the software code in the same time in open access repositories, following reproducible research best practices — the practices that we want to promote in our Demo Music Observatory and further data observatories to serve business, evidence-based policy and scientific research.\n","date":1607148600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607148600,"objectID":"2d8c015284b58d7783790ea7188cc50e","permalink":"https://reprex.nl/post/2020-12-04-pirate-libraries/","publishdate":"2020-12-05T08:10:00+02:00","relpermalink":"/post/2020-12-04-pirate-libraries/","section":"post","summary":"The article utilizes the our reproducible datasets created with our regions package that provides to provides high quality indicators for the creative industries on provincial, state, regional and metropolitan area level, and builds on many years of expertise in empirical research on the field of music and audiovisual piracy, home copying and private copying compensation.","tags":["reproducible-science","reproducible-research","music-observatory"],"title":"Reproducible research in practice: empirical study on the structural conditions of book piracy in global and European academia","type":"post"},{"authors":["Balazs Bodó","Daniel Antal","Zoltan Puha"],"categories":null,"content":"PLOS One is the fourth most influential multidisciplinary journal after Nature, and Science, and Proceedings of the National Academy of Sciences of the United States of America (based on H index.) On December 3, 2020 it published a paper co-authored by Dr. Balazs Bodo, associate professor at the Institute for Information Law (IViR), Daniel Antal (Reprex, Demo Music Observatory), a data scientist interested in reproducible research, as an independent researcher, and Zoltan Puha, a Data Science PhD at Tilburg University, JADS. PLOS (Public Library of Science) is a nonprofit Open Access publisher, empowering researchers to accelerate progress in science and medicine by leading a transformation in research communication.\nThe article utilizes the our reproducible datasets created with our regions package, and builds on many years of expertise in empirical research on the field of music and audiovisual piracy, home copying and private copying compensation (see for example Private Copying in Croatia.) Our aim is to provide reliable, high quality indicators for the creative industries not only on national, but provincial, state, regional and metropolitan area level, too, because these levels are often more relevant for creators, performers and policy-makers.\nThe topic of the paper is Library Genesis (LG), the biggest piratical scholarly library on the internet, which provides copyright infringing access to more than 2.5 million scientific monographs, edited volumes, and textbooks. The paper uses advanced statistical methods to explain why researchers around the globe use copyright infringing knowledge resources. The analysis is based on a huge usage dataset from LG, as well as data from the World Bank, Eurostat, and Eurobarometer, to identify the role of macroeconomic factors, such as R\u0026amp;D and higher education spending, GDP, researcher density in scholarly copyright infringing activities.\nWe created a global and a far more detailed European model for pirate book downloads. The main finding of the paper is that open access, even if it is radical, is not a panacea. The hypothesis of the research was that researchers in low-income regions use piratical open knowledge resources relatively more to compensate for the limitations of their legal access infrastructures. The authors found evidence to the contrary. Researchers in high income countries and European regions with access to high quality knowledge infrastructures, and high levels of funding use radical open access resources more intensively than researchers in lower income countries and regions, with less resourceful libraries. This means that while open knowledge is an important resource to close the knowledge gap between centrum and periphery, equality in access does not translate into equality in use. Structural knowledge inequalities are both present and are being reproduced in the context of open access resources.\nThe paper is unique not just because of the data it is based on. It also sets new standards in interdisciplinary legal research by publishing the paper, the data and the software code in the same time in open access repositories, following reproducible research best practices — the practices that we want to promote in our Digital Music Observatory and further data observatories to serve business, evidence-based policy and scientific research.\nOur research was funded from the Horizon Europe 2020 Research grant #710722 “OPENing UP new methods, indicators and tools for peer review, dissemination of research results, and impact measurement”.\n","date":1606993200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606993200,"objectID":"00bb271b4cb0d1dcd93784d6dfc2e32b","permalink":"https://reprex.nl/publication/scholarly_pirate_libraries_2020/","publishdate":"2020-12-03T11:00:00Z","relpermalink":"/publication/scholarly_pirate_libraries_2020/","section":"publication","summary":"The topic of the paper is Library Genesis (LG), the biggest piratical scholarly library on the internet, which provides copyright infringing access to more than 2.5 million scientific monographs, edited volumes, and textbooks. The paper uses advanced statistical methods to explain why researchers around the globe use copyright infringing knowledge resources. The analysis is based on a huge usage dataset from LG, as well as data from the World Bank, Eurostat, and Eurobarometer, to identify the role of macroeconomic factors, such as R\u0026D and higher education spending, GDP, researcher density in scholarly copyright infringing activities.","tags":["market-report","Books","Piracy","Shadow libraries"],"title":"Can scholarly pirate libraries bridge the knowledge access gap? An empirical study on the structural conditions of book piracy in global and European academia","type":"publication"},{"authors":["Daniel Antal"],"categories":null,"content":"The Feasibility study for the establishment of a European Music Observatory was published on 13 November. Our private observatory, CEEMID was consulted in the creation of the Feasibility Study, and some of our recommendations found way into the consultant’s document. We created a Demo Music Observatory to provide a practical guidance on the decisions facing the European stakeholders, and to answer the questions that were left open in the Feasibility Study — particularly on data integration and the institutional model, where a wrong choice can lead to very long delivery time, quality control and budgeting.\nWe have been developing our Demo Music Observatory in the world’s 2nd ranked university-backed incubator program, the Yes!Delft AI Validation Lab since 15 September 2020. Our aim is to show a better organizational model, examples of research automation and other data integration innovation that can reduce the budgetary needs of the European Music Observatory by 80-90% and provide far more timely, accurate, and relevant service than most data observatories in Europe.\nCEEMID has been creating a similar data observatory to the foreseen European Data Observatory, solely based on the contribution of about 60 European stakeholders. As the Feasibility Study suggests, we would be happy to transfer much of CEEMID’s content to the European Data Observatory, which could potentially fill up about 50-70% of the envisioned observatory. We are building our Demo Music Observatory based on the 2000 pan-European indicators collected by CEEMID since 2014.\nChallenge Our Demo Observatory: Check out the Music Diversity \u0026amp; Circulation Pillar of our Demo Music Observatory. If you do not find what you are looking for, contact us — we will try to put the data there from our repositories.\nIllusory data gap: active and music participation is available on EU level both for gender groups or four ethnic minorities – this is regularly featured in various European CAP surveys and in our national CAP surveys, too. The Feasibility Study is based on perceived data gaps between data needs of the European stakeholders and data availability. We have shown earlier this year to the European stakeholders that much of these data gaps are illusory. We would like to give about 50 indicators with full documentation, automated, weekly, monthly, quarterly, or annual refreshment for free for all music industry users. We would like to challenge the stakeholders to formulate data requests to us and think together on the ways how could the European music industry build a better observatory faster and with less cost.\nChallenge Our Demo Observatory: Check out the Music Economy Pillar of our Demo Music Observatory. If you do not find what you are looking for, contact us — we will try to put the data there from our repositories.\nThe Feasibility Study concludes that a “European Music Observatory would require a very significant allocation of funds, beyond what could be currently expected from the possible budget of the future Creative Europe programme”. While the Feasibility Study provide cost options, or any cost-benefit analysis, we are certain that this is an exaggeration. Most European data observatories operate with an annual 20,000-200,000-euro subsidy. We want to show with our Demo Music Observatory what can be achieved with an annual budget of 20,000 euros, 50,000 euros, 100,000 euros or 200,000 euros.\nChallenge Our Demo Observatory: Check out the Music, Society and Citizenship Pillar of our Demo Music Observatory. If you do not find what you are looking for, contact us — we will try to put the data there from our repositories.\n","date":1605502980,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605502980,"objectID":"2193c0e77a81b141c64639299215b004","permalink":"https://reprex.nl/post/2020-11-16-european-music-observatory-feasibility/","publishdate":"2020-11-16T07:03:00+02:00","relpermalink":"/post/2020-11-16-european-music-observatory-feasibility/","section":"post","summary":"The Feasibility Study on the European Music Observatory was published on 13 November.  We created a Demo Music Observatory to provide a practical guidance on the decisions facing the European stakeholders, and to answer the questions that were left open in the Feasibility Study --- particularly on data quality, time to build, and costs.","tags":["Europe","EU","reproducible-research","music-observatory"],"title":"Feasibility Study For The Establishment Of A European Music Observatory \u0026 The Demo Observatory","type":"post"},{"authors":null,"categories":null,"content":"“Big data creates injustice.” – Cathy O’Neil, author of Weapons of Math Destruction\nListen Local is a trustworthy, ethical AI-powered system that aims to help great artists in small organizations and small countries using big data. We want to make sure that audiences are not only recommended global superhits, but locally relevant music, too. At present, corporate algorithms fail to connect listeners in small countries with music from the local scene - with artists whom the listener can easily see perform live in local venues, who sing in the listener’s language and who connect with the listener’s feelings and experiences.\nFrom the artist’s perspective, we want to understand why certain demographics of artists only get partly paid, or not paid at all. We want to understand why some artists are never recommended by corporate AI algorithms. Every good music should be able to find its audience on streaming platforms; and, moreover,the global streaming platforms must give equal chances and fair remuneration to all musicians regardless of language, ethnicity, gender, race, or any other such factor.\nMusic streaming services seemingly make the entire world repertoire available to any audience – which requires an entirely new approach to music education and music discovery. Most people discover music and learn to like a certain style or genre in their teenage years. If the AI algorithms that make personalized playlists and recommendations do not include locally relevant music, young people will not be exposed to local discoveries in their taste formation processes. This influences the genres and styles of music that people are open to encountering at later life phases and in later social worlds, including the exposure that adults pass on to their children.\nListen Local wants to prevent global hits from colonizing local musical ecosystems and taking attention, visibility and listening time from local acts. Music is a social activity, and young people should have the opportunity to discover artists whom they can see performing live with their friends, with whom they can learn to play on the same stage, or behind the same turntable. Our goal is to connect young people as well as adults to music from their local communities, and to help artists from small countries gain fair access to audiences and opportunities in their communities and beyond.\nWhat do we do? We are building a recommendation system that allows the user – a radio DJ or music editor, an educator, or a music lover –- to control the recommendation algorithm: for example, to set language preferences or to find music in his or her town or country.\nWe are conducting statistical tests that measure biases in the way artists with different ethnic, national, country of origin, race, scene, genre, age or gender background are promoted and paid, or other biases of algorithms when they recommend music or sell it, to analyze how global hits colonize local music ecosystems and to determine how to prevent this from happening.\nThrough this, we are gaining understanding of why certain artists are never recommended, or never get paid. We are localizing AI. Because music for most artists is a local business, we are building tools that help artists connect to local audiences, target tour destinations that are within reach, and optimize domestic and foreign marketing efforts.\nWe are involved in various research and development activities. We are building prototype applications with our partners, and we are conducting impact analyses to detect AI and big data problems. We are collaborating with eminent competition law and copyright law practitioners to understand how independent artists and small labels, publishers, and small country collective management organizations can be protected from the adverse effects of big data and AI.\nWhy do we do it? Currently more than half of global music sales is automated through AI algorithms. YouTube, Spotify, Apple Music and other music and media streaming platforms use AI that compares the audience member’s preferences, biographical information about the creators and performers of the music, and the content and aesthetic qualities of the music to personalize recommendations from more than a hundred million recordings and videos. If the AI algorithm is biased or the supporting data and metadata is incomplete or faulty, some artists and performers will never connect with new audiences, nor get paid. Further compounding this problem, bookings for festivals and clubs - the primary income source for most musicians and their technical and managerial support teams - are increasingly conducted through automated pre-selection by algorithms that monitor the recordings, sales, and fan bases of artists.\nThe severity of this problem is demonstrated by our pilot project, based on the rich, emerging local music market of Slovakia. Through our strong relationships with music stakeholders, we gained access to vast amounts of confidential data and insider …","date":1601373600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601373600,"objectID":"b2e19b1e9ca794de9ecf52207abfca5e","permalink":"https://reprex.nl/project/listen-local/","publishdate":"2020-09-29T10:00:00Z","relpermalink":"/project/listen-local/","section":"project","summary":"Listen Local is a trustworthy, ethical AI-powered system that aims to help great artists in small organizations and small countries using big data. We want to make sure that audiences are not only recommended global superhits, but locally relevant music, too. At present, corporate algorithms fail to connect listeners in small countries with music from the local scene - with artists whom the listener can easily see perform live in local venues, who sing in the listener’s language and who connect with the listener’s feelings and experiences.","tags":["Listen Local","Trustworthy AI","Music recommendations"],"title":"Listen Local","type":"project"},{"authors":null,"categories":null,"content":"Reprex with its Digital Music Observatory team was commissioned to prepare an analysis on the justified and not justified differences in music creators’ earnings. We have posted our most important findings in an earlier blogpost (Music Creators’ Earnings in the Streaming Era. United Kingdom Research Cooperation With the Digital Music Observatory.\nThe UK Intellectual Property Office has published the entire report on the music creators’ earnings, and we have made our detailed analysis available in a side-publication. Reprex also signed an agreement with the researchers of the Music Creators’ Earnings project to deposit all data published in the report in the Digital Music Observatory, and to promote the building of the observatory further.\nThe research questions asked in this report are related to the Music Creator Earnings’ Project (MCE), exploring issues concerning equitable remuneration and earnings distributions. We were tasked with providing a longitudinal analysis of earnings development and relating our findings to equitable remuneration. The starting point of our work was centred around a very broadly defined problem: how much money music creators (rightsholders) earn from streaming, how these earnings are distributed, and how the earnings and their distribution have developed during the last decade.\nWe have started to retrospectively harmonize the Music Creators Earnigs survey for the the Digital Music Observatory. The survey’s raw data is accessible on the website of the UKIPO here. Because of the bias of the survey, we did not include statistical indicators of the survey yet in our observatory, but we made the processed data available on our open repository space on Zenodo. Nevertheless, because of the relatively large sample size (n=708) we believe that important comparisons can be made with our CEEMID surveys, and we can shed some light on the earnings distribution of UK artists, and the way they distribute and finance their recordings.\nsee our Report See our main findings in a blogpost See the first version of the processed, machine readable, partially cleaned datafile of the Music Creators Earnings survey 2020. ","date":1601373600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601373600,"objectID":"cd113dff3dfcd7d17bda5f29dfac9017","permalink":"https://reprex.nl/project/mce/","publishdate":"2020-09-29T10:00:00Z","relpermalink":"/project/mce/","section":"project","summary":"Our Digital Music Observatory contributed to the Music Creators’ Earnings in the Streaming Era project with understanding the level of justified and unjustified differences in rightsholder earnings, and putting them into a broader music economy context. The entire research paper is published by the UK Intellectual Property office, and we made the details of our analysis available in a joint publication.","tags":["Competition","Music","United Kingdom"],"title":"Music Creators' Earning Project","type":"project"},{"authors":["Daniel Antal, CFA","Réka Szentirmay"],"categories":null,"content":"We would like to validate our product market/fit in two segments, business/policy research and scientific research, with a supporting role given to data journalism. Because we want to follow a bootstrapping strategy, we must focus on those clients where we find the highest value proposition, which is of course easier said than done. We see much interest in our offering from other continents, therefore we truly welcome the opportunity that we can do this on a truly global business canvas in one of the worlds’ top five incubators, the number 2 university-backed incubator in the world, second to none in Europe, in the Yes!Delft AI+Blockchain Validation Lab.\nIn Europe hundreds of thousands of microenterprises, such as record labels, video producers or book publishers are facing data and AI giants like Google’s YouTube, Apple Music, Spotify, Netflix or Amazon. If the recommendation engines of these giants do not recommend their songs, films or books, then their investments are doomed to fail, because about half of the global sales are driven by AI algorithms. When they make a claim for the missing money, they will immediately find themselves in a dispute with gigabytes of data that they can only handle with a data scientist, even though they do not even have an IT professional or an HR professional to make the hire.\nAn awful lot of money, creativity and real values are at stake, and we want to be on the creator’s side, their technician’s side, their manager’s side when they want to get a fair share from the pie and they want to help these industry leader to make the pie grow.\nThe UNESCO and the EU have been promoting as an organizational solution the fragmentation problem with the so-called data observatories that are pooling the business, policy, and scientific research needs of various domains, like music. This is an idea that we really like, and we believe that our research automation solutions can help these observatories to grow faster as ecosystems, create better quality and more timely data and research products and a far lower cost.\nWe define ourselves as a reproducible research company inspired by the philosophy of open collaboration, based on open-source software and open data. We want to explore various revenue models around these ideas.\nWe are not committed to open source licensing if more permissive licensing policies provide us with better opportunities.\nWe would like to explore various data-as-service models, because we do not want to be locked into the position of cheap open data vendors.\nWe want to deploy AI applications that really help earning money in these sectors with playlisting, recommendation engines, forecasting applications, or royalty valuations, because our open collaboration approach brings up enough data sooner to than its alternatives, because it manages inherent conflicts of interests, fragmentation, and decentralization better than hierarchical solutions.\nTimeline\nIn January CEEMID reached its peak: we introduced a 12-country reproducible research project made with only freelancers in Brussels, presented as best use case of evidence-based policy design.\nIn February Daniel visited the Yes!Delft Co-Lab to find out who would be the best co-founder to re-launch CEEMID as an enterprise.\nIn April we started to release our data as open data for validation.\nOne month ago we started-up.\nThen we launched the music.dataobservatory.eu project.\nA few other data observatories.\nBonus:\nPalato in the Hague, where we took our selfie and had an absolutely amazing dinner after the pitch. Check them out! ","date":1601047899,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601047899,"objectID":"3e2ff6f2fbf2e879fb3358f2feed666a","permalink":"https://reprex.nl/post/2020-09-25-yesdelft-validation/","publishdate":"2020-09-25T15:31:39Z","relpermalink":"/post/2020-09-25-yesdelft-validation/","section":"post","summary":"We see much interest in our offering from other continents, therefore we truly welcome the opportunity that we can do this on a truly global business canvas in one of the worlds’ top five incubators, the number 2 university-backed incubator in the world, in the Yes!Delft AI+Blockchain Validation Lab.","tags":["open-data","reproducible","start-up","open-source"],"title":"Product/Market Fit Validation in Yes!Delft","type":"post"},{"authors":["Daniel Antal, CFA"],"categories":null,"content":"Our original intention was to make surveying more accessible for music and creative industry partners, by relying more on already existing survey data, and better designing complementary, smaller surveys, becasue surveying, opinion polling is becoming increasingly expensive in the develop world. People are less and less likely to sit down for an interview in their houses. We have tried to harmonize our custom surveys, particuarly with Kantar in Hungary and Focus in Slovakia with exisiting EU projects. But we ended up making a part of international survey harmonization across countries and throughout years easier to automate.\nSurveys are like sensors for natural sciences and industrial production. They are essential for almost any social and economic statistical indicator, for calculating the inflation, parts of the GDP, participation in education programs. Making surveys easier to harmonize and exploit more already existing survey data can bring down research cost, and can increase research value at the same time. (See our earlier blog post Increase The Value Of Market Research With Open Data And Survey Harmonization.)\nSo, if you are an R user, you can use install.packages(“retroharmonize”) to get the released 0.1.13 version and make tutorials with real Eurobarometer or Afrobarometer microdata. With devtools::install_github(\u0026#34;antaldaniel/retroharmonize\u0026#34;) you can already install the current development version 0.1.14, which handles perl-like regex, which will be necessary for our next tutorial in the making for Arab Barometer.\nRelated:\nretroharmonize package website\nretroharmonize on github\n","date":1600687899,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600687899,"objectID":"010af539e67da4262227fb56053052d9","permalink":"https://reprex.nl/post/2020-09-21-retroharmonize_release/","publishdate":"2020-09-21T11:31:39Z","relpermalink":"/post/2020-09-21-retroharmonize_release/","section":"post","summary":"Our ex post survey harmonization package retroharmonize passed all automated tests and peer-reviews and was released today on CRAN.","tags":["R","open-data","reproducible","surveys","open-source"],"title":"Reproducible Survey Harmonization: retroharmonize Is Released","type":"post"},{"authors":["Daniel Antal","Réka Szentirmay"],"categories":null,"content":"Today, on 15 September 2020, we officially launched our minimal viable product as we promised to partners back in February. This was a particularly difficult period for everybody. We aspired to deliver by September in a very different environment, our hopes for commissioned work went up in flames with the pandemic, and our targeted users, musicians and music entrepreneurs, talent managers, music venues lost most of their income. The organizations helping them, granting authorities, export offices and collective management societies are overwhelmed with the problem. During these troublesome times, our team expanded, attracted great new talent, and kept working.\nOur first product is the Demo Music Observatory, a collaborative, automated research-based observatory for the music industry, one that is particularly hard hit by the COVID19 crisis. Not only great artists, composers, technicians, managers fell victim to the virus, but musicians lost about 50–90% of their income from live music. This translates to a 100% loss for the live music technicians and managers.\nSee our earlier blogpost on what you see on the video.\nThe music industry was never a place for great job security. For putting up a show, you usually need a network of 10–200 artists, technicians and managers to work together as freelancers without all those social benefits that many people enjoy in other walks of life. We have been trying to figure out how to help this microenterprise and freelancer-network based industry with research for five years. Our aim is to make them competitive when they are talking with their buyers: Google, Apple, Spotify, who are really heavy-weight data and AI pros. Our better plan their tours, when they will be back on the road, to understand what sort of audiences and purchasing power waits for them in different European cities.\nWe are launching at a time when the music industry is crying for help.Therefore, we have decided to make our demo observatory open and unfinished. Over the last 7 years, we have built up about 2000 music and creative sector indicators to be used for business KPIs, forecasting targets, grant evaluations, royalty valuations, concert demography target group analysis and other professional uses. We would like to open up, based on your needs, about 50 well-designed indicators, and pledge to keep it daily refreshed, corrected, documented, citaable, downloadable. Also, feel free to use our most valuable source code—use it for your own purposes, even modify it, as long as you keep it open.\nFor our smaller partners, we follow what musicians do these days on Bandcamp: name your price. We make a pledge to our small partners: if you need reliable data to plan your next grant calls, calculate royalties, compensations, predict hit candidates, give us the job—and name your price. Post-corona, you can take for a dollar the best music from Bandcamp. You can take our research products, for a limited period, for any amount you name, as long as it is for a good cause and serves the industry, musicians, technicians or managers. In return, we ask for your feedback. Help us validate whether we are on the right track, tell us how we can cooperate after the pandemic, in better times.\nOur larger and better funded partners? We ask you to pay the price we name, because we believe that it is a well-justified, fair and competitive price, set by pricing experts.\nWe appreciate it if you take a look at our offering, or if you pass this blogpost on to your colleagues in the industry. Our main target audience initially are music professional in broader Europe, but we are planning to cover all major global markets very soon, too. Feedback from the U.S., Australia, Canada, Colombia, Brazil \u0026amp; Argentina is particularly welcome as we have great plans over there!\nWho we are? We started our operations on 1 September 2020 on the basis of CEEMID, a pan-European data observatory that created about 2000 music and creative industry indicators for its users. In the coming days, we are gradually opening up about 50 music industry and 50 broader creative industry indicators in a fully reproducible workflow, with daily re-freshed, re-processed, well-formatted and documented indicators for business and policy decisions.\nWe would like to validate this approach in one of the world’s most prestigious university-backed incubator programs, in the Yes!Delft AI/Blockchain Validation Lab. We’re finalist on their selection, and all help before 23 September from our friends in the music industry is more than appreciated. If we get there, we can rely on probably the best pros in Europe to make our offering better tailored and financially sustainable.\nGet in touch! We use the very simple and extremely secure keybase.io, a kind of mix of Whatsapp, Skype, Google Drive, One Drive and zoom. You can get in touch on that platform with us in anytime here.\nYou can easily contact on LinkedIn Daniel or Kátya and of course, we have a usually working email contact …","date":1600156839,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600156839,"objectID":"f6e568ff8086896258dd95f01951aeed","permalink":"https://reprex.nl/post/2020-09-15-music-observatory-launch/","publishdate":"2020-09-15T08:00:39Z","relpermalink":"/post/2020-09-15-music-observatory-launch/","section":"post","summary":"We would like to validate our open source, open data, open collaboration based reproducible observatory concept with the Demo Music Observatory. All feedback is welcome.","tags":["R","Open data","reproducible research","music","Digital Music Observatory"],"title":"Launching Our Demo Music Observatory","type":"post"},{"authors":null,"categories":null,"content":"The Digital Music Observatory is a fully automated, open source, open data observatory that links public datasets in order to provide a comprehensive view of the European music industry. The DMO produces key business and policy indicators that enable the growth of music business strategies and national music policies in a way that works both for music lover audiences and the creative enterprises of the sector, and contributes to a more competitive, fair and sustainable European music ecosystem.\nIts data pillars are following the structure laid out in the Feasibility study for the establishment of a European Music Observatory.\nThe Demo Music Observatory Pillars:\nMusic Economy Diversity \u0026amp; Circulation Music \u0026amp; Society Innovation - innovative data applications Music is one of the most data-driven service industries where the majority of sales are already made by AI-driven autonomous systems. The DMO is a fully-functional service that can function as a testing ground of the European Data Strategy, showcasing the ways in which the music industry is affected by the problems that the Digital Services Act and the Trustworthy AI initiatives attempt to regulate. If these policies will work for the European microenterprise-dominated, complex and fragile European music ecosystem, then they are likely to make Europe fit for the digital age.\nDownload our introduction.\nOur Product/Market Fit was validated in the world’s 2nd ranked university-backed incubator program, the Yes!Delft AI Validation Lab. We are currently developing this project with the help of the JUMP European Music Market Accelerator program.\nFollow news about us or the more comprehensive Data \u0026amp; Lyrics blog.\nContact us.\nUse Cases We work with collective management organizations, when they do not have the data, or do not have the right to use the data that they have for various professional uses, including private copying damage claims, setting royalty tariffs (and defending them in copyright or competition tribunals.)\nWe support researchers at universities and consultancy to produce better evidence-based policies, business strategies or scientific output. We provide them thoroughly tested, properly processed, ready-to-import, ready-to-use data in various music, creative industries, competition, and climate change related issues. We work with very heterogeneous and highly fragmented data.\nOur team members have been involved with open governmental and open science data for almost 20 years individually. We know how to find, process, and make usable legally open, unique data which cannot be purchased on the market (from university archives, tax authorities, public satellites) in a way that matches scientific or financial auditing standards.\nWe participate in various trustworthy, ethical AI R\u0026amp;D projects with high-quality data and testing data to perform bad outcomes or malfunctioning recommendations of music AI systems.\n","date":1600128000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625875200,"objectID":"6f2ce9582bd2121f73d764a0c85f6eca","permalink":"https://reprex.nl/observatories/music/","publishdate":"2020-09-15T00:00:00Z","relpermalink":"/observatories/music/","section":"observatories","summary":"The Digital Music Observatory is a fully automated, open source, open data observatory that links public datasets in order to provide a comprehensive view of the European music industry.","tags":["Music"],"title":"Digital Music Observatory","type":"observatories"},{"authors":["Daniel Antal","Sandor Budai","Line Matson","Moon Moon Moon"],"categories":null,"content":"We are building data ecosystems, so called observatories, where scientific, business, policy and civic users can find factual information, data, evidence for their domain. Our open source, open data, open collaboration approach allows to connect various open and proprietary data sources, and our reproducible research workflows allow us to automate data collection, processing, publication, documentation and presentation.\nOur scripts are checking data sources, such as Eurostat’s Eurobase, Spotify’s API and other music industry sources every day for new information, and process any data corrections or new disclosure, interpolate, backcast or forecast missing values, make currency translations and unit conversions. This is shown illustrated with an earlier post.\nFor direct access to the file visit this link.\nIn the video we show automated the creation of an observatory website with well-formatted, statistical data dissemination, a technical document in PDF and an ebook can be automated. In our view, our technology is particularly useful technology in business and scientific researech projects, where it is important that always the most timely and correct data is being analyzed, and remains automatically documented and cited. We are ready deploy public, collaborative, or private data observatories in short time.\nData processing costs can be as high as 80% for any in-house AI deployment project. We work mainly with organization that do not have in house data science team, and acquire their data anyway from outside the organization. In their case, this rate can be as high as 95%, meaning that getting and processing the data for deploying AI can be 20x more expensive than the AI solution itself.\nAI solutions require a large amount of standardized, well processed data to learn from. We want to radically decrease the cost of data acquisition and processing for our users so that exploiting AI becomes in their reach. This is particularly important in one of our target industries, the music industries, where most of the global sales is algorithmic and AI-driven. Artists, bands, small labels, publishers, even small country national associations cannot remain competitive if they cannot participate in this technological revolution.\nWe started our operations on 1 September 2020 on the basis of CEEMID, a pan-European data observatory that created about 2000 music and creative industry indicators for its users. In the coming days, we are gradually opening up about 50 music industry and 50 broader creative industry indicators in a fully reproducible workflow, with daily re-freshed, re-processed, well-formatted and documented indicators for business and policy decisions.\nWe would like to validate this approach in one of the world’s most prestigious university-backed incubator programs, in the Yes!Delft AI/Blockchain Validation Lab.\nVideo credits Data acquisition and processing: Daniel Antal, CFA and Marta Kołczyńska, PhD (survey data). Documentation automation: Sandor Budai Video art: Line Matson Music: Moon Moon Moon. ","date":1599840039,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599840039,"objectID":"b4f8622152e32e38ccb53a2c262b9caa","permalink":"https://reprex.nl/post/2020-09-11-creating-automated-observatory/","publishdate":"2020-09-11T16:00:39Z","relpermalink":"/post/2020-09-11-creating-automated-observatory/","section":"post","summary":"The making of an automated and reproducible data tool for the music industry. A short video and a brief explanation.","tags":["R","open-data","reproducible"],"title":"Creating An Automated Data Observatory","type":"post"},{"authors":["Daniel Antal"],"categories":null,"content":"Retrospective data harmonization The aim of retroharmonize is to provide tools for reproducible retrospective (ex-post) harmonization of datasets that contain variables measuring the same concepts but coded in different ways. Ex-post data harmonization enables better use of existing data and creates new research opportunities. For example, harmonizing data from different countries enables cross-national comparisons, while merging data from different time points makes it possible to track changes over time.\nRetrospective data harmonization is associated with challenges including conceptual issues with establishing equivalence and comparability, practical complications of having to standardize the naming and coding of variables, technical difficulties with merging data stored in different formats, and the need to document a large number of data transformations. The retroharmonize package assists with the latter three components, freeing up the capacity of researchers to focus on the first.\nSpecifically, the retroharmonize package proposes a reproducible workflow, including a new class for storing data together with the harmonized and original metadata, as well as functions for importing data from different formats, harmonizing data and metadata, documenting the harmonization process, and converting between data types. See here for an overview of the functionalities.\nThe new labelled_spss_survey() class is an extension of haven’s labelled_spss class. It not only preserves variable and value labels and the user-defined missing range, but also gives an identifier, for example, the filename or the wave number, to the vector. Additionally, it enables the preservation – as metadata attributes – of the original variable names, labels, and value codes and labels, from the source data, in addition to the harmonized variable names, labels, and value codes and labels. This way, the harmonized data also contain the pre-harmonization record. The stored original metadata can be used for validation and documentation purposes.\nThe vignette Working With The labelled_spss_survey Class provides more information about the labelled_spss_survey() class.\nIn Harmonize Value Labels we discuss the characteristics of the labelled_spss_survey() class and demonstrates the problems that using this class solves.\nWe also provide three extensive case studies illustrating how the retroharmonize package can be used for ex-post harmonization of data from cross-national surveys:\nAfrobarometer Arab Barometer Eurobarometer The creators of retroharmonize are not affiliated with either Afrobarometer, Arab Barometer, Eurobarometer, or the organizations that designs, produces or archives their surveys.\nWe started building an experimental APIs data is running retroharmonize regularly and improving known statistical data sources. See: Digital Music Observatory, Green Deal Data Observatory, Economy Data Observatory.\nCitations and related work Citing the data sources Our package has been tested on three harmonized survey’s microdata. Because retroharmonize is not affiliated with any of these data sources, to replicate our tutorials or work with the data, you have download the data files from these sources, and you have to cite those sources in your work.\nAfrobarometer data: Cite Afrobarometer Arab Barometer data: cite Arab Barometer. Eurobarometer data: The Eurobarometer data Eurobarometer raw data and related documentation (questionnaires, codebooks, etc.) are made available by GESIS, ICPSR and through the Social Science Data Archive networks. You should cite your source, in our examples, we rely on the GESIS data files.\nCiting the retroharmonize R package For main developer and contributors, see the package homepage.\nThis work can be freely used, modified and distributed under the GPL-3 license:\ncitation(\u0026#34;retroharmonize\u0026#34;) #\u0026gt; #\u0026gt; To cite package \u0026#39;retroharmonize\u0026#39; in publications use: #\u0026gt; #\u0026gt; Daniel Antal (2021). retroharmonize: Ex Post Survey Data #\u0026gt; Harmonization. R package version 0.1.17. #\u0026gt; https://retroharmonize.dataobservatory.eu/ #\u0026gt; #\u0026gt; A BibTeX entry for LaTeX users is #\u0026gt; #\u0026gt; @Manual{, #\u0026gt; title: {retroharmonize: Ex Post Survey Data Harmonization}, #\u0026gt; author: {Daniel Antal}, #\u0026gt; year: {2021}, #\u0026gt; doi: {10.5281/zenodo.5006056}, #\u0026gt; note: {R package version 0.1.17}, #\u0026gt; url: {https://retroharmonize.dataobservatory.eu/}, #\u0026gt; } Contact For contact information, contributors, see the package homepage.\nCode of Conduct Please note that the retroharmonize project is released with a Contributor Code of Conduct. By contributing to this project, you agree to abide by its terms.\nClick the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. ","date":1598313600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624870800,"objectID":"d6f90fd73adcc2b6e69ea678f8058c1c","permalink":"https://reprex.nl/software/retroharmonize/","publishdate":"2020-08-25T00:00:00Z","relpermalink":"/software/retroharmonize/","section":"software","summary":"The goal of retroharmonize is to facilitate retrospective (ex-post) harmonization of data, particularly survey data, in a reproducible manner.","tags":["Surveys","Survey harmonization"],"title":"retroharmonize R package for survey harmonization","type":"software"},{"authors":["Daniel Antal, CFA","Réka Szentirmay"],"categories":null,"content":"The big day has come: the co-founders singed off the documents at the public notary and started the registration of a reproducible research start-up in Leiden. We got a lot of support from our friends! Your encouragement gives us a lot of energy to accomplish our first milestones, and to get Reprex B.V. going!\nReprex means ‘reproducible example’ in data science. When you are stuck with a problem, creating a reproducible example allows other computer scientists, statisticians, programmers or data users to solve it. In 80% of the cases, you usually find the solution while creating a generalized example. In the 20% other cases, you can reach out for help easily.\nIn the coming days, we are launching demo versions of our headline products, data observatories. music.dataobservatory.eu will be a fully automated online service that every day collects, processes, cleans, and publishes scientifically valid data about European music. Very soon after we will launch two other observatories.\nThe creative and cultural sector, NGOs, most research institutions, data journalism teams are usually very small, and they do not have internal IT or data science capacities. We would like to provide them a transparent, high quality, and fully open source solution to acquire data, process it without errors, document it and make sense of it. We would like to embrace the idea of open collaboration among creative enterprises, scientific researchers, NGOs, data journalists and policymakers with our work.\nOur work will comply with the Open Policy Analysis standards developed by the Berkeley Initiative for Transparency in the Social Sciences \u0026amp; Center for Effective Global Action and the four principles of reproducible research: reviewability, replicability, confirmability and auditability. We believe that these standards apply in reproducible finance, empirical evidence presentation in courts, or advocating sound policies and producing high-quality journalism.\nDo you want to help our start? We would like to enter into the Validation Lab of one of the best artificial intelligence incubators in early September. Talented team members, letters of intents and assignments from organizations will give a lot of credibility to our start Meet our team ».\nPut as in contact with people who love to write code in R and interested in automating business and social science research and primary data collection such as surveying. Check out what sort of code we create »\nIntroduce us to people who need data and information to make better informed decision and analysis in music, film, book publishing, photography services or socially responsible finance.\nShare contacts of data journalists who would like to develop stories from big survey programs like Eurobarometer, Afrobarometer and Lationbarometro, or base their storytelling on data and its visualizations. See our survey harmonization examples »\nDo you know such people? Send over this post or connect us in an email or social media message!\nThanks again for your good wishes and encouragements, and hope to hear from you soon!\n","date":1598264100,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598981640,"objectID":"3da46c8667871a37f68d68fbfc34a1af","permalink":"https://reprex.nl/post/2020-08-24-start-up/","publishdate":"2020-08-24T10:15:00Z","relpermalink":"/post/2020-08-24-start-up/","section":"post","summary":"The big day has come: the co-founders singed off the documents at the public notary and started the registration of a reproducible research start-up. Do you want to help us?","tags":["R","open-data","reproducible"],"title":"Starting-up","type":"post"},{"authors":["Daniel Antal"],"categories":null,"content":"iotables processes all the symmetric input-output tables of the EU member states, and calculates direct, indirect and induced effects, multipliers for GVA, employment, taxation. These are important inputs into policy evaluation, business forecasting, or granting/development indicator design. iotables is used by about 800 experts around the world.\nCode of Conduct Please note that the iotables project is released with a Contributor Code of Conduct. By contributing to this project, you agree to abide by its terms.\nClick the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. ","date":1591142400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644487200,"objectID":"e5736a65571a6c82cc15b66bbb8da8b4","permalink":"https://reprex.nl/software/iotables/","publishdate":"2020-06-03T00:00:00Z","relpermalink":"/software/iotables/","section":"software","summary":"The goal of iotables is to make allow a programmatic acces to the symmetric input-output tables of Eurostat. It creates multipliers, calculates direct, indirect and induced effects from European SIOT tables.","tags":["Environmental impact analysis","Economic impact analysis"],"title":"iotables R package for working with symmetric input-output tables","type":"software"},{"authors":["Daniel Antal"],"categories":null,"content":"CEEMID \u0026amp; Consolidated Independent presented and discussed with stakeholders the Central \u0026amp; Eastern European Music Industry Report 2020 as a case-study on national and comparative evidence-based policymaking in the cultural and creative sector on the CCS Ecosystems: FLIPPING THE ODDS Conference – a two-day high-level stakeholder event jointly organized by Geothe-Institute and the DG Education and Culture of the European Commission with the Creative FLIP project.\nThe CEE Report builds on the results of the first Hungarian, Slovak, Croatian and Czech music industry reports are compared with Armenian, Austrian, Bulgarian, Lithuanian, Serbian and Slovenian data and findings.\nOur research findings were earlier presented and discussed in Vienna, Prague, Budapest and Bratislava with stakeholders.\nYou can find the earlier presentations in the blog section of the website.\nExecutive Summary The first Central European Music Industry Report is the result of a co-operation that started among stakeholders in three EU countries five years ago to measure the economic value added of music – the basis of a modern royalty pricing system. This gave birth to CEEMID, originally the Central \u0026amp; Eastern European Music Industry Databases, a data integration programme that now in 2020, covers all of Europe. CEEMID fulfils similar roles to the planned European Music Observatory and supports all pillars of the future pan-European system.\nThe comparison of Western and Eastern music audiences reveals key demographic differences that make the unchanged adoption of business practices from mature markets in the region questionable. Chapter 2 of this report will show these differences and their consequences on music markets, in terms of visiting and acquisition likelihood, frequency, seasonality and purchasing capacity. This is an example of how CEEMID fulfils the role of Pillar 3 (music, society and citizenship) in the planned European Music Observatory.\nChapter 3 contrasts market demand with the supply strategies of musicians. CEEMID has been surveying music professionals, including artists, technicians and managers about their working conditions, market conditions and plans for five years across a growing number of countries. In 2019 we invited 100 national and regional stakeholders to distribute our surveys. In some countries, our surveys already have several years of historic data, making the resulting musician database probably the largest ever source of data about how music is produced and how musicians live. We are constantly looking for partners to roll out this survey to new countries in new languages.\nThe CEE region has comparative advantages in big music events like festivals, and it has become one of the most important hubs for cultural tourism in the world. We explain this phenomenon in Chapter 4 by showing the differences in demand composition, demography and supply of venues in the second chapter. The lack of a modern and dense network of permanent music venues gave rise to magnificent music festivals in the CEE. Open’er, Sziget and Exit are among the biggest and best festivals in the world, closely followed by several smaller festivals in all countries. The share of festivals in the live music market is many times higher than in Western Europe and they provide vital export revenues to the local music economies. However, they play a limited role in finding new audiences for local artists, as they are increasingly programming for Western audiences by providing shows of international hits. They can only very partially fill in the gaps left by the small venue problem that hit the emerging markets harder than the UK or Australia, where policy action had been already taken to reverse the decline of the availability of smaller live music venues.\nOn the recording side, our analysis shows that modern digital services are growing at a faster rate than in mature markets. Because of lower repertoire competition, streaming quantities are similar for a typical Austrian, Czech, Hungarian, Polish or Slovak track than in the mature markets. However, revenue growth is limited because of the interplay of several analysed factors. Our analysis of the live and recorded music markets shows that CEEMID fulfils the roles of the Pillar 1 (music economy) of the planned European Music Observatory.\nMost recorded music sales revenue in the region comes from streaming platforms, just like in the mature markets. Successful sales strategies require a solid knowledge of the global marketplace and the ability to understand and train sales algorithms. Micro-enterprises, such as independent labels, have very limited ability to cope with these functions, given that they do not have market research or R\u0026amp;D functions. CEEMID and Consolidated Independent have started initiating open, national R\u0026amp;D consortia to create the necessary concentration in data assets, analytical capacity and budgets to close this gap. As a first step, CEEMID and Consolidated Independent have …","date":1580313600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580313600,"objectID":"5ee96ab1e81941d29fc0164f71dc9a4b","permalink":"https://reprex.nl/publication/ceereport_2020/","publishdate":"2020-01-29T16:00:00Z","relpermalink":"/publication/ceereport_2020/","section":"publication","summary":"The results of the first Hungarian, Slovak, Croatian and Czech music industry reports are compared with Armenian, Austrian, Bulgarian, Lithuanian, Serbian and Slovenian data and findings.","tags":["Market report","Music industry","Armenia","Austria","Bulgaria","Czechia","Lithuania","Hungary","Slovakia","Serbia"],"title":"Central \u0026 Eastern European Music Industry Report 2020","type":"publication"},{"authors":null,"categories":null,"content":"CEEMID was multi-country project that was a predecessor of Reprex’s Digital Music Observatory. It transferred thousands of indicators to the Digital Music Observatory and offered it to the future European Music Observatory.\nThe CEEMID project (2014-2020) formed the basis of our first data observatory — the challenges of a 12-country data collection and sharing project forced our team to find novel software, data governance and data processing solution that fitted a very fragmented, multi-language music industry with many internal and external challenges. We showed that we can provide reach, data-driven evidence in seemingly data poor countries. We can find alternative data sources when there are no data vendors, no official government statistics are present, or when important data assets cannot be used due to business confidentiality clauses.\nThe Central European Music Industry Report 2020 concluded the CEEMID project showing that building meaningful statistical indicators for the live performance, recording and publishing sides of the music industry is possible even in seemingly data poor emerging and future markets. Our Report was presented as a best practice by the European Commission and the Geothe Institute in 2020. In 2019 we offered CEEMID as one possible alternative to building the European Music Observatory. In our experience and understanding, the music industry has many failed international data projects because of the inherent conflicts of interests among big and large countries, authors and producers, producers, and performers, and in 2020 we launched our Digital Music Observatory.\nFrom an early stage, there has been an interest in our solutions from newer and newer industries. During the validation of our observatory’s product/market fit, we realized that we gave a novel solution to a problem that is not at all unique to the music industry. The fragmentation of data assets among the institutional boundaries of small enterprises and NGOs, the fragmentation of research budgets that disallow comprehensive data collection problems, the reliance on questionable quality and hard-to-integrate public and third-party data is present in almost all business and policy domains.\nThe Case Study in Belgium brings together open data in a novel way from satellite, hydrological, opinion polling and tax administration data to show the geographical overlap of catastrophic drought and flood risk with the local political awareness and financial capacity to manage it. Our approach to music data turned out to be applicable in many situations when the data and the research capacities are fragmented. We developed reliable software tools and know-how bring up reusable open government and open science data, which are available upon request in developed countries like raw diamonds, without the polishing of data scientists, documentation, or modern databases. We learned how to build a decentralized approach to data sharing and resource pooling using the agile open collaboration method of open-source software development. We became experts in handling legally open data and freedom of information requests on an industrial scale. After the launch of the Digital Music Observatory, we started building three new observatories with various partners in Computational Antitrust, Green Deal (climate change) and the broader Cultural Creative Sectors \u0026amp; Industries.\nCEEMID did not only work with public and openly accessible data. We used these novel sources when other data was not available, legally could not be used, or it was prohibitively expensive. But most of the value we created for music rightsholders required the management of highly confidential data. We know that a public data observatory is not ideal for all potential users. We are piloting fully private observatories, and a blend of pubic (and therefore widely trustworthy) and proprietary hybrid observatories based on the experience of the ‘public’ and ‘private’ layers of CEEMID.\nHistorically CEEMID started out as the Central and Eastern European Music Industry Databases out of necessity following a CISAC Good Governance Seminar for European Societies in 2013, and eventually grew out of an abandoned GESAC project. The adoption of European single market and copyright rules, and the increased activity of competition authority and regulators required a more structured approach to set collective royalty and compensations tariffs in a region that was regarded traditionally as data-poor with lower quantity of industry and government data sources available. In 2014 three societies, Artisjus, HDS and SOZA realized that need to make further efforts to modernize the way they measure their own economic impact, the economic value of their licenses to remain competitive in advocating the interests vis-à-vis domestic governments, international organizations like CISAC and GESAC and the European Union. They signed a Memorandum of Understanding with their consultant to set up the CEEMID …","date":1551225600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634835600,"objectID":"f9ecb6b3cbc70328e0e3434240c3c0d5","permalink":"https://reprex.nl/project/ceemid/","publishdate":"2019-02-27T00:00:00Z","relpermalink":"/project/ceemid/","section":"project","summary":"CEEMID was multi-country project that was a predecessor of Reprex’s Digital Music Observatory.","tags":["CEEMID","Digital Music Observatory","Surveys"],"title":"CEEMID","type":"project"},{"authors":[],"categories":[],"content":"Greenwashing Competition Data Observatory | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"5a5fb64a121536e8988c263fb7b7ed75","permalink":"https://reprex.nl/slides/greenwashing/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/greenwashing/","section":"slides","summary":"An introduction to the Competition Data Observatory","tags":["greenwashing"],"title":"Evidence Against Greenwashing","type":"slides"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"36f64f49ffbb6367f661538547979910","permalink":"https://reprex.nl/slides/template/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/template/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Daniel Antal"],"categories":null,"content":"Installation You can install the development version from GitHub with:\ndevtools::install_github(\u0026#34;rOpenGov/regions\u0026#34;) or the released version from CRAN:\ninstall.packages(\u0026#34;devtools\u0026#34;) regions currently takes care of 20,000 sub-divisional boundary changes in Europe since 1999. Comparing departments of France in 2013, with 2007 vojvodinas of Poland and 2018 megyék in Hungary? This extremely errorprone work is automated, as a result, you can compare 110-260 regions for far better analysis. regions was downloaded about 600 researchers in the first month after release.\nYou can review the complete package documentation on regions.dataobservatory.eu. If you find any problems with the code, please raise an issue on Github. Pull requests are welcome if you agree with the Contributor Code of Conduct\nIf you use regions in your work, please cite the package.\nMotivation Working with sub-national statistics has many benefits. In policymaking or in social sciences, it is a common practice to compare national statistics, which can be hugely misleading. The United States of America, the Federal Republic of Germany, Slovakia and Luxembourg are all countries, but they differ vastly in size and social homogeneity. Comparing Slovakia and Luxembourg to the federal states or even regions within Germany, or the states of Germany and the United States can provide more adequate insights. Statistically, the similarity of the aggregation level and high number of observations can allow more precise control of model parameters and errors.\nThe advantages of switching from a national level of the analysis to a sub-national level comes with a huge price in data processing, validation and imputation. The package Regions aims to help this process.\nThis package is an offspring of the eurostat package on rOpenGov. It started as a tool to validate and re-code regional Eurostat statistics, but it aims to be a general solution for all sub-national statistics. It will be developed parallel with other rOpenGov packages.\nSub-national Statistics Have Many Challenges Frequent boundary changes: as opposed to national boundaries, the territorial units, typologies are often change, and this makes the validation and recoding of observation necessary across time. For example, in the European Union, sub-national typologies change about every three years and you have to make sure that you compare the right French region in time, or, if you can make the time-wise comparison at all.\nHierarchical aggregation and special imputation: missingness is very frequent in sub-national statistics, because they are created with a serious time-lag compared to national ones, and because they are often not back-casted after boundary changes. You cannot use standard imputation algorithms because the observations are not similarly aggregated or averaged. Often, the information is seemingly missing, and it is present with an obsolete typology code.\nPackage functionality Generic vocabulary translation and joining functions for geographically coded data Keeping track of the boundary changes within the European Union between 1999-2021 Vocabulary translation and joining functions for standardized European Union statistics Vocabulary translation for the ISO-3166-2 based Google data and the European Union Imputation functions from higher aggregation hierarchy levels to lower ones, for example from NUTS1 to NUTS2 or from ISO-3166-1 to ISO-3166-2 (impute down) Imputation functions from lower hierarchy levels to higher ones (impute up) Aggregation function from lower hierarchy levels to higher ones, for example from NUTS3 to NUTS1 or from ISO-3166-2 to ISO-3166-1 (aggregate; under development) Disaggregation functions from higher hierarchy levels to lower ones, again, for example from NUTS1 to NUTS2 or from ISO-3166-1 to ISO-3166-2 (disaggregate; under development) Vignettes / Articles Working With Regional, Sub-National Statistical Products Validating Your Typology Recoding And Relabelling The Typology Of The Google Mobility Reports (COVID-19) Feedback? Raise and issue on Github or get in touch. Downloaders from CRAN: Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. ","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624276800,"objectID":"ffb0c296df8a28131e6ab084f18b3963","permalink":"https://reprex.nl/software/regions/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/software/regions/","section":"software","summary":"regions currently takes care of 20,000 sub-divisional boundary changes in Europe since 1999.","tags":["Regional statistics"],"title":"regions R package to create sub-national statistical indicators","type":"software"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://reprex.nl/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]